{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t5JqrpJWoNaB"
   },
   "source": [
    "# CRAFT demo (inference only) using ConvoKit\n",
    "\n",
    "This example notebook shows how an already-trained CRAFT model can be applied to conversational data to predict future derailment. This example uses the fully trained Wikiconv-based model as reported in the \"Trouble on the Horizon\" paper, and applies it to ConvoKit's version of the labeled Wikiconv corpus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import convokit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import Forecaster, Corpus, download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit.forecaster.CRAFTModel import CRAFTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading craft-wiki-pretrained to /Users/mishkin/.convokit/saved-models/craft-wiki-pretrained\n",
      "Downloading craft-wiki-pretrained/craft_pretrained.tar from https://zissou.infosci.cornell.edu/convokit/models/craft_wikiconv/craft_pretrained.tar (974.6MB)... Done\n",
      "Downloading craft-wiki-pretrained/index2word.json from https://zissou.infosci.cornell.edu/convokit/models/craft_wikiconv/index2word.json (998.5KB)... Done\n",
      "Downloading craft-wiki-pretrained/word2index.json from https://zissou.infosci.cornell.edu/convokit/models/craft_wikiconv/word2index.json (898.4KB)... Done\n"
     ]
    }
   ],
   "source": [
    "craft_model = CRAFTModel(initial_weights=\"craft-wiki-pretrained\", torch_device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Forecaster.__init__() got an unexpected keyword argument 'forecast_mode'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m forecaster = \u001b[43mForecaster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforecaster_model\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcraft_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mforecast_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfuture\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mconvo_structure\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlinear\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mtext_func\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mutt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mutt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMAX_LENGTH\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mlabel_func\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mutt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mutt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcomment_has_personal_attack\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mforecast_attribute_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforecast_prob_attribute_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpred_score\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m                        \u001b[49m\u001b[43muse_last_only\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mskip_broken_convos\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m                       \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: Forecaster.__init__() got an unexpected keyword argument 'forecast_mode'"
     ]
    }
   ],
   "source": [
    "forecaster = Forecaster(forecaster_model = craft_model,\n",
    "                        forecast_mode = \"future\",\n",
    "                        convo_structure=\"linear\",\n",
    "                        text_func = lambda utt: utt.meta[\"tokens\"][:(MAX_LENGTH-1)],\n",
    "                        label_func = lambda utt: int(utt.meta['comment_has_personal_attack']),\n",
    "                        forecast_attribute_name=\"prediction\", forecast_prob_attribute_name=\"pred_score\",\n",
    "                        use_last_only = True,\n",
    "                        skip_broken_convos=False\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading conversations-gone-awry-corpus to /Users/mishkin/.convokit/saved-corpora/conversations-gone-awry-corpus\n",
      "Downloading conversations-gone-awry-corpus from http://zissou.infosci.cornell.edu/convokit/datasets/conversations-gone-awry-corpus/conversations-gone-awry-corpus.zip (45.2MB)... Done\n"
     ]
    }
   ],
   "source": [
    "corpus = Corpus(filename=download(\"conversations-gone-awry-corpus\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o_ev-7g-xsGQ"
   },
   "source": [
    "## Part 2: load the data\n",
    "\n",
    "Now we load the labeled Wikiconv corpus from ConvoKit, and run some transformations to prepare it for use with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit.forecaster.CRAFT import craft_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for utt in corpus.iter_utterances():\n",
    "    utt.add_meta(\"tokens\", craft_tokenize(craft_model.voc, utt.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1; Percent complete: 2.5%\n",
      "Iteration: 2; Percent complete: 5.0%\n",
      "Iteration: 3; Percent complete: 7.5%\n",
      "Iteration: 4; Percent complete: 10.0%\n",
      "Iteration: 5; Percent complete: 12.5%\n",
      "Iteration: 6; Percent complete: 15.0%\n",
      "Iteration: 7; Percent complete: 17.5%\n",
      "Iteration: 8; Percent complete: 20.0%\n",
      "Iteration: 9; Percent complete: 22.5%\n",
      "Iteration: 10; Percent complete: 25.0%\n",
      "Iteration: 11; Percent complete: 27.5%\n",
      "Iteration: 12; Percent complete: 30.0%\n",
      "Iteration: 13; Percent complete: 32.5%\n",
      "Iteration: 14; Percent complete: 35.0%\n",
      "Iteration: 15; Percent complete: 37.5%\n",
      "Iteration: 16; Percent complete: 40.0%\n",
      "Iteration: 17; Percent complete: 42.5%\n",
      "Iteration: 18; Percent complete: 45.0%\n",
      "Iteration: 19; Percent complete: 47.5%\n",
      "Iteration: 20; Percent complete: 50.0%\n",
      "Iteration: 21; Percent complete: 52.5%\n",
      "Iteration: 22; Percent complete: 55.0%\n",
      "Iteration: 23; Percent complete: 57.5%\n",
      "Iteration: 24; Percent complete: 60.0%\n",
      "Iteration: 25; Percent complete: 62.5%\n",
      "Iteration: 26; Percent complete: 65.0%\n",
      "Iteration: 27; Percent complete: 67.5%\n",
      "Iteration: 28; Percent complete: 70.0%\n",
      "Iteration: 29; Percent complete: 72.5%\n",
      "Iteration: 30; Percent complete: 75.0%\n",
      "Iteration: 31; Percent complete: 77.5%\n",
      "Iteration: 32; Percent complete: 80.0%\n",
      "Iteration: 33; Percent complete: 82.5%\n",
      "Iteration: 34; Percent complete: 85.0%\n",
      "Iteration: 35; Percent complete: 87.5%\n",
      "Iteration: 36; Percent complete: 90.0%\n",
      "Iteration: 37; Percent complete: 92.5%\n",
      "Iteration: 38; Percent complete: 95.0%\n",
      "Iteration: 39; Percent complete: 97.5%\n",
      "Iteration: 40; Percent complete: 100.0%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<convokit.model.corpus.Corpus at 0x7ff539d91a50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.transform(corpus, selector=lambda convo: convo.meta[\"split\"] == \"train\",\n",
    "                    ignore_utterances=lambda utt: utt.meta[\"is_section_header\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'forecaster' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m forecasts_df = \u001b[43mforecaster\u001b[49m.summarize(corpus)\n",
      "\u001b[31mNameError\u001b[39m: name 'forecaster' is not defined"
     ]
    }
   ],
   "source": [
    "forecasts_df = forecaster.summarize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>pred_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utt_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>800622928.18454.18454</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351871224.50472.50472</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409048245.4938.4938</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751475142.54124.54124</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308491753.38115.38115</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404257585.20200.20200</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159022461.6705.6705</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746296311.83642.83642</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117788418.23770.23770</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.987995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18657304.7525.7525</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.987427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200417282.167665.167665</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.987180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462029088.1785.1785</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110875381.4905.4893</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737162646.263371.263371</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379019100.144622.144622</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362070598.18873.18873</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36494082.4097.4097</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677077058.15302.15302</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170314474.34849.34849</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.985931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79340130.87335.87335</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.985910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         prediction  pred_score\n",
       "utt_id                                         \n",
       "800622928.18454.18454           1.0    0.989630\n",
       "351871224.50472.50472           1.0    0.988888\n",
       "409048245.4938.4938             1.0    0.988836\n",
       "751475142.54124.54124           1.0    0.988621\n",
       "308491753.38115.38115           1.0    0.988546\n",
       "404257585.20200.20200           1.0    0.988429\n",
       "159022461.6705.6705             1.0    0.988336\n",
       "746296311.83642.83642           1.0    0.988175\n",
       "117788418.23770.23770           1.0    0.987995\n",
       "18657304.7525.7525              1.0    0.987427\n",
       "200417282.167665.167665         1.0    0.987180\n",
       "462029088.1785.1785             1.0    0.986980\n",
       "110875381.4905.4893             1.0    0.986850\n",
       "737162646.263371.263371         1.0    0.986698\n",
       "379019100.144622.144622         1.0    0.986244\n",
       "362070598.18873.18873           1.0    0.986196\n",
       "36494082.4097.4097              1.0    0.986079\n",
       "677077058.15302.15302           1.0    0.986012\n",
       "170314474.34849.34849           1.0    0.985931\n",
       "79340130.87335.87335            1.0    0.985910"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecasts_df.head(20)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of CRAFT inference demo using ConvoKit",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
