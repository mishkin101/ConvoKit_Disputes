{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the Expected Context Framework to Wikipedia discussions\n",
    "\n",
    "This notebook demonstrates an application of the Expected Context Framework to analyze Wikipedia talk page discussions. We are working up to the following question: what types of comments are more likely to start conversations that eventually derail into toxic personal attacks, versus conversations that remain civil throughout? The notebook goes over a few key function calls along the way. See [this paper](https://www.cs.cornell.edu/~cristian/Conversations_gone_awry_files/conversations_gone_awry.pdf) for details on the analysis question and datasets, and [this dissertation](https://tisjune.github.io/research/dissertation) for details on the framework and more comments on the below analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this demo, we start by training an Expected Context Model on a collection of Wikipedia discussions (different from the dataset we later analyze). In short, we want to infer different _rhetorical types_ of comments that occur at the start of these discussions. Via the framework, we'll derive representations of comments based on their expected replies (the \"forwards context\" of the conversation), and then infer types of comments by clustering these representations. We interpret the resultant clusters as different rhetorical types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an extended version of this analysis, on a slightly older implementation of the model (using the `PromptTypes` functionality), see [this notebook](https://github.com/CornellNLP/ConvoKit/blob/master/examples/conversations-gone-awry/Conversations_Gone_Awry_Prediction.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading and preprocessing the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from convokit import Corpus\n",
    "from convokit import download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OPTION 1: DOWNLOAD CORPUS \n",
    "# UNCOMMENT THESE LINES TO DOWNLOAD CORPUS\n",
    "# DATA_DIR = '<YOUR DIRECTORY>'\n",
    "# WIKI_CORPUS_PATH = download('wiki-corpus', data_dir=DATA_DIR)\n",
    "\n",
    "# OPTION 2: READ PREVIOUSLY-DOWNLOADED CORPUS FROM DISK\n",
    "# UNCOMMENT THIS LINE AND REPLACE WITH THE DIRECTORY WHERE THE TENNIS-CORPUS IS LOCATED\n",
    "# WIKI_CORPUS_PATH = '<YOUR DIRECTORY>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wiki_corpus = Corpus(WIKI_CORPUS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Speakers: 38462\n",
      "Number of Utterances: 391294\n",
      "Number of Conversations: 125292\n"
     ]
    }
   ],
   "source": [
    "wiki_corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We represent Wikipedia comments as dependency-parse arcs; in order to capture  rhetorical rather than topical information, we've removed nouns. These features are included with the release of the corpus, and can be loaded as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wiki_corpus.load_info('utterance',['arcs_censored'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure that the arcs are stored in the right format (i.e., as strings, not lists), we apply the following transformer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from convokit.text_processing import TextProcessor\n",
    "join_arcs = TextProcessor(input_field='arcs_censored', output_field='arcs',\n",
    "                     proc_fn=lambda sents: '\\n'.join(sents))\n",
    "wiki_corpus = join_arcs.transform(wiki_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In applying the framework, we need to associate utterances with their replies. One comment can receive multiple replies; here, we arbitrarily choose one (noting that future work could make better use of this additional information). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ut in wiki_corpus.iter_utterances(selector=lambda x: x.reply_to is not None):\n",
    "    wiki_corpus.get_utterance(ut.reply_to).meta['next_id'] = ut.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Applying the Expected Context Framework\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from convokit.expected_context_framework import ColNormedTfidfTransformer, ExpectedContextModelTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply the Expected Context Framework, we start by converting the input utterance text to an input vector representation. Here, we represent utterances in a term-document matrix that's _normalized by columns_ (empirically, we found that this ensures that the representations derived by the framework aren't skewed by the relative frequency of utterances). We use the `ColNormedTfidfTransformer` transformer to do this.\n",
    "\n",
    "We found that it was preferable to derive different tf-idf representations (and hence different inverse document frequencies, normalization terms, and vocabularies) for comments that receive replies, and utterances that have predecessors. We make this partitioning by passing in different selectors to the `fit` functions below.\n",
    "\n",
    "The two sets are of course overlapping, but the former set mostly contains comments that start conversations, and the second contains more comments that reply to conversation-starters. We note that we'd expect the language of conversation-starters and repliers to be slightly different (i.e., the former tend to be requests, and the latter tend to be responses to these requests)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_tfidf_obj = ColNormedTfidfTransformer(input_field='arcs', output_field='first_tfidf', binary=True, min_df=50)\n",
    "_ = first_tfidf_obj.fit(wiki_corpus, selector=lambda x: x.meta.get('next_id',None) is not None)\n",
    "_ = first_tfidf_obj.transform(wiki_corpus)\n",
    "\n",
    "second_tfidf_obj = ColNormedTfidfTransformer(input_field='arcs', output_field='second_tfidf', binary=True, min_df=50)\n",
    "_ = second_tfidf_obj.fit(wiki_corpus, selector=lambda x: x.reply_to is not None)\n",
    "_ = second_tfidf_obj.transform(wiki_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then initialize an Expected Context Model:\n",
    "* we specify that the conversational context we will derive our comment representations from is the reply, `context_field=next_id`\n",
    "* as input, the model will use tf-idf representations from `vect_field=first_tfidf` to represent comments, and `context_vect_field=second_tfidf` to represent context comments\n",
    "* we'll derive `n_svd_dims=25`-dimensional representations, and infer `n_clusters=6` clusters\n",
    "* to infer these clusters, we will cluster _term_-level representations, `cluster_on='terms'`. Note that by default, the model will cluster _comment_-level representations, but in this context (perhaps since comments can get fairly long and unstructured), clustering on terms produces more interpretable output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ec_fw = ExpectedContextModelTransformer(\n",
    "    context_field='next_id', output_prefix='fw', \n",
    "    vect_field='first_tfidf', context_vect_field='second_tfidf', \n",
    "      n_svd_dims=25, n_clusters=6, cluster_on='terms',\n",
    "     random_state=1000, cluster_random_state=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(note that the following call takes some time to run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ec_fw.fit(wiki_corpus, selector=lambda x: (x.meta.get('first_tfidf__n_feats',0)>=1)\n",
    "                                  and (x.meta.get('next_id',None) is not None), \n",
    "            context_selector=lambda x: (x.meta.get('second_tfidf__n_feats',0)>= 1)\n",
    "                         and (x.reply_to is not None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferred comment types\n",
    "\n",
    "Below, we print representative terms, comments, and context terms and comments for the clusters we've inferred (note that the output is quite long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLUSTER 0 0\n",
      "---\n",
      "terms\n",
      "           cluster_dist\n",
      "index                  \n",
      "'m_*           0.497348\n",
      "thought_*      0.498929\n",
      "guess_*        0.508338\n",
      "sorry>*        0.521577\n",
      "know_*         0.526687\n",
      "had_*          0.531728\n",
      "got_*          0.537593\n",
      "'s_*           0.543810\n",
      "have>*         0.544413\n",
      "saw_*          0.549280\n",
      "\n",
      "context terms\n",
      "          cluster_dist\n",
      "index                 \n",
      "saw_*         0.598228\n",
      "yes>*         0.603147\n",
      "knew_*        0.607990\n",
      "but>*         0.614208\n",
      "oh>*          0.615937\n",
      "anyway>*      0.619059\n",
      "hey>*         0.620055\n",
      "guess_*       0.620307\n",
      "oh_*          0.635252\n",
      "and>*         0.639936\n",
      "\n",
      "\n",
      "utterances\n",
      "> 512605 0.456 Thanks for your help but I thought I'd point [http:\\/\\/en.wikipedia.org\\/w\\/index.php?title=List_of_Playboy_Playmates_of_1962&curid=27082401&diff=358137637&oldid=357917384 this] out.  Thanks again, <s\n",
      "> 384706 0.463 Sorry but I don't know. I 've seen people doing this manually based. -- \n",
      "> 58226 0.464 Hi WFinch. I think it's awesome that you're improving Nero Wolfe articles, but I'm curious - do you know the copyright status of the scripts you are linking to in some articles (eg [[The Silent Speake\n",
      "> 141668 0.464 [http:\\/\\/en.wikipedia.org\\/w\\/index.php?title=Halloween_%281978_film%29&curid=20179415&diff=443119488&oldid=443117044 This] was gorgeous.  I thought I had done some severe cutting in my plot trimming\n",
      "> 294263 0.468 Yes, I saw the comment, and thought it was likely to be the case. I found myself itching to add ''proto-'' in the lede, but that's probably a worse fudge than using an anachronistic term that is widel\n",
      "> 325392 0.469 Well, to be honest I knew I was probably not following the right protocol! I thought my solution would be ok but I guess I should have asked for help instead. Anyways, thanks for the advice and the cl\n",
      "> 134322 0.470 LOL! Sorry about that man. I just think all this confusing about it is ridiculous. By the way, the reason I suggested the second cover go by Disc Two or Meet Miley Cyrus Cover is so it won't get contr\n",
      "> 341552 0.471 (I think when referring to chart positions, it is better to use numerals whether or not our friendly style guide suggests  it, if in fact it comments (as opposed to spelling out numbers one to nine). \n",
      "> 24168 0.471 By the way, just thought I'd say that I think the recent edits you made to this article look good. There's so much negativity all the time I like to consciously remember to comment on useful additions\n",
      "> 549552 0.472 Ah... that makes sense. Thanks. Do you know who is responsible for picking names? The [[Admiralty]]? I've seen a lot of RN ship names (especially 18th century) that seem like somebody threw a dart at \n",
      "\n",
      "context-utterances\n",
      ">> 141287 0.550 Hey thanks mate atleast someone has the logical mind to remove trashy pov its a shame that admins who protect these articles like k2 and nanga parbat turn a blind eye towards this blatant pov just bec\n",
      ">> 177807 0.554 Very nice, well done, Maybe format the dates? from 00-00-00, to 1 August 1111, as an exemple. but overall, you did a wonderful job on the list. <br \\/>&nbsp;&nbsp;\\u2013 ''\n",
      ">> 70287 0.568 Re Eddie Watkins. Yes it is, he joined Wigan in March 1939. I'll update the article to reflect his league career today. When I started writing many of the Welsh articles I had a limited number of refe\n",
      ">> 422098 0.569 I saw you had contributed to video game articles and I remember many video game pictures from Ubisoft were deleted from Commons, so I wondered what if anything you might have uploaded there, since it'\n",
      ">> 344312 0.578 Thanks. But I saw that William, a real expert, already talked to him. --\n",
      ">> 234888 0.586 It's no big deal. After thinking about it, I guess you're right about this. --\n",
      ">> 23171 0.590 Yeah, I guess it makes sence. Since the CFL doesn't play all their games on one particular day of the week. And thanks the website, I got all my information from [http:\\/\\/michigan-football.com\\/cfl\\/\n",
      ">> 394976 0.592 hi Maurreen, it more happenstance than system, i was filling in red links at [[MacArthur Fellows Program]], (which to me is a snowball keep) and checking histories, saw a couple that i undid, also fou\n",
      ">> 576498 0.594 Wow Mongo, never expected this. You've had a hard time here, but your work dealing with fringe views is invaluable. I hope you can look beyond this one block and see that you are very much appreciated\n",
      ">> 583441 0.596 I was just starting to RC patrol when I saw that diff. I thought it looked fimiliar and I realised I had one just like that[http:\\/\\/en.wikipedia.org\\/w\\/index.php?title=User_talk%3ASpellcast&diff=149\n",
      "\n",
      "====\n",
      "\n",
      "CLUSTER 1 1\n",
      "---\n",
      "terms\n",
      "              cluster_dist\n",
      "index                     \n",
      "let_*             0.507374\n",
      "done_*            0.509473\n",
      "appreciate_*      0.512464\n",
      "tried_*           0.524234\n",
      "help_*            0.530647\n",
      "let_know          0.536958\n",
      "look_*            0.540756\n",
      "hi>*              0.545773\n",
      "hi_*              0.548464\n",
      "take_*            0.549002\n",
      "\n",
      "context terms\n",
      "               cluster_dist\n",
      "index                      \n",
      "okay>*             0.641118\n",
      "ok>*               0.646864\n",
      "alright>*          0.653850\n",
      "uploaded_have      0.670640\n",
      "update_*           0.681726\n",
      "ok_*               0.683843\n",
      "helps_*            0.705702\n",
      "cool>*             0.707850\n",
      "cool_*             0.709546\n",
      "hope_do            0.712557\n",
      "\n",
      "\n",
      "utterances\n",
      "> 164003 0.446 Good work on the list of Jat clans. It would be nice if there were a more current census.  Let me know if you need help with polishing on articles you write, and I will be glad to edit.  You might use\n",
      "> 550714 0.452 Hello Splash! I haven't had much of a chance for correspondance lately, getting ready for the start of the new semester and all that, but I've been wondering what your ideas are concerning the [[Londo\n",
      "> 350317 0.454 If you do ever choose to run again, please let me know.  I'll be there. &mdash;&nbsp;\n",
      "> 340943 0.455 Let me know which sound files you want added. I'd like to see \\\"Harborcoat\\\", but I suppose I would have to be \\\"Letter Never Sent\\\" or \\\"Camera\\\" from that album. \n",
      "> 161635 0.456 Once you've figured out what format you want, let me know what archive names you want and what you want at the top of each archive and I'll be able to set up the bot for you. '''<span style=\\\"font-fam\n",
      "> 365578 0.457 Hi Sydney. I hope this finds you well. My name is Matthew Roth and I'm a Storyteller at the Wikimedia Foundation. We're chronicling the inspiring stories of the Wikipedia community, especially editors\n",
      "> 339036 0.457 Hi Leah, good hearing from you again! When I'm creating books, I mainly create them on two merits: The first is that I must have some sort of interest in the topic, and the second is that the topic mu\n",
      "> 107916 0.459 You might try contacting user [[User talk:Colds7ream|Colds7ream]], who successfully took [[International Space Station]] through FAC a year ago -- they may be both knowledgeable and willing to help wi\n",
      "> 570792 0.460 I actually don't know how to do that. If you can point me at any examples of what you're trying to do, I'll prod at it and let you know how it works. I'd like to encourage you to focus less on your us\n",
      "> 462990 0.461 Your help is very much appreciated. I don't know if I understand exactly all what you mean but I will try my best. The examples of other composers that you suggested will be a great help. I will be in\n",
      "\n",
      "context-utterances\n",
      ">> 296304 0.601 Alright; got someone else I could bug? I've already contacted Fuchs. <font face=\\\"Verdana\\\">\n",
      ">> 165740 0.610 Thanks, I appreciate the help.  The list above helps, and I'll mess with it some more to see if any further scrutiny is required to eliminate the chances of tagging incorrect images.  \n",
      ">> 347273 0.616 Hi, you have some good comments. I started a rudimentary Core Topics COTW at [[Wikipedia:Version 1.0 Editorial Team\\/Core topics\\/Core topics COTW]]. We can see how it goes. Thanks. \n",
      ">> 321554 0.618 OK with the group we can do it all. Although Picasso images are proving to be tough to work with because of copyrights and estate issues. Olympia, maybe or late Monet - what a story. \n",
      ">> 551717 0.623 Great, I hate autoblocks. They're more trouble than they're worth in situations like these. Ok, off to deliver pizzas...<font color=\\\"#4682B4\\\">\n",
      ">> 90138 0.623 Okay. Nevertheless, please drop a line on the football project talk page once the discussion has been opened. --\n",
      ">> 374426 0.625 Okay, I appreciate your looking into it, \n",
      ">> 545836 0.629 Hey there. Yes, I do see your argument, but unfortunately with organisations like the CDC and WHO all referring to this as \\\"swine influenza\\\" (see [http:\\/\\/www.who.int\\/csr\\/disease\\/swineflu\\/en\\/i\n",
      ">> 543511 0.631 Ok then... I appreciate the recognition though. Thanks, <b><font face=\\\"Arial\\\" color=\\\"1F860E\\\">[[User:BrendelSignature|Signature]]<\\/font><font color=\\\"20038A\\\"><sup>\n",
      ">> 239293 0.643 Since he hasn't edited since the end of August, I also dropped a copy on Jpgordon's page as well.  Hopefully we'll hear from one of them soon. \n",
      "\n",
      "====\n",
      "\n",
      "CLUSTER 2 2\n",
      "---\n",
      "terms\n",
      "               cluster_dist\n",
      "index                      \n",
      "deleted_*          0.483710\n",
      "deleted_be         0.542814\n",
      "remove_*           0.551680\n",
      "restored_*         0.560979\n",
      "deleted_was        0.577411\n",
      "deleted_not        0.580295\n",
      "deleted_is         0.586556\n",
      "find_can           0.586681\n",
      "remove_from        0.589373\n",
      "remove_please      0.591656\n",
      "\n",
      "context terms\n",
      "               cluster_dist\n",
      "index                      \n",
      "hello_*            0.617250\n",
      "restored_'ve       0.634718\n",
      "restored_*         0.635371\n",
      "hello>*            0.662584\n",
      "restored_have      0.666999\n",
      "replaced_with      0.673871\n",
      "since>*            0.675255\n",
      "replaced_*         0.679293\n",
      "tag_*              0.693324\n",
      "provided_*         0.694144\n",
      "\n",
      "\n",
      "utterances\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 116734 0.471 also ... you deleted mention in the body of at least one bio of the fact that the person was Jewish.  Please RV all such deletions, or let me know why you do not wish to do so.  Thanks. --\n",
      "> 111384 0.473 To clarify, [[WP:G4]] only applies to articles deleted per a [[WP:XFD|deletion discussion]], not those deleted via [[WP:CSD]]. Cheers \\u2014\n",
      "> 373927 0.474 the article was deleted due to copyright infringement. OTRS has received permission from the copyright holder under CC-by-sa-3.0 to use the material. If you have OTRS access, please consult ticket# 20\n",
      "> 23238 0.475 I know you've managed to deflect concerns about your userpage in the past, Timeshift, but I'm afraid it'll be best for everyone if you take GorillaWarfare's advice now, rather than taking this to an M\n",
      "> 490974 0.476 Hi. Please do not recreate \\\"WP:USER.pce3@ij.net\\\". Doing so constitutes recreation of deleted material and will be deleted on sight and may lead to blocking of your account. --PS2pcGAMER (talk) 10:59\n",
      "> 527977 0.478 The article was deleted at a second AfD nomination ([[Wikipedia:Articles for deletion\\/List of city nicknames (2nd nomination)]]). The result on that nomination was delete. If you want to contest the \n",
      "> 290756 0.480 The edit you made [http:\\/\\/en.wikipedia.org\\/w\\/index.php?title=Political_positions_of_Barack_Obama&diff=254112557&oldid=254098937 here] constitutes a misuse of the rollback feature, and I must ask y\n",
      "> 42967 0.481 The inclusionists, so far as I know, have won the culture war at XfD. If you have even two or three refs from any even semi-decent source, the article will not be deleted. Moreover, you can make a cas\n",
      "> 495307 0.482 The deletion log[http:\\/\\/en.wikipedia.org\\/w\\/index.php?title=Special:Log\\/delete&page=Bernadette_Sands_McKevitt] states ''deleted \\\"Bernadette Sands McKevitt\\\" (csd a7)'' - I have no idea what a ''c\n",
      "> 427636 0.482 You have your email turned off.  Therefore, you have to email me.  If you're referring to this: [[Wikipedia:Articles for deletion\\/Alexander MacGregor]], the result was '''no consensus'''.  Any inform\n",
      "\n",
      "context-utterances\n",
      ">> 344102 0.589 Hi Mrg. If you check out [[Latin alphabet]], you will see that this term is not restricted to the original Roman alphabet, but includes the close derivatives like German (with umlauts \\xe4,\\xdc,...), \n",
      ">> 263586 0.599 Hello. Well, everything needs to be verifiable. If the photograph says that it can be reproduced then I would advise that that permission also needs to be be uploaded and linked to. \n",
      ">> 517615 0.611 Thank you for warning me about 3rr. I was acting in goodwill as proposed by [[User:Kmccoy|kmccoy]]'s mediation, by substituting the compromise (temp) version of the article for the disputed one. All p\n",
      ">> 336908 0.616 Hi Mike, seriously, nothing personal. If I hadn't made the changes, somebody, eventually would have. I would recommend that you review some of Wikipedia's policy, guidelines and FAQs at [[WP:HELP]]. A\n",
      ">> 264359 0.616 Hi. <nowiki>{{nn-band}}<\\/nowiki> means \\\"non-notable band.\\\" Your article failed the criteria for inclusion outlined at [[WP:BAND]]. For inclusion, you MUST cite several reliable third party referenc\n",
      ">> 123827 0.626 Hello! It so happens that my mother (76 years old) was with him in the same class and remembers him very well. If you need any details on personnal basis that could clarify anything - just ask.  --\n",
      ">> 503563 0.626 Oh for heaven's sake you two. Stop bickering about the past. Homologeo, if some of the deleted material is worth discussing then discuss it. You don't need to restore old edits for that. If it is hard\n",
      ">> 532648 0.627 In that case, no problem. Page is restored. For proper formatting, I advise you to check some similar articles and try to format it in the similar way. Any by the way, if you upload a photo, you shoul\n",
      ">> 480730 0.629 Man was that ever. Ok, I will first review you edits to see what we need to do. If you don't have email set please do. Friday is also your coach and  I advise you to contact him to see if we can set u\n",
      ">> 117653 0.630 842U, I see that elsewhere you have recently directed this editor to [[WP:OWN]]. IIRC when a similar issue arose concerning this editor, [[User:Daniel_J._Leivick]] took a special interest in him and g\n",
      "\n",
      "====\n",
      "\n",
      "CLUSTER 3 3\n",
      "---\n",
      "terms\n",
      "           cluster_dist\n",
      "index                  \n",
      "is_*           0.558697\n",
      "is_there       0.564460\n",
      "is_not         0.576292\n",
      "is_is          0.591916\n",
      "even>*         0.593364\n",
      "seems_to       0.600885\n",
      "'s_not         0.609943\n",
      "what>*         0.614863\n",
      "are_not        0.617335\n",
      "mean_does      0.617859\n",
      "\n",
      "context terms\n",
      "           cluster_dist\n",
      "index                  \n",
      "to>*           0.631598\n",
      "has_*          0.631947\n",
      "is_*           0.650184\n",
      "as>*           0.660322\n",
      "is_fine        0.662922\n",
      "in>*           0.668126\n",
      "is_to          0.669242\n",
      "is_see         0.678658\n",
      "because>*      0.689098\n",
      "makes_*        0.689591\n",
      "\n",
      "\n",
      "utterances\n",
      "> 531550 0.526 It is not that big of a deal or anything, but there are some college\\/university navbars that have unique fonts on the heading. The only reason I did it like that, is because that specific font is ver\n",
      "> 526290 0.531 Is the asterisk in the infobox a stray mark or does it mean something? \n",
      "> 356839 0.533 In the caption to this phote there is a small error. The word \\\"rebar\\\" is slang for reinforcement bar. What the workers are placing is not rebar but welded wire reinforcement, abbreviated WWR, someti\n",
      "> 559270 0.535 Deleting is not the most appropiate solution to the problem. Protecting the article, blocking the offending users and continued editing efforts are better solutions. \n",
      "> 332579 0.535 There is one important factor here: changing a category to a list is not a removal of information. \n",
      "> 61281 0.536 But lack of reliable sources for an article in the process of being written is not grounds for speedy deletion! \n",
      "> 189103 0.536 But Ireland is not in the World Cup. Extremely sexy 12:19, 25 June 2006 (UTC)\n",
      "> 133651 0.538 There is no cabal, and this is not a secret message. 000393DB396E. --\n",
      "> 178596 0.538 what a lot of utter (expletive deleted) - the order of the logic by the editor is fundamentally wrong and against the general intent of things work - add content and then verify is not how it works - \n",
      "> 134734 0.540 I think a reader expects a link to the authority when the link is so labelled as being to the authority. The unitary authority in this case ''is'' [[Cornwall Council]] - [[Cornwall]] is ''not'' a unit\n",
      "\n",
      "context-utterances\n",
      ">> 159825 0.613 For some reason, the original block failed, as it didn't register in the block log. But the good news is that the re-block succeeded. --\n",
      ">> 40914 0.622 Hehe, I'm relieved to see that the bot has very little idea of how I think - though the obvious articles related to Wikileaks are always interesting. ;)  I can see that after my editing the [[Critical\n",
      ">> 210360 0.626 And giving that terminology too much weight. That is all my complaint is.\n",
      ">> 280606 0.626 Paper33d was protesting Morwen's warnings (plural) and clearly not understanding the issue when I added my first note, which was explanatory and '''not''' a warning. The policy against blanking talk p\n",
      ">> 197116 0.628 Do you have some further information on this? I know that &amp;ndash; is the  correct html source but the Wikipeda software does more than just displaying html. For example umlaut \\xe4 doesn't have to\n",
      ">> 505876 0.629 I understand that rule with the talk headers and I only do it as a minor edit when Im there doing other things.  The problem I have with that rule in general is that without the talk header newbys and\n",
      ">> 483934 0.631 And I hate to think he's a [[Dungeons & Dragons|D&D]] fan, but the only reference I can find to that term is in [[Nodwick]]. Go figure... -\n",
      ">> 275755 0.634 And \\u09b8\\u09cc\\u09ae\\u09cb is just my name in [[Bengali language|Bengali]]. --''\n",
      ">> 88155 0.637 As my German friends used to say ''Machs Nicth'' sp, makes no difference as long as a source supports whatever section they fall under. --\n",
      ">> 405770 0.637 In the spirit of good faith, of course, I will assume that this was a case of some overly fast twinkle-editing which resulted in a message going to the wrong person, which I will of course forgive, wi\n",
      "\n",
      "====\n",
      "\n",
      "CLUSTER 4 4\n",
      "---\n",
      "terms\n",
      "                cluster_dist\n",
      "index                       \n",
      "thinking_*          0.738030\n",
      "think_be            0.741211\n",
      "be_there            0.751830\n",
      "start_should        0.758371\n",
      "make_sure           0.759340\n",
      "thinking_about      0.760743\n",
      "what>do             0.765511\n",
      "thinking_'m         0.768603\n",
      "be_might            0.772642\n",
      "hmm>*               0.772663\n",
      "\n",
      "context terms\n",
      "           cluster_dist\n",
      "index                  \n",
      "split_*        0.798109\n",
      "turn_*         0.832830\n",
      "perhaps>*      0.835086\n",
      "then>*         0.837803\n",
      "but>if         0.845863\n",
      "think_yes      0.854162\n",
      "could_*        0.854613\n",
      "finish_*       0.858283\n",
      "tend_be        0.858555\n",
      "set_*          0.858626\n",
      "\n",
      "\n",
      "utterances\n",
      "> 344270 0.705 Maybe its a matter of definition. Where does \\\"uncomfortable\\\" go to \\\"painful\\\"? To be honest, my evidence is purely anecdotal - I was thinking about warm water mixers in showers. Modern ones often a\n",
      "> 157057 0.709 I agree about making an end-box version of the Holocaust infobox to be used in place of the sidebar version. I don't know a lot about infobox editing, however - though this might be an opportunity to \n",
      "> 563614 0.710 Poor [[User:Ron Ritzman|Ron Ritzman]]! &#9786;<p>I see that you blocked {{user|Frnnrthprd}}.  I, given [http:\\/\\/en.wikipedia.org\\/w\\/index.php?diff=390963663&oldid=390939755 this], which is BLP vanda\n",
      "> 389411 0.711 Hmm, you raise good arguments. If the material is posted directly on the talk page a header is indeed required. Thinking about it a bit. '''Yoenit''' (\n",
      "> 176895 0.711 Shouldn't it be formatted like another notability guideline, ala [[Wikipedia:Notability (people)]]? There might be a school one already? \\u2022 <span style=\\\"font-variant:small-caps\\\"><font color=\\\"#8\n",
      "> 399915 0.714 In other news . . . I'd been thinking of nominating one or two clueful people as administrator. These are people who've been beavering away ''writing articles'' and making informative contributions to\n",
      "> 27579 0.714 Also I would be curious what you think about the choices it makes about which symbols are suitble for rendering as simple html.  To me many things should probably include spaces that do not.  But issu\n",
      "> 487973 0.715 My best advice to you is that one should avoid getting caught up in the debates on the RfA, or worrying to much about this go-round.  While this RfA is unlikely to succeed, I think if you broaden your\n",
      "> 197697 0.719 You don't have infoboxes everywhere. If it is about inserting original script in normal articles, it might be better to have something like the IPA template and a font presented horizontally. If so, w\n",
      "> 492604 0.719 I would agree if it was clear that all of these categories should be treated the same.  That may well be the case.  There is also another interesting question raised here if you look at the parent cat\n",
      "\n",
      "context-utterances\n",
      ">> 271870 0.773 Maybe if the building has enough content then split it into an own separate article... <small style=\\\"font:bold 12px Courier New;display:inline;border:#009 1px dashed;padding:1px 6px 2px 7px;white-spa\n",
      ">> 191805 0.793 Ok, split. \n",
      ">> 337287 0.794 Then Buddha must love me :). Hey, no biggie here. Cheers and take care! --\n",
      ">> 577834 0.798 That's good to see that you've noticed some errors, I assume there could be many. I didn't create the content, I only split existing content from [[Mickey Mouse]] into a new article.  --  \n",
      ">> 96972 0.799 BTW, if the section gets too long, it can always be split off into a new article. \n",
      ">> 183800 0.801 Troublesome? Should I be donning my flameproof suit yet again? Argh! but thank you. Much to be done on Khokhar, I think. - \n",
      ">> 575632 0.805 Hire me to be your campaign manager. With any luck, we'd split the Republican vote right in half.\\u2014\n",
      ">> 48820 0.807 We agree that [http:\\/\\/www.os390-mvs.freesurf.fr\\/mvshist.htm MVS... a long history] is \\\"not a well-established source, it's just the readily available one\\\" (although it looks like it's written by \n",
      ">> 247277 0.810 Should I pass the pooh to Materialscientist who changed to the de-version? (No I won't) --\n",
      ">> 141862 0.812 FYI, the basketball coach navboxes for five of the six major conferences (ACC, Big Ten, Big XII, Pac-10, SEC) have now been upgraded.  Once we finish enhancing the Division I basketball navboxes and p\n",
      "\n",
      "====\n",
      "\n",
      "CLUSTER 5 5\n",
      "---\n",
      "terms\n",
      "            cluster_dist\n",
      "index                   \n",
      "reverted_*      0.610958\n",
      "report_*        0.618923\n",
      "revert_*        0.637270\n",
      "appears_*       0.650385\n",
      "explain_*       0.675527\n",
      "warned_*        0.682376\n",
      "think_did       0.685245\n",
      "for>*           0.687296\n",
      "was_not         0.687717\n",
      "welcome_to      0.689001\n",
      "\n",
      "context terms\n",
      "             cluster_dist\n",
      "index                    \n",
      "ignore_*         0.715005\n",
      "fixed_have       0.742801\n",
      "refused_*        0.746171\n",
      "accusing_*       0.759295\n",
      "apologize_*      0.765259\n",
      "handled_*        0.766994\n",
      "extended_*       0.767898\n",
      "continue_do      0.768159\n",
      "keeping_*        0.774206\n",
      "clarify_*        0.775986\n",
      "\n",
      "\n",
      "utterances\n",
      "> 279892 0.564 First of all, about edit - Eupator removed not only my edit but others. I have showed now on talkpage another neutral source to support my edit. But question is not about content but about behavior. A\n",
      "> 349468 0.569 And they are back again [http:\\/\\/en.wikipedia.org\\/w\\/index.php?title=Trigger_point&diff=213404241&oldid=213149905]. I reverted this time. --\n",
      "> 385865 0.572 Yes Fainites, direktor reverted all other users as well. And, no, C didn\\xb4t edit-warred this time, he only reverted direktor, who actually started edit-warring again, just as he continuosly does in \n",
      "> 364488 0.572 I have [[Totimoshi|restored the article]] with some text and refs. It's not much, but I believe that the notability has been established because the band has been reviewed by multiple unrelated public\n",
      "> 267363 0.577 Yes, there is a guideline, policy, or whatever. \\\"Requirement\\\" on Wikipedia is to strong a word. But it does say in [[WP:Footnotes]] or [[WP:CITE]] or someplace that a \\\"bunch of links at the bottom\\\n",
      "> 362856 0.578 You reverted the page four times, Sanders. That's a violation. \n",
      "> 214104 0.580 I've just noticed your hidden comment in this edit, [http:\\/\\/en.wikipedia.org\\/w\\/index.php?title=Will_Eisner&diff=next&oldid=171281643].  Please note such comments are counter to our policies on [[W\n",
      "> 476805 0.581 Thanks for your offer to unblock me. I would obviously have accepted your conditions but was so thoroughly disgusted by the ridiculousness of the block that I didn't even bother to sign in for a week \n",
      "> 153679 0.585 Yes, the latter certainly appears to be a breach of the traditional rights and also of Magna Carta - yet according to a judge interviewed on R4 the other night, it is precisely what Parliament has dec\n",
      "> 484395 0.585 I was going to be bold and \\\"fix\\\" this, but it appears that it will require an administrator change and I found that you had explicitly changed this stuff.   Can you please explain to me why DNS shou\n",
      "\n",
      "context-utterances\n",
      ">> 234254 0.686 Hi Harry<br> Yes, the National Jockey's Hall of Fame did exist at Pimlico and burnt to ground when [[Pimlico]]'s historic Clubhouse caught fire and then both ceased to exist. That was infact the build\n",
      ">> 569540 0.691 Eh?  I stopped using that '''ages''' ago, when first alerted to a problem!  My sig now links though to my talk page and contains no image or other html\\/wiki code. Regards, \n",
      ">> 573280 0.712 How is Gator1? I hope everything has worked out but I'm disappointed to have not seen some decisive stance taken by the [[User talk:Jimbo Wales#Gator1 stalked in the real world|wikipedia chief]]. I ho\n",
      ">> 215912 0.714 I sign off mostly all my comments with \\\"Thanks!\\\"  Just habbit I guess.  I apologize if I offended you by saying that. \n",
      ">> 408379 0.716 Just FYI, you struck almost your entire guide - which I think was an typo in the wikicode - so I [http:\\/\\/en.wikipedia.org\\/w\\/index.php?title=User:Heimstern\\/ACE2010&diff=400313994&oldid=400311822 f\n",
      ">> 441447 0.722 Ok, thx a lot. I corrected my mistake in RFC: [http:\\/\\/en.wikipedia.org\\/w\\/index.php?title=Wikipedia%3ARequests_for_comment%2FCollect&diff=284157460&oldid=284155997] He still violated terms of his u\n",
      ">> 513939 0.724 Okay, I accept that this case is analogous to species names. \n",
      ">> 327599 0.728 Your right I copied each page and then changed all the information to try and save time. Thanks for cleaning them up. \n",
      ">> 267445 0.729 I apparently sent you (and a some other people) the wrong stuff by mistake ! This whole FA thing is complicated and as it turns out the article is [http:\\/\\/en.wikipedia.org\\/wiki\\/Wikipedia:Featured_\n",
      ">> 431892 0.730 Apology accepted :) Okay, if the consensus is for there to be no hyphens, I'll accept that, though it still comes as a surprise, amd still doesn't explain why adverbs which don't end -ly aren't treate\n",
      "\n",
      "====\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ec_fw.print_clusters(k=10,corpus=wiki_corpus,max_chars=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "demo continues below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per our interpretation, we assign the following names to these clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ec_fw.set_cluster_names(['casual', 'coordination', \n",
    "              'procedures', 'contention',\n",
    "             'editing', 'moderation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utts</th>\n",
       "      <th>terms</th>\n",
       "      <th>context_utts</th>\n",
       "      <th>context_terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>casual</th>\n",
       "      <td>0.336966</td>\n",
       "      <td>0.195341</td>\n",
       "      <td>0.201834</td>\n",
       "      <td>0.205236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contention</th>\n",
       "      <td>0.097679</td>\n",
       "      <td>0.174233</td>\n",
       "      <td>0.202557</td>\n",
       "      <td>0.237722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coordination</th>\n",
       "      <td>0.348370</td>\n",
       "      <td>0.199721</td>\n",
       "      <td>0.136531</td>\n",
       "      <td>0.105293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>editing</th>\n",
       "      <td>0.019979</td>\n",
       "      <td>0.160892</td>\n",
       "      <td>0.225581</td>\n",
       "      <td>0.202943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moderation</th>\n",
       "      <td>0.097966</td>\n",
       "      <td>0.153724</td>\n",
       "      <td>0.118555</td>\n",
       "      <td>0.130136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>procedures</th>\n",
       "      <td>0.099040</td>\n",
       "      <td>0.116089</td>\n",
       "      <td>0.114942</td>\n",
       "      <td>0.118670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  utts     terms  context_utts  context_terms\n",
       "casual        0.336966  0.195341      0.201834       0.205236\n",
       "contention    0.097679  0.174233      0.202557       0.237722\n",
       "coordination  0.348370  0.199721      0.136531       0.105293\n",
       "editing       0.019979  0.160892      0.225581       0.202943\n",
       "moderation    0.097966  0.153724      0.118555       0.130136\n",
       "procedures    0.099040  0.116089      0.114942       0.118670"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ec_fw.print_cluster_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Application to analysis data\n",
    "\n",
    "We now use the comment types we've just derived to analyze a dataset containing conversations that eventually derail into toxic behavior, and conversations that stay on track throughout. We load this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OPTION 1: DOWNLOAD CORPUS \n",
    "# UNCOMMENT THESE LINES TO DOWNLOAD CORPUS\n",
    "# DATA_DIR = '<YOUR DIRECTORY>'\n",
    "# AWRY_CORPUS_PATH = download('conversations-gone-awry-corpus', data_dir=DATA_DIR)\n",
    "\n",
    "# OPTION 2: READ PREVIOUSLY-DOWNLOADED CORPUS FROM DISK\n",
    "# UNCOMMENT THIS LINE AND REPLACE WITH THE DIRECTORY WHERE THE TENNIS-CORPUS IS LOCATED\n",
    "# AWRY_CORPUS_PATH = '<YOUR DIRECTORY>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "awry_corpus = Corpus(AWRY_CORPUS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "awry_corpus = awry_corpus.filter_conversations_by(lambda convo: convo.meta['annotation_year'] == '2018')\n",
    "# here we filter to consider only the conversations from the original paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Speakers: 2010\n",
      "Number of Utterances: 6363\n",
      "Number of Conversations: 1168\n"
     ]
    }
   ],
   "source": [
    "awry_corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by extracting the same noun-less dependency parse arcs that we used when training the model, above. To do this, we need to load the dependency parses, and then apply a few additional transformers, below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "awry_corpus.load_info('utterance',['parsed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from demo_text_pipelines import wiki_arc_pipeline\n",
    "# see `demo_text_pipelines.py` in this demo's directory for details\n",
    "# in short, this pipeline will compute the dependency-parse arcs we use as input features,\n",
    "# but will skip over utterances for which these attributes already exist\n",
    "awry_corpus = wiki_arc_pipeline().transform(awry_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We represent the comments from the new dataset as tf-idf vectors, using the vocabulary and parameters we've derived over the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "awry_corpus = first_tfidf_obj.transform(awry_corpus)\n",
    "awry_corpus = second_tfidf_obj.transform(awry_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we apply the trained model to transform the new dataset. In particular, we annotate each comment with an attribute, `fw_clustering.cluster`, that denotes the comment type it's assigned to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "awry_corpus = ec_fw.transform(awry_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To facilitate subsequent analyses, we will gather the comment types for each comment into a table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_assign_df = awry_corpus.get_attribute_table('utterance',['fw_clustering.cluster_id_'])\n",
    "type_assignments = np.zeros((len(cluster_assign_df), 6))\n",
    "type_assignments[np.arange(len(cluster_assign_df)),cluster_assign_df['fw_clustering.cluster_id_'].values.astype(int)] = 1\n",
    "cluster_assign_df = pd.DataFrame(columns=np.arange(6), index=cluster_assign_df.index, data=type_assignments)\n",
    "cluster_assign_df.columns = ec_fw.get_cluster_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>casual</th>\n",
       "      <th>coordination</th>\n",
       "      <th>procedures</th>\n",
       "      <th>contention</th>\n",
       "      <th>editing</th>\n",
       "      <th>moderation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146743638.12652.12652</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146743638.12667.12652</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146842219.12874.12874</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146860774.13072.13072</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143890867.11926.11926</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       casual  coordination  procedures  contention  editing  \\\n",
       "id                                                                             \n",
       "146743638.12652.12652     0.0           0.0         0.0         0.0      1.0   \n",
       "146743638.12667.12652     1.0           0.0         0.0         0.0      0.0   \n",
       "146842219.12874.12874     1.0           0.0         0.0         0.0      0.0   \n",
       "146860774.13072.13072     1.0           0.0         0.0         0.0      0.0   \n",
       "143890867.11926.11926     0.0           0.0         0.0         0.0      1.0   \n",
       "\n",
       "                       moderation  \n",
       "id                                 \n",
       "146743638.12652.12652         0.0  \n",
       "146743638.12667.12652         0.0  \n",
       "146842219.12874.12874         0.0  \n",
       "146860774.13072.13072         0.0  \n",
       "143890867.11926.11926         0.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_assign_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analysis: comparing comment types in awry versus on-track conversations\n",
    "\n",
    "We start by preprocessing the data, to facilitate our comparison of awry versus on-track conversations. Ultimately, we will compare the occurrence of comment types in the first and second comments of these discussions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first, we need to directly map comment IDs to their conversations. We'll build a DataFrame to do this\n",
    "comment_ids = []\n",
    "convo_ids = []\n",
    "timestamps = []\n",
    "page_ids = []\n",
    "for conversation in awry_corpus.iter_conversations():\n",
    "    for comment in conversation.iter_utterances():\n",
    "        # section headers are included in the dataset for completeness, but for prediction we need to ignore\n",
    "        # them as they are not utterances\n",
    "        if not comment.meta[\"is_section_header\"]:\n",
    "            comment_ids.append(comment.id)\n",
    "            convo_ids.append(comment.root)\n",
    "            timestamps.append(comment.timestamp)\n",
    "            page_ids.append(conversation.meta[\"page_id\"])\n",
    "comment_df = pd.DataFrame({\"conversation_id\": convo_ids, \"timestamp\": timestamps, \"page_id\": page_ids}, index=comment_ids)\n",
    "\n",
    "# we'll do our construction using awry conversation ID's as the reference key\n",
    "awry_convo_ids = set()\n",
    "# these dicts will then all be keyed by awry ID\n",
    "good_convo_map = {}\n",
    "page_id_map = {}\n",
    "for conversation in awry_corpus.iter_conversations():\n",
    "    if conversation.meta[\"conversation_has_personal_attack\"] and conversation.id not in awry_convo_ids:\n",
    "        awry_convo_ids.add(conversation.id)\n",
    "        good_convo_map[conversation.id] = conversation.meta[\"pair_id\"]\n",
    "        page_id_map[conversation.id] = conversation.meta[\"page_id\"]\n",
    "awry_convo_ids = list(awry_convo_ids)\n",
    "pairs_df = pd.DataFrame({\"bad_conversation_id\": awry_convo_ids,\n",
    "                         \"conversation_id\": [good_convo_map[cid] for cid in awry_convo_ids],\n",
    "                         \"page_id\": [page_id_map[cid] for cid in awry_convo_ids]})\n",
    "# finally, we will augment the pairs dataframe with the IDs of the first and second comment for both\n",
    "# the bad and good conversation. This will come in handy for constructing the feature matrix.\n",
    "first_ids = []\n",
    "second_ids = []\n",
    "first_ids_bad = []\n",
    "second_ids_bad = []\n",
    "for row in pairs_df.itertuples():\n",
    "    # \"first two\" is defined in terms of time of posting\n",
    "    comments_sorted = comment_df[comment_df.conversation_id==row.conversation_id].sort_values(by=\"timestamp\")\n",
    "    first_ids.append(comments_sorted.iloc[0].name)\n",
    "    second_ids.append(comments_sorted.iloc[1].name)\n",
    "    comments_sorted_bad = comment_df[comment_df.conversation_id==row.bad_conversation_id].sort_values(by=\"timestamp\")\n",
    "    first_ids_bad.append(comments_sorted_bad.iloc[0].name)\n",
    "    second_ids_bad.append(comments_sorted_bad.iloc[1].name)\n",
    "pairs_df = pairs_df.assign(first_id=first_ids, second_id=second_ids, \n",
    "                           bad_first_id=first_ids_bad, bad_second_id=second_ids_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tox_first_comment_features =pairs_df[['bad_first_id']].join(cluster_assign_df, how='left', on='bad_first_id')[cluster_assign_df.columns]\n",
    "ntox_first_comment_features =pairs_df[['first_id']].join(cluster_assign_df, how='left', on='first_id')[cluster_assign_df.columns]\n",
    "\n",
    "tox_second_comment_features =pairs_df[['bad_second_id']].join(cluster_assign_df, how='left', on='bad_second_id')[cluster_assign_df.columns]\n",
    "ntox_second_comment_features =pairs_df[['second_id']].join(cluster_assign_df, how='left', on='second_id')[cluster_assign_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute log-odds ratios of each comment type, comparing the awry and on-track conversations. We will also compute significance values from binomal tests comparing the proportion of awry-turning conversations exhibiting a particular comment type to the proportion of on-track conversations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_p_stars(x):\n",
    "    if x < .001: return '***'\n",
    "    elif x < .01: return '**'\n",
    "    elif x < .05: return '*'\n",
    "    else: return ''\n",
    "def compare_tox(df_ntox, df_tox,  min_n=0):\n",
    "    cols = df_ntox.columns\n",
    "    num_feats_in_tox = df_tox[cols].sum().astype(int).rename('num_feat_tox')\n",
    "    num_nfeats_in_tox = (1 - df_tox[cols]).sum().astype(int).rename('num_nfeat_tox')\n",
    "    num_feats_in_ntox = df_ntox[cols].sum().astype(int).rename('num_feat_ntox')\n",
    "    num_nfeats_in_ntox = (1 - df_ntox[cols]).sum().astype(int).rename('num_nfeat_ntox')\n",
    "    prop_tox = df_tox[cols].mean().rename('prop_tox')\n",
    "    ref_prop_ntox = df_ntox[cols].mean().rename('prop_ntox')\n",
    "    n_tox = len(df_tox)\n",
    "    df = pd.concat([\n",
    "        num_feats_in_tox, \n",
    "        num_nfeats_in_tox,\n",
    "        num_feats_in_ntox,\n",
    "        num_nfeats_in_ntox,\n",
    "        prop_tox,\n",
    "        ref_prop_ntox,\n",
    "    ], axis=1)\n",
    "    df['num_total'] = df.num_feat_tox + df.num_feat_ntox\n",
    "    df['log_odds'] = np.log(df.num_feat_tox) - np.log(df.num_nfeat_tox) \\\n",
    "        + np.log(df.num_nfeat_ntox) - np.log(df.num_feat_ntox)\n",
    "    df['abs_log_odds'] = np.abs(df.log_odds)\n",
    "    df['binom_p'] = df.apply(lambda x: stats.binom_test(x.num_feat_tox, n_tox, x.prop_ntox), axis=1)#*5\n",
    "    df = df[df.num_total >= min_n]\n",
    "    df['p'] = df['binom_p'].apply(lambda x: '%.3f' % x)\n",
    "    df['pstars'] = df['binom_p'].apply(get_p_stars)\n",
    "    return df.sort_values('log_odds', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_comparisons = compare_tox(ntox_first_comment_features, tox_first_comment_features)\n",
    "second_comparisons = compare_tox(ntox_second_comment_features, tox_second_comment_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the resultant log-odds ratios, we note some differences in which types of comments tend to start awry versus on track discussions: _contentious_ comments tend to signal future troubles, while _coordinating_ work is a signal that the conversation will remain civil throughout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we are now ready to plot these comparisons. the following (rather intimidating) helper function \n",
    "# produces a nicely-formatted plot:\n",
    "def draw_figure(ax, first_cmp, second_cmp, title='', prompt_types=6, min_log_odds=.2, min_freq=50,xlim=.85):\n",
    "\n",
    "    # selecting and sorting the features to plot, given minimum effect sizes and statistical significance\n",
    "    frequent_feats = first_cmp[first_cmp.num_total >= min_freq].index.union(second_cmp[second_cmp.num_total >= min_freq].index)\n",
    "    lrg_effect_feats = first_cmp[(first_cmp.abs_log_odds >= .2)\n",
    "                                & (first_cmp.binom_p < .05)].index.union(second_cmp[(second_cmp.abs_log_odds >= .2)\n",
    "                                                                                  & (second_cmp.binom_p < .05)].index)\n",
    "#     feats_to_include = frequent_feats.intersection(lrg_effect_feats)\n",
    "    feats_to_include = first_cmp.index\n",
    "    feat_order = sorted(feats_to_include, key=lambda x: first_cmp.loc[x].log_odds, reverse=True)\n",
    "\n",
    "    # parameters determining the look of the figure\n",
    "    colors = ['blue', 'grey']\n",
    "    shapes = ['^', 's']    \n",
    "    eps = .02\n",
    "    star_eps = .035\n",
    "    xlim = xlim\n",
    "    min_log = .2\n",
    "    gap_prop = 2\n",
    "    label_size = 14\n",
    "    title_size=18\n",
    "    radius = 256\n",
    "    features = feat_order\n",
    "    ax.invert_yaxis()\n",
    "    ax.plot([0,0], [0, len(features)/gap_prop], color='black')\n",
    "    \n",
    "    # for each figure we plot the point according to effect size in the first and second comment, \n",
    "    # and add axis labels denoting statistical significance\n",
    "    yticks = []\n",
    "    yticklabels = []\n",
    "    for f_idx, feat in enumerate(features):\n",
    "        curr_y = (f_idx + .5)/gap_prop\n",
    "        yticks.append(curr_y)\n",
    "        try:\n",
    "            \n",
    "            first_p = first_cmp.loc[feat].binom_p\n",
    "            second_p = second_cmp.loc[feat].binom_p            \n",
    "            if first_cmp.loc[feat].abs_log_odds < min_log:\n",
    "                first_face = \"white\"\n",
    "            elif first_p >= 0.05:\n",
    "                first_face = 'white'\n",
    "            else:\n",
    "                first_face = colors[0]\n",
    "            if second_cmp.loc[feat].abs_log_odds < min_log:\n",
    "                second_face = \"white\"\n",
    "            elif second_p >= 0.05:\n",
    "                second_face = 'white'\n",
    "            else:\n",
    "                second_face = colors[1]\n",
    "            ax.plot([-1 * xlim, xlim], [curr_y, curr_y], '--', color='grey', zorder=0, linewidth=.5)\n",
    "            \n",
    "            ax.scatter([first_cmp.loc[feat].log_odds], [curr_y + eps], s=radius, edgecolor=colors[0], marker=shapes[0],\n",
    "                        zorder=20, facecolors=first_face)\n",
    "            ax.scatter([second_cmp.loc[feat].log_odds], [curr_y + eps], s=radius, edgecolor=colors[1], marker=shapes[1], \n",
    "                       zorder=10, facecolors=second_face)\n",
    "            \n",
    "            first_pstr_len = len(get_p_stars(first_p))\n",
    "            second_pstr_len = len(get_p_stars(second_p))\n",
    "            p_str = np.array([' '] * 8)\n",
    "            if first_pstr_len > 0:\n",
    "                p_str[:first_pstr_len] = '*'\n",
    "            if second_pstr_len > 0:\n",
    "                p_str[-second_pstr_len:] = '⁺'\n",
    "            \n",
    "            feat_str = str(feat) + '\\n' + ''.join(p_str)\n",
    "            yticklabels.append(feat_str)\n",
    "        except Exception as e:\n",
    "            yticklabels.append('')\n",
    "    \n",
    "    # add the axis labels\n",
    "    ax.set_xlabel('log-odds ratio', fontsize=28)\n",
    "    ax.set_xticks([-xlim-.05, -.5, 0, .5, xlim])\n",
    "    ax.set_xticklabels(['on-track', -.5, 0, .5, 'awry'], fontsize=24)\n",
    "    ax.set_yticks(yticks)\n",
    "    ax.set_yticklabels(yticklabels, fontsize=32)\n",
    "    ax.tick_params(axis='both',  which='both', bottom='off',  top='off',left='off')\n",
    "    return feat_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAw8AAAJwCAYAAADP3112AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMzOzSv4/SKIiI+B7dakAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(1,1, figsize=(10,10))\n",
    "_ = draw_figure(ax, first_comparisons, second_comparisons, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pipeline usage\n",
    "\n",
    "We can also apply the framework via a pipeline that handles the following:\n",
    "* processes text (via a pipeline supplied by the user; see cell below)\n",
    "* transforms text to input representation (via `ColNormedTfidfTransformer`)\n",
    "* derives framework output (via `ExpectedContextModelTransformer`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from convokit.expected_context_framework import ExpectedContextModelPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize the pipeline with the following arguments:\n",
    "* `text_field` specifies which utterance metadata field to use as text input.\n",
    "* `share_tfidf_models` indicates whether we want to train one `ColNormedTfidfTransformer` model for both utterances and context-utterances. In this case, since we want different input representations for first and second comments, we set this argument to `False`.\n",
    "* `text_pipe` specifies the pipeline used to compute the contents of `text_field`\n",
    "* `tfidf_params` specifies the parameters to be passed into the underlying `ColNormedTfidfTransformer` object\n",
    "* `min_terms` specifies the minimum number of terms in the vocabulary that an utterance must contain for it to be considered in fitting and transforming the underlying `ExpectedContextModelTransformer` object (see the `selector` argument passed into `ec_fw.fit` above)\n",
    "\n",
    "All other arguments are inherited from `ExpectedContextModelTransformer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fw_pipe = ExpectedContextModelPipeline(context_field='next_id', output_prefix='fw',\n",
    "        text_field='arcs', share_tfidf_models=False,\n",
    "        text_pipe=wiki_arc_pipeline(), \n",
    "        tfidf_params={'binary': True, 'min_df': 50}, \n",
    "        min_terms=1,\n",
    "        n_svd_dims=25, n_clusters=6, cluster_on='terms',\n",
    "        random_state=1000, cluster_random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fw_pipe.fit(wiki_corpus,\n",
    "            selector=lambda x: x.meta.get('next_id',None) is not None,\n",
    "            context_selector=lambda x: x.reply_to is not None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should produce the same output as calling the constituent steps separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLUSTER 0 0\n",
      "---\n",
      "terms\n",
      "           cluster_dist\n",
      "index                  \n",
      "'m_*           0.497348\n",
      "thought_*      0.498929\n",
      "guess_*        0.508338\n",
      "sorry>*        0.521577\n",
      "know_*         0.526687\n",
      "had_*          0.531728\n",
      "got_*          0.537593\n",
      "'s_*           0.543810\n",
      "have>*         0.544413\n",
      "saw_*          0.549280\n",
      "\n",
      "context terms\n",
      "          cluster_dist\n",
      "index                 \n",
      "saw_*         0.598228\n",
      "yes>*         0.603147\n",
      "knew_*        0.607990\n",
      "but>*         0.614208\n",
      "oh>*          0.615937\n",
      "anyway>*      0.619059\n",
      "hey>*         0.620055\n",
      "guess_*       0.620307\n",
      "oh_*          0.635252\n",
      "and>*         0.639936\n",
      "\n",
      "CLUSTER 1 1\n",
      "---\n",
      "terms\n",
      "              cluster_dist\n",
      "index                     \n",
      "let_*             0.507374\n",
      "done_*            0.509473\n",
      "appreciate_*      0.512464\n",
      "tried_*           0.524234\n",
      "help_*            0.530647\n",
      "let_know          0.536958\n",
      "look_*            0.540756\n",
      "hi>*              0.545773\n",
      "hi_*              0.548464\n",
      "take_*            0.549002\n",
      "\n",
      "context terms\n",
      "               cluster_dist\n",
      "index                      \n",
      "okay>*             0.641118\n",
      "ok>*               0.646864\n",
      "alright>*          0.653850\n",
      "uploaded_have      0.670640\n",
      "update_*           0.681726\n",
      "ok_*               0.683843\n",
      "helps_*            0.705702\n",
      "cool>*             0.707850\n",
      "cool_*             0.709546\n",
      "hope_do            0.712557\n",
      "\n",
      "CLUSTER 2 2\n",
      "---\n",
      "terms\n",
      "               cluster_dist\n",
      "index                      \n",
      "deleted_*          0.483710\n",
      "deleted_be         0.542814\n",
      "remove_*           0.551680\n",
      "restored_*         0.560979\n",
      "deleted_was        0.577411\n",
      "deleted_not        0.580295\n",
      "deleted_is         0.586556\n",
      "find_can           0.586681\n",
      "remove_from        0.589373\n",
      "remove_please      0.591656\n",
      "\n",
      "context terms\n",
      "               cluster_dist\n",
      "index                      \n",
      "hello_*            0.617250\n",
      "restored_'ve       0.634718\n",
      "restored_*         0.635371\n",
      "hello>*            0.662584\n",
      "restored_have      0.666999\n",
      "replaced_with      0.673871\n",
      "since>*            0.675255\n",
      "replaced_*         0.679293\n",
      "tag_*              0.693324\n",
      "provided_*         0.694144\n",
      "\n",
      "CLUSTER 3 3\n",
      "---\n",
      "terms\n",
      "           cluster_dist\n",
      "index                  \n",
      "is_*           0.558697\n",
      "is_there       0.564460\n",
      "is_not         0.576292\n",
      "is_is          0.591916\n",
      "even>*         0.593364\n",
      "seems_to       0.600885\n",
      "'s_not         0.609943\n",
      "what>*         0.614863\n",
      "are_not        0.617335\n",
      "mean_does      0.617859\n",
      "\n",
      "context terms\n",
      "           cluster_dist\n",
      "index                  \n",
      "to>*           0.631598\n",
      "has_*          0.631947\n",
      "is_*           0.650184\n",
      "as>*           0.660322\n",
      "is_fine        0.662922\n",
      "in>*           0.668126\n",
      "is_to          0.669242\n",
      "is_see         0.678658\n",
      "because>*      0.689098\n",
      "makes_*        0.689591\n",
      "\n",
      "CLUSTER 4 4\n",
      "---\n",
      "terms\n",
      "                cluster_dist\n",
      "index                       \n",
      "thinking_*          0.738030\n",
      "think_be            0.741211\n",
      "be_there            0.751830\n",
      "start_should        0.758371\n",
      "make_sure           0.759340\n",
      "thinking_about      0.760743\n",
      "what>do             0.765511\n",
      "thinking_'m         0.768603\n",
      "be_might            0.772642\n",
      "hmm>*               0.772663\n",
      "\n",
      "context terms\n",
      "           cluster_dist\n",
      "index                  \n",
      "split_*        0.798109\n",
      "turn_*         0.832830\n",
      "perhaps>*      0.835086\n",
      "then>*         0.837803\n",
      "but>if         0.845863\n",
      "think_yes      0.854162\n",
      "could_*        0.854613\n",
      "finish_*       0.858283\n",
      "tend_be        0.858555\n",
      "set_*          0.858626\n",
      "\n",
      "CLUSTER 5 5\n",
      "---\n",
      "terms\n",
      "            cluster_dist\n",
      "index                   \n",
      "reverted_*      0.610958\n",
      "report_*        0.618923\n",
      "revert_*        0.637270\n",
      "appears_*       0.650385\n",
      "explain_*       0.675527\n",
      "warned_*        0.682376\n",
      "think_did       0.685245\n",
      "for>*           0.687296\n",
      "was_not         0.687717\n",
      "welcome_to      0.689001\n",
      "\n",
      "context terms\n",
      "             cluster_dist\n",
      "index                    \n",
      "ignore_*         0.715005\n",
      "fixed_have       0.742801\n",
      "refused_*        0.746171\n",
      "accusing_*       0.759295\n",
      "apologize_*      0.765259\n",
      "handled_*        0.766994\n",
      "extended_*       0.767898\n",
      "continue_do      0.768159\n",
      "keeping_*        0.774206\n",
      "clarify_*        0.775986\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fw_pipe.ec_model.print_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fw_pipe.set_cluster_names(['casual', 'coordination', \n",
    "              'procedures', 'contention',\n",
    "             'editing', 'moderation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline enables us to transform ad-hoc string input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_ut = fw_pipe.transform_utterance('Let me help you out with that')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: coordination\n"
     ]
    }
   ],
   "source": [
    "print('type:', new_ut.meta['fw_clustering.cluster'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, instead of storing vector representations with a corpus, the pipeline writes these representations to a field in the utterance metadata itself (since the utterance is not attached to a corpus):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.34251719530565966,\n",
       " 0.02658927446810624,\n",
       " -0.01927147734336277,\n",
       " 0.032577912301350556,\n",
       " -0.22583186273707992,\n",
       " 0.3726452662095833,\n",
       " 0.19622014569623866,\n",
       " -0.10407111691341157,\n",
       " -0.29038262872096327,\n",
       " -0.014681640364270429,\n",
       " 0.16817088225571575,\n",
       " 0.13965716231892997,\n",
       " -0.19330007418977502,\n",
       " 0.335512083137985,\n",
       " -0.04301223983724843,\n",
       " -0.10041294183984298,\n",
       " 0.3141634142240819,\n",
       " 0.004730871157014037,\n",
       " -0.4032757831822109,\n",
       " -0.14092188454058427,\n",
       " -0.1225539502059763,\n",
       " 0.009954456070505423,\n",
       " 0.06985947800825029,\n",
       " -0.21434796397126002]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note that different versions of SpaCy may produce different outputs, since the\n",
    "# dependency parses may change from version to version\n",
    "new_ut.meta['fw_repr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
