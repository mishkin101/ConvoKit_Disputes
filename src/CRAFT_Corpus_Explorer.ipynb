{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from tqdm import tqdm\n",
    "\n",
    "from convokit import Corpus, download\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading conversations-gone-awry-corpus to /Users/mishkin/Desktop/Research/Convo_Kit/ConvoKit_Disputes/data/convokit_datasets/conversations-gone-awry-corpus\n",
      "Downloading conversations-gone-awry-corpus from http://zissou.infosci.cornell.edu/convokit/datasets/conversations-gone-awry-corpus/conversations-gone-awry-corpus.zip (45.2MB)... Done\n",
      "Downloading conversations-gone-awry-cmv-corpus to /Users/mishkin/Desktop/Research/Convo_Kit/ConvoKit_Disputes/data/convokit_datasets/conversations-gone-awry-cmv-corpus\n",
      "Downloading conversations-gone-awry-cmv-corpus from http://zissou.infosci.cornell.edu/convokit/datasets/conversations-gone-awry-cmv-corpus/conversations-gone-awry-cmv-corpus.zip (51.5MB)... Done\n"
     ]
    }
   ],
   "source": [
    "# Load the corpus\n",
    "from convokit import Corpus, download\n",
    "\n",
    "\n",
    "wiki_path = download(\"conversations-gone-awry-corpus\", data_dir = \"/Users/mishkin/Desktop/Research/Convo_Kit/ConvoKit_Disputes/data/convokit_datasets\")\n",
    "cmv_path  = download(\"conversations-gone-awry-cmv-corpus\", data_dir= \"/Users/mishkin/Desktop/Research/Convo_Kit/ConvoKit_Disputes/data/convokit_datasets\")\n",
    "corpus_w = Corpus(wiki_path)\n",
    "corpus_cmv = Corpus(cmv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kodis_corp = corpus_converter.test_corp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic stats\n",
    "print(\"Speakers:\", len(list(corpus.iter_speakers())))\n",
    "print(\"Conversations:\", len(list(corpus.iter_conversations())))\n",
    "print(\"Utterances:\", len(list(corpus.iter_utterances())))\n",
    "\n",
    "# Utterances per conversation\n",
    "utterance_counts = [len(list(c.iter_utterances())) for c in corpus.iter_conversations()]\n",
    "plt.hist(utterance_counts, bins=30)\n",
    "plt.title(\"Distribution of Utterances per Conversation\")\n",
    "plt.xlabel(\"Utterances\")\n",
    "plt.ylabel(\"Number of Conversations\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Conversations with removed final comments\n",
    "removed = [c.meta.get(\"has_removed_comment\", False) for c in corpus.iter_conversations()]\n",
    "pd.Series(removed).value_counts().plot(kind=\"bar\")\n",
    "plt.title(\"Final Comment Moderation\")\n",
    "plt.xticks([0, 1], [\"Not Removed\", \"Removed\"], rotation=0)\n",
    "plt.ylabel(\"Number of Conversations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the number of utterances per conversation\n",
    "conversation_lengths = [len(list(convo.iter_utterances())) for convo in corpus.iter_conversations()]\n",
    "\n",
    "# Compute average, median, and max\n",
    "average_length = np.mean(conversation_lengths)\n",
    "median_length = np.median(conversation_lengths)\n",
    "max_length = np.max(conversation_lengths)\n",
    "\n",
    "# Sample a few conversation structures\n",
    "sample_structures = {}\n",
    "for i, convo in enumerate(corpus.iter_conversations()):\n",
    "    if i >= 3: break  # Just look at 3 examples\n",
    "    utt_structure = [(utt.id, utt.reply_to) for utt in convo.iter_utterances()]\n",
    "    sample_structures[convo.id] = utt_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(average_length, median_length, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of conversations by number of unique speakers\n",
    "speaker_count_distribution = defaultdict(int)\n",
    "\n",
    "\n",
    "for convo in corpus.iter_conversations():\n",
    "    speaker_ids = {utt.speaker.id for utt in convo.iter_utterances()}\n",
    "    speaker_count_distribution[len(speaker_ids)] += 1\n",
    "\n",
    "# Sort for plotting\n",
    "sorted_counts = dict(sorted(speaker_count_distribution.items()))\n",
    "\n",
    "# Plot the distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(sorted_counts.keys(), sorted_counts.values(), color=\"blue\")\n",
    "plt.xlabel(\"Number of Unique Speakers in Conversation\")\n",
    "plt.ylabel(\"Number of Conversations\")\n",
    "plt.title(\"Distribution of Conversations by Number of Unique Speakers\")\n",
    "plt.xticks(list(sorted_counts.keys()))\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# List to store lengths of derailed conversations\n",
    "derailed_lengths = []\n",
    "\n",
    "for convo in corpus.iter_conversations():\n",
    "    if convo.meta.get(\"has_removed_comment\") == True:\n",
    "        num_utts = len(list(convo.iter_utterances()))\n",
    "        derailed_lengths.append(num_utts)\n",
    "\n",
    "# Compute average length before derailment\n",
    "average_derailment_length = np.mean(derailed_lengths)\n",
    "\n",
    "# Plot histogram of lengths\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(derailed_lengths, bins=range(1, max(derailed_lengths)+1), color=\"tomato\", edgecolor=\"black\", alpha=0.7)\n",
    "plt.title(\"Distribution of Conversation Lengths Before Derailment (CGA-CMV)\")\n",
    "plt.xlabel(\"Number of Utterances\")\n",
    "plt.ylabel(\"Number of Derailed Conversations\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "average_derailment_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from convokit import Corpus, download\n",
    "\n",
    "\n",
    "\n",
    "# Group all corpora\n",
    "corpora = {\n",
    "    \"CGA-CMV\": cmv_corpus,\n",
    "    \"CGA-WIKI\": wiki_corpus,\n",
    "    \"Test Corpus\": test_corp\n",
    "}\n",
    "\n",
    "fig, axs = plt.subplots(len(corpora), 4, figsize=(20, 12))\n",
    "fig.suptitle(\"Conversational Characteristics Across Corpora\", fontsize=16)\n",
    "\n",
    "for i, (label, corpus) in enumerate(corpora.items()):\n",
    "    # --- Plot 1: Distribution of Utterances per Conversation ---\n",
    "    utterance_counts = [len(list(c.iter_utterances())) for c in corpus.iter_conversations()]\n",
    "    axs[i, 0].hist(utterance_counts, bins=30, color=\"skyblue\", edgecolor=\"black\")\n",
    "    axs[i, 0].set_title(f\"{label}\\nUtterances per Conversation\")\n",
    "    axs[i, 0].set_xlabel(\"Utterances\")\n",
    "    axs[i, 0].set_ylabel(\"Conversations\")\n",
    "\n",
    "    # --- Plot 2: Final Comment Moderation ---\n",
    "    removed = [c.meta.get(\"has_removed_comment\", False) for c in corpus.iter_conversations()]\n",
    "    pd.Series(removed).value_counts().sort_index().plot(kind=\"bar\", ax=axs[i, 1], color=[\"gray\", \"red\"])\n",
    "    axs[i, 1].set_title(f\"{label}\\nFinal Comment Moderation\")\n",
    "    axs[i, 1].set_xticks([0, 1])\n",
    "    axs[i, 1].set_xticklabels([\"Not Removed\", \"Removed\"])\n",
    "    axs[i, 1].set_ylabel(\"Conversations\")\n",
    "\n",
    "    # --- Plot 3: Unique Speakers per Conversation ---\n",
    "    speaker_count_distribution = defaultdict(int)\n",
    "    for convo in corpus.iter_conversations():\n",
    "        speaker_ids = {utt.speaker.id for utt in convo.iter_utterances()}\n",
    "        speaker_count_distribution[len(speaker_ids)] += 1\n",
    "    sorted_counts = dict(sorted(speaker_count_distribution.items()))\n",
    "    axs[i, 2].bar(sorted_counts.keys(), sorted_counts.values(), color=\"blue\")\n",
    "    axs[i, 2].set_title(f\"{label}\\nSpeakers per Conversation\")\n",
    "    axs[i, 2].set_xlabel(\"Unique Speakers\")\n",
    "    axs[i, 2].set_ylabel(\"Conversations\")\n",
    "\n",
    "    # --- Plot 4: Lengths of Derailed Conversations ---\n",
    "    derailed_lengths = [\n",
    "        len(list(convo.iter_utterances()))\n",
    "        for convo in corpus.iter_conversations()\n",
    "        if convo.meta.get(\"has_removed_comment\") == True\n",
    "    ]\n",
    "    axs[i, 3].hist(\n",
    "        derailed_lengths,\n",
    "        bins=range(1, max(derailed_lengths) + 1 if derailed_lengths else 2),\n",
    "        color=\"tomato\",\n",
    "        edgecolor=\"black\"\n",
    "    )\n",
    "    axs[i, 3].set_title(f\"{label}\\nLength Before Derailment\")\n",
    "    axs[i, 3].set_xlabel(\"Utterances\")\n",
    "    axs[i, 3].set_ylabel(\"Derailed Conversations\")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
