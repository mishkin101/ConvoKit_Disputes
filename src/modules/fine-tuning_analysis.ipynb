{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis from KODIS Fine-Tuning on WIKI pre-trained corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import Corpus\n",
    "corpus_kodis_ground = Corpus(filename=\"/Users/mishkin/Desktop/Research/Convo_Kit/ConvoKit_Disputes/data/saved_corpora/corpus_kodis_ground_resuls\")\n",
    "corpus_no_last = Corpus(filename=\"/Users/mishkin/Desktop/Research/Convo_Kit/ConvoKit_Disputes/data/saved_corpora/corpus_kodis_no_last_resuls\")\n",
    "corpus_no_submit_last = Corpus(filename=\"/Users/mishkin/Desktop/Research/Convo_Kit/ConvoKit_Disputes/data/saved_corpora/corpus_kodis_no_last_submit_results\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.calibration import CalibrationDisplay\n",
    "\n",
    "# Replace these with your actual variables\n",
    "corpora_info = [\n",
    "    (\"KODIS_NO_SUBMIT_LAST\", corpus_kodis_no_submit_last, forecaster_kodis_ground, nolast_submit_metrics, no_submit_last_convo_df),\n",
    "    (\"KODIS_NO_LAST\",         corpus_kodis_no_last, forecaster_kodis_no_last, nolast_metrics,  nolast_conv_df),\n",
    "    (\"KODIS_GROUND\",          corpus_kodis_ground,forecaster_kodis_no_last_submit, ground_metrics, ground_conv_df),\n",
    "]\n",
    "\n",
    "n_rows = 5\n",
    "n_cols = len(corpora_info)\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(5 * n_cols, 3 * n_rows))\n",
    "fig.suptitle(\"Comparison Across KODIS Variants\", fontsize=18)\n",
    "\n",
    "for col, (label, corpus, forecaster, metrics, conv_df) in enumerate(corpora_info):\n",
    "    # Row 0: Average conversation length\n",
    "    lengths = [\n",
    "        len(convo.get_utterance_ids())\n",
    "        for convo in corpus.iter_conversations()\n",
    "        if convo.meta.get(\"split\") == \"test\"\n",
    "    ]\n",
    "    avg_len = np.mean(lengths)\n",
    "    ax0 = axes[0, col]\n",
    "    ax0.bar([0], [avg_len])\n",
    "    ax0.set_xticks([])\n",
    "    ax0.set_title(f\"{label}\\nAvg Length: {avg_len:.1f}\")\n",
    "\n",
    "    # Row 1: Calibration curve\n",
    "    ax1 = axes[1, col]\n",
    "    y_true = conv_df[\"forecast\"]\n",
    "    y_prob = conv_df[\"score\"]\n",
    "    CalibrationDisplay.from_predictions(\n",
    "        y_true=y_true,\n",
    "        y_prob=y_prob,\n",
    "        n_bins=10,\n",
    "        name=label,\n",
    "        ax=ax1\n",
    "    )\n",
    "    ax1.set_title(f\"Calibration Curve for {label}\")\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Row 2: Probability histogram\n",
    "    ax2 = axes[2, col]\n",
    "    bins_prob = np.linspace(0, 1, 11)\n",
    "    ax2.hist(y_prob, bins=bins_prob, edgecolor='k')\n",
    "    ax2.set_title(\"Probability Histogram\")\n",
    "    ax2.set_xlabel(\"Predicted Probability\")\n",
    "    ax2.set_ylabel(\"Count\")\n",
    "    ax2.grid(True)\n",
    "\n",
    "    # Row 3: Confusion matrix\n",
    "    ax3 = axes[3, col]\n",
    "    y_pred = conv_df[\"forecast\"]\n",
    "    ConfusionMatrixDisplay.from_predictions(\n",
    "        y_true=y_true,\n",
    "        y_pred=y_pred,\n",
    "        display_labels=[\"No Derail\", \"Derail\"],\n",
    "        cmap=\"Blues\",\n",
    "        ax=ax3\n",
    "    )\n",
    "    ax3.set_title(\"Confusion Matrix\")\n",
    "\n",
    "    # Row 4: Metrics summary text\n",
    "    ax4 = axes[4, col]\n",
    "    ax4.axis('off')\n",
    "    metrics_text = \"\\n\".join(f\"{k}: {v:.2f}\" for k, v in metrics.items())\n",
    "    ax4.text(0.5, 0.5, metrics_text, ha='center', va='center', fontsize=10)\n",
    "    ax4.set_title(\"Test Metrics Summary\")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
