<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>craft_fine_tuning_demo_using_convokit – My Forecaster Explorer</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-79108a0fc1995748cbd19a5b0e3e3e7c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">My Forecaster Explorer</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<p><a href="https://colab.research.google.com/github/mishkin101/ConvoKit_Disputes/blob/main/CRAFT_fine_tuning_demo_using_ConvoKit.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a></p>
<section id="craft-demo-fine-tuning-and-inference-using-convokit" class="level1">
<h1>CRAFT demo (fine-tuning and inference) using ConvoKit</h1>
<p>This example notebook shows how to fine-tune a pretrained CRAFT conversational model for the task of forecasting conversational derailment, as shown in the “Trouble on the Horizon” paper (note however that due to nondeterminism in the training process, the results will not exactly reproduce the ones shown in the paper; if you need the exact inference results from the paper, see the inference-only version of this notebook).</p>
<div id="cell-2" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># start by installing ConvoKit on the colab VM</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install <span class="op">-</span>q convokit</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-3" class="cell" data-outputid="a9d10e05-c6db-401f-a651-20bb60a3c095" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># import necessary libraries, including convokit</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.jit <span class="im">import</span> script, trace</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> optim</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sys</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> unicodedata</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> itertools</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> urllib.request <span class="im">import</span> urlretrieve</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> convokit <span class="im">import</span> download, Corpus</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-4" class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># define globals and constants</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>MAX_LENGTH <span class="op">=</span> <span class="dv">80</span>  <span class="co"># Maximum sentence length (number of tokens) to consider</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co"># configure model</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>hidden_size <span class="op">=</span> <span class="dv">500</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>encoder_n_layers <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>context_encoder_n_layers <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>decoder_n_layers <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>dropout <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Configure training/optimization</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>clip <span class="op">=</span> <span class="fl">50.0</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>teacher_forcing_ratio <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">1e-5</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>decoder_learning_ratio <span class="op">=</span> <span class="fl">5.0</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>print_every <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>train_epochs <span class="op">=</span> <span class="dv">30</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Default word tokens</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>PAD_token <span class="op">=</span> <span class="dv">0</span>  <span class="co"># Used for padding short sentences</span></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>SOS_token <span class="op">=</span> <span class="dv">1</span>  <span class="co"># Start-of-sentence token</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>EOS_token <span class="op">=</span> <span class="dv">2</span>  <span class="co"># End-of-sentence token</span></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>UNK_token <span class="op">=</span> <span class="dv">3</span>  <span class="co"># Unknown word token</span></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a><span class="co"># model download paths</span></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>WORD2INDEX_URL <span class="op">=</span> <span class="st">"http://zissou.infosci.cornell.edu/convokit/models/craft_wikiconv/word2index.json"</span></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>INDEX2WORD_URL <span class="op">=</span> <span class="st">"http://zissou.infosci.cornell.edu/convokit/models/craft_wikiconv/index2word.json"</span></span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>MODEL_URL <span class="op">=</span> <span class="st">"http://zissou.infosci.cornell.edu/convokit/models/craft_wikiconv/craft_pretrained.tar"</span></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a><span class="co"># confidence score threshold for declaring a positive prediction.</span></span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a><span class="co"># this value was previously learned on the validation set.</span></span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>FORECAST_THRESH <span class="op">=</span> <span class="fl">0.570617</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="part-1-set-up-data-conversion-utilities" class="level2">
<h2 class="anchored" data-anchor-id="part-1-set-up-data-conversion-utilities">Part 1: set up data conversion utilities</h2>
<p>We begin by setting up some helper functions and classes for converting conversational text data into a torch-friendly Tensor format. Note that these low-level routines are largely taken from the <a href="https://pytorch.org/tutorials/beginner/chatbot_tutorial.html">PyTorch seq2seq chatbot tutorial</a>.</p>
<div id="cell-6" class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Voc:</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""A class for representing the vocabulary used by a CRAFT model"""</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, name, word2index<span class="op">=</span><span class="va">None</span>, index2word<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.name <span class="op">=</span> name</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.trimmed <span class="op">=</span> <span class="va">False</span> <span class="cf">if</span> <span class="kw">not</span> word2index <span class="cf">else</span> <span class="va">True</span> <span class="co"># if a precomputed vocab is specified assume the user wants to use it as-is</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.word2index <span class="op">=</span> word2index <span class="cf">if</span> word2index <span class="cf">else</span> {<span class="st">"UNK"</span>: UNK_token}</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.word2count <span class="op">=</span> {}</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.index2word <span class="op">=</span> index2word <span class="cf">if</span> index2word <span class="cf">else</span> {PAD_token: <span class="st">"PAD"</span>, SOS_token: <span class="st">"SOS"</span>, EOS_token: <span class="st">"EOS"</span>, UNK_token: <span class="st">"UNK"</span>}</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_words <span class="op">=</span> <span class="dv">4</span> <span class="cf">if</span> <span class="kw">not</span> index2word <span class="cf">else</span> <span class="bu">len</span>(index2word)  <span class="co"># Count SOS, EOS, PAD, UNK</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> addSentence(<span class="va">self</span>, sentence):</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> word <span class="kw">in</span> sentence.split(<span class="st">' '</span>):</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.addWord(word)</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> addWord(<span class="va">self</span>, word):</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> word <span class="kw">not</span> <span class="kw">in</span> <span class="va">self</span>.word2index:</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.word2index[word] <span class="op">=</span> <span class="va">self</span>.num_words</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.word2count[word] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.index2word[<span class="va">self</span>.num_words] <span class="op">=</span> word</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.num_words <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.word2count[word] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Remove words below a certain count threshold</span></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> trim(<span class="va">self</span>, min_count):</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.trimmed:</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.trimmed <span class="op">=</span> <span class="va">True</span></span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>        keep_words <span class="op">=</span> []</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> k, v <span class="kw">in</span> <span class="va">self</span>.word2count.items():</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> v <span class="op">&gt;=</span> min_count:</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>                keep_words.append(k)</span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'keep_words </span><span class="sc">{}</span><span class="st"> / </span><span class="sc">{}</span><span class="st"> = </span><span class="sc">{:.4f}</span><span class="st">'</span>.<span class="bu">format</span>(</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>            <span class="bu">len</span>(keep_words), <span class="bu">len</span>(<span class="va">self</span>.word2index), <span class="bu">len</span>(keep_words) <span class="op">/</span> <span class="bu">len</span>(<span class="va">self</span>.word2index)</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>        ))</span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Reinitialize dictionaries</span></span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.word2index <span class="op">=</span> {<span class="st">"UNK"</span>: UNK_token}</span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.word2count <span class="op">=</span> {}</span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.index2word <span class="op">=</span> {PAD_token: <span class="st">"PAD"</span>, SOS_token: <span class="st">"SOS"</span>, EOS_token: <span class="st">"EOS"</span>, UNK_token: <span class="st">"UNK"</span>}</span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_words <span class="op">=</span> <span class="dv">4</span> <span class="co"># Count default tokens</span></span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> word <span class="kw">in</span> keep_words:</span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.addWord(word)</span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a Voc object from precomputed data structures</span></span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> loadPrecomputedVoc(corpus_name, word2index_url, index2word_url):</span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a>    <span class="co"># load the word-to-index lookup map</span></span>
<span id="cb4-53"><a href="#cb4-53" aria-hidden="true" tabindex="-1"></a>    r <span class="op">=</span> requests.get(word2index_url)</span>
<span id="cb4-54"><a href="#cb4-54" aria-hidden="true" tabindex="-1"></a>    word2index <span class="op">=</span> r.json()</span>
<span id="cb4-55"><a href="#cb4-55" aria-hidden="true" tabindex="-1"></a>    <span class="co"># load the index-to-word lookup map</span></span>
<span id="cb4-56"><a href="#cb4-56" aria-hidden="true" tabindex="-1"></a>    r <span class="op">=</span> requests.get(index2word_url)</span>
<span id="cb4-57"><a href="#cb4-57" aria-hidden="true" tabindex="-1"></a>    index2word <span class="op">=</span> r.json()</span>
<span id="cb4-58"><a href="#cb4-58" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Voc(corpus_name, word2index, index2word)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-7" class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Helper functions for preprocessing and tokenizing text</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Turn a Unicode string to plain ASCII, thanks to</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># https://stackoverflow.com/a/518232/2809427</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> unicodeToAscii(s):</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">''</span>.join(</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>        c <span class="cf">for</span> c <span class="kw">in</span> unicodedata.normalize(<span class="st">'NFD'</span>, s)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> unicodedata.category(c) <span class="op">!=</span> <span class="st">'Mn'</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Tokenize the string using NLTK</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tokenize(text):</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>    tokenizer <span class="op">=</span> nltk.tokenize.RegexpTokenizer(pattern<span class="op">=</span><span class="vs">r'\w+|[^\w\s]'</span>)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># simplify the problem space by considering only ASCII data</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>    cleaned_text <span class="op">=</span> unicodeToAscii(text.lower())</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># if the resulting string is empty, nothing else to do</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> cleaned_text.strip():</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> []</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> tokenizer.tokenize(cleaned_text)</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Given a ConvoKit conversation, preprocess each utterance's text by tokenizing and truncating.</span></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Returns the processed dialog entry where text has been replaced with a list of</span></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a><span class="co"># tokens, each no longer than MAX_LENGTH - 1 (to leave space for the EOS token)</span></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> processDialog(voc, dialog):</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>    processed <span class="op">=</span> []</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> utterance <span class="kw">in</span> dialog.iter_utterances():</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># skip the section header, which does not contain conversational content</span></span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> utterance.meta[<span class="st">'is_section_header'</span>]:</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>        tokens <span class="op">=</span> tokenize(utterance.text)</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>        <span class="co"># replace out-of-vocabulary tokens</span></span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(tokens)):</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> tokens[i] <span class="kw">not</span> <span class="kw">in</span> voc.word2index:</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>                tokens[i] <span class="op">=</span> <span class="st">"UNK"</span></span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>        processed.append({<span class="st">"tokens"</span>: tokens, <span class="st">"is_attack"</span>: <span class="bu">int</span>(utterance.meta[<span class="st">'comment_has_personal_attack'</span>]), <span class="st">"id"</span>: utterance.<span class="bu">id</span>})</span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> processed</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Load context-reply pairs from the Corpus, optionally filtering to only conversations</span></span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a><span class="co"># from the specified split (train, val, or test).</span></span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Each conversation, which has N comments (not including the section header) will</span></span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a><span class="co"># get converted into N-1 comment-reply pairs, one pair for each reply</span></span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a><span class="co"># (the first comment does not reply to anything).</span></span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Each comment-reply pair is a tuple consisting of the conversational context</span></span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a><span class="co"># (that is, all comments prior to the reply), the reply itself, the label (that</span></span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a><span class="co"># is, whether the reply contained a derailment event), and the comment ID of the</span></span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a><span class="co"># reply (for later use in re-joining with the ConvoKit corpus).</span></span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a><span class="co"># The function returns a list of such pairs.</span></span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> loadPairs(voc, corpus, split<span class="op">=</span><span class="va">None</span>, last_only<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a>    pairs <span class="op">=</span> []</span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> convo <span class="kw">in</span> corpus.iter_conversations():</span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a>        <span class="co"># consider only conversations in the specified split of the data</span></span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> split <span class="kw">is</span> <span class="va">None</span> <span class="kw">or</span> convo.meta[<span class="st">'split'</span>] <span class="op">==</span> split:</span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a>            dialog <span class="op">=</span> processDialog(voc, convo)</span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a>            iter_range <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(dialog)) <span class="cf">if</span> <span class="kw">not</span> last_only <span class="cf">else</span> [<span class="bu">len</span>(dialog)<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> idx <span class="kw">in</span> iter_range:</span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a>                reply <span class="op">=</span> dialog[idx][<span class="st">"tokens"</span>][:(MAX_LENGTH<span class="op">-</span><span class="dv">1</span>)]</span>
<span id="cb5-59"><a href="#cb5-59" aria-hidden="true" tabindex="-1"></a>                label <span class="op">=</span> dialog[idx][<span class="st">"is_attack"</span>]</span>
<span id="cb5-60"><a href="#cb5-60" aria-hidden="true" tabindex="-1"></a>                comment_id <span class="op">=</span> dialog[idx][<span class="st">"id"</span>]</span>
<span id="cb5-61"><a href="#cb5-61" aria-hidden="true" tabindex="-1"></a>                <span class="co"># gather as context all utterances preceding the reply</span></span>
<span id="cb5-62"><a href="#cb5-62" aria-hidden="true" tabindex="-1"></a>                context <span class="op">=</span> [u[<span class="st">"tokens"</span>][:(MAX_LENGTH<span class="op">-</span><span class="dv">1</span>)] <span class="cf">for</span> u <span class="kw">in</span> dialog[:idx]]</span>
<span id="cb5-63"><a href="#cb5-63" aria-hidden="true" tabindex="-1"></a>                pairs.append((context, reply, label, comment_id))</span>
<span id="cb5-64"><a href="#cb5-64" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pairs</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-8" class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Helper functions for turning dialog and text sequences into tensors, and manipulating those tensors</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> indexesFromSentence(voc, sentence):</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> [voc.word2index[word] <span class="cf">for</span> word <span class="kw">in</span> sentence] <span class="op">+</span> [EOS_token]</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> zeroPadding(l, fillvalue<span class="op">=</span>PAD_token):</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">list</span>(itertools.zip_longest(<span class="op">*</span>l, fillvalue<span class="op">=</span>fillvalue))</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> binaryMatrix(l, value<span class="op">=</span>PAD_token):</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    m <span class="op">=</span> []</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, seq <span class="kw">in</span> <span class="bu">enumerate</span>(l):</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>        m.append([])</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> token <span class="kw">in</span> seq:</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> token <span class="op">==</span> PAD_token:</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>                m[i].append(<span class="dv">0</span>)</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>                m[i].append(<span class="dv">1</span>)</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> m</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Takes a batch of dialogs (lists of lists of tokens) and converts it into a</span></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a><span class="co"># batch of utterances (lists of tokens) sorted by length, while keeping track of</span></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a><span class="co"># the information needed to reconstruct the original batch of dialogs</span></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> dialogBatch2UtteranceBatch(dialog_batch):</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>    utt_tuples <span class="op">=</span> [] <span class="co"># will store tuples of (utterance, original position in batch, original position in dialog)</span></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch_idx <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(dialog_batch)):</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>        dialog <span class="op">=</span> dialog_batch[batch_idx]</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> dialog_idx <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(dialog)):</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>            utterance <span class="op">=</span> dialog[dialog_idx]</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>            utt_tuples.append((utterance, batch_idx, dialog_idx))</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># sort the utterances in descending order of length, to remain consistent with pytorch padding requirements</span></span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>    utt_tuples.sort(key<span class="op">=</span><span class="kw">lambda</span> x: <span class="bu">len</span>(x[<span class="dv">0</span>]), reverse<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># return the utterances, original batch indices, and original dialog indices as separate lists</span></span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>    utt_batch <span class="op">=</span> [u[<span class="dv">0</span>] <span class="cf">for</span> u <span class="kw">in</span> utt_tuples]</span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>    batch_indices <span class="op">=</span> [u[<span class="dv">1</span>] <span class="cf">for</span> u <span class="kw">in</span> utt_tuples]</span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>    dialog_indices <span class="op">=</span> [u[<span class="dv">2</span>] <span class="cf">for</span> u <span class="kw">in</span> utt_tuples]</span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> utt_batch, batch_indices, dialog_indices</span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Returns padded input sequence tensor and lengths</span></span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> inputVar(l, voc):</span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a>    indexes_batch <span class="op">=</span> [indexesFromSentence(voc, sentence) <span class="cf">for</span> sentence <span class="kw">in</span> l]</span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a>    lengths <span class="op">=</span> torch.tensor([<span class="bu">len</span>(indexes) <span class="cf">for</span> indexes <span class="kw">in</span> indexes_batch])</span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a>    padList <span class="op">=</span> zeroPadding(indexes_batch)</span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a>    padVar <span class="op">=</span> torch.LongTensor(padList)</span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> padVar, lengths</span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a><span class="co"># Returns padded target sequence tensor, padding mask, and max target length</span></span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> outputVar(l, voc):</span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a>    indexes_batch <span class="op">=</span> [indexesFromSentence(voc, sentence) <span class="cf">for</span> sentence <span class="kw">in</span> l]</span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a>    max_target_len <span class="op">=</span> <span class="bu">max</span>([<span class="bu">len</span>(indexes) <span class="cf">for</span> indexes <span class="kw">in</span> indexes_batch])</span>
<span id="cb6-50"><a href="#cb6-50" aria-hidden="true" tabindex="-1"></a>    padList <span class="op">=</span> zeroPadding(indexes_batch)</span>
<span id="cb6-51"><a href="#cb6-51" aria-hidden="true" tabindex="-1"></a>    mask <span class="op">=</span> binaryMatrix(padList)</span>
<span id="cb6-52"><a href="#cb6-52" aria-hidden="true" tabindex="-1"></a>    mask <span class="op">=</span> torch.ByteTensor(mask)</span>
<span id="cb6-53"><a href="#cb6-53" aria-hidden="true" tabindex="-1"></a>    padVar <span class="op">=</span> torch.LongTensor(padList)</span>
<span id="cb6-54"><a href="#cb6-54" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> padVar, mask, max_target_len</span>
<span id="cb6-55"><a href="#cb6-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-56"><a href="#cb6-56" aria-hidden="true" tabindex="-1"></a><span class="co"># Returns all items for a given batch of pairs</span></span>
<span id="cb6-57"><a href="#cb6-57" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> batch2TrainData(voc, pair_batch, already_sorted<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb6-58"><a href="#cb6-58" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> already_sorted:</span>
<span id="cb6-59"><a href="#cb6-59" aria-hidden="true" tabindex="-1"></a>        pair_batch.sort(key<span class="op">=</span><span class="kw">lambda</span> x: <span class="bu">len</span>(x[<span class="dv">0</span>]), reverse<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-60"><a href="#cb6-60" aria-hidden="true" tabindex="-1"></a>    input_batch, output_batch, label_batch, id_batch <span class="op">=</span> [], [], [], []</span>
<span id="cb6-61"><a href="#cb6-61" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> pair <span class="kw">in</span> pair_batch:</span>
<span id="cb6-62"><a href="#cb6-62" aria-hidden="true" tabindex="-1"></a>        input_batch.append(pair[<span class="dv">0</span>])</span>
<span id="cb6-63"><a href="#cb6-63" aria-hidden="true" tabindex="-1"></a>        output_batch.append(pair[<span class="dv">1</span>])</span>
<span id="cb6-64"><a href="#cb6-64" aria-hidden="true" tabindex="-1"></a>        label_batch.append(pair[<span class="dv">2</span>])</span>
<span id="cb6-65"><a href="#cb6-65" aria-hidden="true" tabindex="-1"></a>        id_batch.append(pair[<span class="dv">3</span>])</span>
<span id="cb6-66"><a href="#cb6-66" aria-hidden="true" tabindex="-1"></a>    dialog_lengths <span class="op">=</span> torch.tensor([<span class="bu">len</span>(x) <span class="cf">for</span> x <span class="kw">in</span> input_batch])</span>
<span id="cb6-67"><a href="#cb6-67" aria-hidden="true" tabindex="-1"></a>    input_utterances, batch_indices, dialog_indices <span class="op">=</span> dialogBatch2UtteranceBatch(input_batch)</span>
<span id="cb6-68"><a href="#cb6-68" aria-hidden="true" tabindex="-1"></a>    inp, utt_lengths <span class="op">=</span> inputVar(input_utterances, voc)</span>
<span id="cb6-69"><a href="#cb6-69" aria-hidden="true" tabindex="-1"></a>    output, mask, max_target_len <span class="op">=</span> outputVar(output_batch, voc)</span>
<span id="cb6-70"><a href="#cb6-70" aria-hidden="true" tabindex="-1"></a>    label_batch <span class="op">=</span> torch.FloatTensor(label_batch) <span class="cf">if</span> label_batch[<span class="dv">0</span>] <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> <span class="va">None</span></span>
<span id="cb6-71"><a href="#cb6-71" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> inp, dialog_lengths, utt_lengths, batch_indices, dialog_indices, label_batch, id_batch, output, mask, max_target_len</span>
<span id="cb6-72"><a href="#cb6-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-73"><a href="#cb6-73" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> batchIterator(voc, source_data, batch_size, shuffle<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb6-74"><a href="#cb6-74" aria-hidden="true" tabindex="-1"></a>    cur_idx <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb6-75"><a href="#cb6-75" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> shuffle:</span>
<span id="cb6-76"><a href="#cb6-76" aria-hidden="true" tabindex="-1"></a>        random.shuffle(source_data)</span>
<span id="cb6-77"><a href="#cb6-77" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb6-78"><a href="#cb6-78" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> cur_idx <span class="op">&gt;=</span> <span class="bu">len</span>(source_data):</span>
<span id="cb6-79"><a href="#cb6-79" aria-hidden="true" tabindex="-1"></a>            cur_idx <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb6-80"><a href="#cb6-80" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> shuffle:</span>
<span id="cb6-81"><a href="#cb6-81" aria-hidden="true" tabindex="-1"></a>                random.shuffle(source_data)</span>
<span id="cb6-82"><a href="#cb6-82" aria-hidden="true" tabindex="-1"></a>        batch <span class="op">=</span> source_data[cur_idx:(cur_idx<span class="op">+</span>batch_size)]</span>
<span id="cb6-83"><a href="#cb6-83" aria-hidden="true" tabindex="-1"></a>        <span class="co"># the true batch size may be smaller than the given batch size if there is not enough data left</span></span>
<span id="cb6-84"><a href="#cb6-84" aria-hidden="true" tabindex="-1"></a>        true_batch_size <span class="op">=</span> <span class="bu">len</span>(batch)</span>
<span id="cb6-85"><a href="#cb6-85" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ensure that the dialogs in this batch are sorted by length, as expected by the padding module</span></span>
<span id="cb6-86"><a href="#cb6-86" aria-hidden="true" tabindex="-1"></a>        batch.sort(key<span class="op">=</span><span class="kw">lambda</span> x: <span class="bu">len</span>(x[<span class="dv">0</span>]), reverse<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-87"><a href="#cb6-87" aria-hidden="true" tabindex="-1"></a>        <span class="co"># for analysis purposes, get the source dialogs and labels associated with this batch</span></span>
<span id="cb6-88"><a href="#cb6-88" aria-hidden="true" tabindex="-1"></a>        batch_dialogs <span class="op">=</span> [x[<span class="dv">0</span>] <span class="cf">for</span> x <span class="kw">in</span> batch]</span>
<span id="cb6-89"><a href="#cb6-89" aria-hidden="true" tabindex="-1"></a>        batch_labels <span class="op">=</span> [x[<span class="dv">2</span>] <span class="cf">for</span> x <span class="kw">in</span> batch]</span>
<span id="cb6-90"><a href="#cb6-90" aria-hidden="true" tabindex="-1"></a>        <span class="co"># convert batch to tensors</span></span>
<span id="cb6-91"><a href="#cb6-91" aria-hidden="true" tabindex="-1"></a>        batch_tensors <span class="op">=</span> batch2TrainData(voc, batch, already_sorted<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-92"><a href="#cb6-92" aria-hidden="true" tabindex="-1"></a>        <span class="cf">yield</span> (batch_tensors, batch_dialogs, batch_labels, true_batch_size)</span>
<span id="cb6-93"><a href="#cb6-93" aria-hidden="true" tabindex="-1"></a>        cur_idx <span class="op">+=</span> batch_size</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="part-2-load-the-data" class="level2">
<h2 class="anchored" data-anchor-id="part-2-load-the-data">Part 2: load the data</h2>
<p>Now we load the labeled Wikiconv corpus from ConvoKit, and run some transformations to prepare it for use with PyTorch</p>
<div id="cell-10" class="cell" data-outputid="64557a00-453c-44c0-f334-b5ae83508231">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>corpus <span class="op">=</span> Corpus(filename<span class="op">=</span>download(<span class="st">"conversations-gone-awry-corpus"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Dataset already exists at /root/.convokit/downloads/conversations-gone-awry-corpus</code></pre>
</div>
</div>
<div id="cell-11" class="cell" data-outputid="18931f88-572d-4c39-e5da-df3eca9c078c">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># let's check some quick stats to verify that the corpus loaded correctly</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(corpus.get_utterance_ids()))</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(corpus.get_usernames()))</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(corpus.get_conversation_ids()))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>30021
8069
4188</code></pre>
</div>
</div>
<div id="cell-12" class="cell" data-outputid="61b9f041-d59f-4f5a-a65b-ce9631c02336">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's also take a look at some example data to see what kinds of information/metadata are available to us</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">list</span>(corpus.iter_conversations())[<span class="dv">0</span>].__dict__)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">list</span>(corpus.iter_utterances())[<span class="dv">0</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'_owner': &lt;convokit.model.corpus.Corpus object at 0x7f6424d21358&gt;, '_id': '146743638.12652.12652', '_utterance_ids': ['146743638.12652.12652', '146743638.12667.12652', '146842219.12874.12874', '146860774.13072.13072'], '_usernames': None, '_meta': {'page_title': 'User talk:2005', 'page_id': 1003212, 'pair_id': '143890867.11926.11926', 'conversation_has_personal_attack': False, 'verified': True, 'pair_verified': True, 'annotation_year': '2018', 'split': 'train'}}
Utterance({'id': '146743638.12652.12652', 'user': User([('name', 'Sirex98')]), 'root': '146743638.12652.12652', 'reply_to': None, 'timestamp': 1185295934.0, 'text': '== [WIKI_LINK: WP:COMMONNAME] ==\n', 'meta': {'is_section_header': True, 'comment_has_personal_attack': False, 'toxicity': 0}})</code></pre>
</div>
</div>
<p>Now we can use the utilities defined in Part 1 to convert the ConvoKit conversational data into a tokenized form that can be straightforwardly turned into Tensors later.</p>
<div id="cell-14" class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># First, we need to build the vocabulary so that we know how to map tokens to tensor indicies.</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="co"># For the sake of replicating the paper results, we will load the pre-computed vocabulary objects used in the paper.</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>voc <span class="op">=</span> loadPrecomputedVoc(<span class="st">"wikiconv"</span>, WORD2INDEX_URL, INDEX2WORD_URL)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-15" class="cell" data-outputid="a682ac56-5ec9-4a88-fdce-fc9fb08aa104">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Inspect the Voc object to make sure it loaded correctly</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(voc.num_words) <span class="co"># expected vocab size is 50004: it was built using a fixed vocab size of 50k plus 4 spots for special tokens PAD, SOS, EOS, and UNK.</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">list</span>(voc.word2index.items())[:<span class="dv">10</span>])</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">list</span>(voc.index2word.items())[:<span class="dv">10</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>50004
[('UNK', 3), ('.', 4), ('the', 5), ("'", 6), (',', 7), ('to', 8), ('i', 9), ('of', 10), ('a', 11), ('and', 12)]
[('0', 'PAD'), ('1', 'SOS'), ('2', 'EOS'), ('3', 'UNK'), ('4', '.'), ('5', 'the'), ('6', "'"), ('7', ','), ('8', 'to'), ('9', 'i')]</code></pre>
</div>
</div>
<div id="cell-16" class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the test set data into a list of input/label pairs. Each input will represent the conversation as a list of lists of tokens.</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>train_pairs <span class="op">=</span> loadPairs(voc, corpus, <span class="st">"train"</span>, last_only<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>val_pairs <span class="op">=</span> loadPairs(voc, corpus, <span class="st">"val"</span>, last_only<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>test_pairs <span class="op">=</span> loadPairs(voc, corpus, <span class="st">"test"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-17" class="cell" data-outputid="11d7b50b-bc00-4080-d4ce-9294b3988194">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Validate the conversion by checking data size and some samples</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(train_pairs))</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(val_pairs))</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(test_pairs))</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> p <span class="kw">in</span> train_pairs[:<span class="dv">5</span>]:</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(p)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>2508
840
4365
([['i', 'notice', 'that', 'UNK', 'that', 'moved', 'UNK', 'to', 'bill', 'chen', 'citing', 'UNK', ',', 'then', 'you', 'reverted', 'this', 'change', ',', 'bill', 'chen', 'doesn', "'", 't', 'commonly', 'go', 'by', 'william', ',', 'his', 'book', 'is', 'even', 'penned', 'as', 'bill', 'chen', '.', 'from', 'what', 'i', 'read', 'in', 'wp', ':', 'commonname', 'UNK', 'seems', 'to', 'be', 'correct', ',', 'examples', 'given', 'are', 'names', 'such', 'as', ':', '*', 'UNK', '(', 'not', 'UNK', ')', '*', 'UNK', '(', 'not', 'UNK', ')', 'i', 'think', 'this', 'revert', 'may', 'have', 'been', 'a'], ['chen', 'was', 'known', 'in', 'the', 'poker', 'world', 'as', '"', 'william', '"', 'for', 'years', 'before', 'he', 'became', 'commonly', 'known', 'as', '"', 'bill', '"', '.', 'i', 'changed', 'it', 'back', 'because', 'incidences', 'online', 'including', 'usenet', 'are', 'roughly', 'equal', ',', 'nothing', 'at', 'all', 'like', 'bill', 'clinton', 'and', 'william', 'clinton', ',', 'and', 'in', 'equal', 'cases', 'using', 'the', 'real', 'name', 'seems', 'the', 'best', 'choice', '.', '(', 'the', 'UNK', 'page', 'is', 'especially', 'UNK', '.', '.', '.', 'UNK', 'in', 'the', 'page', 'title', ',', 'bill', 'in', 'the', 'page']], ['i', 'see', 'what', 'you', 'saying', 'i', 'just', 'read', 'his', 'UNK', 'profile', ',', 'it', 'struck', 'me', 'when', 'i', 'saw', 'the', 'change', 'because', 'i', 'remember', 'him', 'being', 'called', 'bill', 'when', 'i', 'watched', 'the', 'last', 'season', 'of', 'high', 'stakes', 'poker', ',', 'but', 'you', 'seem', 'to', 'have', 'many', 'more', 'years', 'experience', 'in', 'the', 'poker', '/', 'gambling', 'world', 'then', 'i', 'do', '(', 'i', "'", 'm', 'still', 'a', 'bit', 'of', 'a', 'newbie', ')', ',', 'so', 'i', 'wanted', 'to', 'check', 'with', 'you', 'first', '.', 'btw', 'as'], 0, '146860774.13072.13072')
([['no', 'more', 'than', 'two', 'editors', 'advocated', 'deletion', '.', 'UNK', 'and', 'maybe', 'UNK', '.', 'that', "'", 's', 'not', 'a', 'clear', 'consensus', 'for', 'deletion', '.', 'cheers', ','], ['in', 'the', 'future', 'please', 'don', "'", 't', 'close', 'afds', 'when', 'you', 'don', "'", 't', 'have', 'the', 'courtesy', 'of', 'reading', 'the', 'comments', '.', 'all', 'comments', 'favored', 'deletion', 'except', 'two', '.', 'please', 'don', "'", 't', 'be', 'so', 'careless', 'in', 'the', 'future', '.'], ['that', 'simply', 'isn', "'", 't', 'true', '.', 'if', 'you', 'read', 'the', 'comments', ',', 'you', "'", 'll', 'find', 'it', "'", 's', 'actually', '2', 'keep', ',', '4', 'transwiki', ',', '2', 'delete', '(', 'more', 'or', 'less', ')', '.', 'the', "'", "'", 'comments', "'", "'", 'favour', 'no', 'consensus', '/', 'transwiki', '.', 'the', '"', 'votes', '"', 'favour', 'delete', ',', 'but', 'voting', 'is', 'evil', ',', 'of', 'course', '.', '.', '.'], ['somehow', ',', 'i', 'suspect', 'you', 'may', 'wish', 'to', 'participate', 'in', 'UNK', 'discussion', '.', 'cheers', ',']], ['i', 'assume', 'your', 'deliberate', 'lying', 'has', 'a', 'point', ',', 'but', 'get', 'over', 'it', '.', 'stop', 'bizarrely', 'goin', 'on', 'about', 'UNK', '.', 'that', 'has', 'nothing', 'to', 'do', 'with', 'the', 'afd', '.', 'there', 'was', 'a', 'plain', 'consensus', 'for', 'deleting', 'the', 'article', '.', 'UNK', 'is', 'completely', 'unrelated', '.', 'please', 'don', "'", 't', 'be', 'so', 'deliberately', 'obtuse', 'in', 'the', 'future', '.', 'wasting', 'other', 'people', "'", 's', 'time', 'is', 'simply', 'rude', '.'], 1, '144065917.12226.12226')
([['if', 'you', 'have', 'problems', 'with', 'my', 'edits', 'to', 'the', 'UNK', 'page', 'please', 'let', 'me', 'know', ',', 'do', 'not', 'just', 'revert', 'the', 'edits', '.', 'although', 'the', 'UNK', 'article', 'is', 'very', 'accurate', 'the', 'introduction', 'is', 'riddled', 'with', 'errors', ',', 'which', 'i', 'corrected', '.', 'i', 'think', 'it', 'is', 'everyone', "'", 's', 'best', 'interests', 'to', 'make', 'wiki', 'pages', 'as', 'accurate', 'as', 'possible', 'and', 'the', 'four', 'wheel', 'drive', 'article', 'is', 'not', 'a', 'UNK', 'example', 'of', 'this', '.', 'i', '.', 'e', '.', 'all', '-', 'wheel'], ['*', 'shrug', '*', 'it', '*', 'is', '*', 'just', 'a', 'marketing', 'term', '.', 'i', 'wish', 'you', 'lot', 'would', 'stop', 'editing', 'it', 'otherwise', '.', 'UNK', '.']], ['although', 'UNK', 'can', 'be', 'considered', 'a', 'form', 'of', 'UNK', 'it', 'is', 'not', 'the', 'same', 'drive', 'train', 'type', 'as', 'part', '-', 'time', 'UNK', '.', 'so', 'i', 'would', 'have', 'to', 'say', 'calling', 'it', 'just', 'a', 'marketing', 'term', 'is', 'a', 'narrow', 'minded', 'and', 'inaccurate', 'statement', '.', 'even', 'though', 'they', 'are', 'similar', 'you', 'can', "'", 't', 'just', 'UNK', 'them', 'into', 'the', 'same', 'group', '.', 'if', ',', 'as', 'you', 'say', ',', 'UNK', 'is', 'just', 'a', 'marketing', 'term', 'then', 'taking', 'a', 'turn', 'in', 'a', 'audi'], 0, '127772860.903.903')
([['please', 'stop', 'removing', 'and', 'altering', 'other', 'editors', "'", 'comments', '.', 'what', 'appeared', 'to', 'be', 'valid', 'concern', 'is', 'quickly', 'descending', 'into', 'trolling', ',', 'and', 'if', 'you', 'continue', ',', 'you', 'may', 'be', 'blocked', 'from', 'editing', '.', 'stop', 'it', '.', '-'], ['well', 'please', 'stop', 'posting', 'incorrect', 'information', '.', 'if', 'you', 'were', 'right', 'i', "'", 'd', 'agree', 'with', 'you', ',', 'and', 'i', 'am', 'not', 'trolling', '.'], ['UNK', 'is', 'trolling', ',', 'as', 'is', 'removing', 'other', 'people', "'", 's', 'comments', '.', 'look', ',', 'wikipedia', 'is', 'built', 'on', 'consensus', ',', 'and', 'consensus', 'has', 'it', 'that', 'we', 'use', 'american', 'style', 'for', 'american', 'subjects', '.', 'end', 'of', 'story', '.', 'any', 'more', 'complaint', 'about', 'trolling', 'about', 'this', 'topic', 'and', 'i', "'", 'll', 'report', 'you', 'myself', '.']], ['bullshit', '.', 'i', 'am', 'correcting', 'a', 'simple', 'mistake', '.', 'if', 'i', 'was', 'trolling', 'i', "'", 'd', 'be', 'doing', 'damage', 'to', 'the', 'page', ',', 'yet', 'i', 'am', 'not', '.', 'what', 'was', 'written', 'is', 'wrong', ',', 'simple', 'as', 'that', '.', 'all', 'i', 'have', 'done', 'is', 'disagree', 'with', 'what', 'was', 'written', 'and', 'written', 'as', 'such', '.', 'if', 'that', "'", 's', 'trolling', 'then', 'you', 'are', 'guilty', 'as', 'well', '.', 'and', 'stop', 'UNK', 'my', 'page', 'dickhead', '.', 'UNK', '.'], 1, '144645449.1479.1479')
([['please', 'stop', 'including', 'disreputable', 'sources', 'for', 'this', 'article', '.', 'wikipedia', 'policy', 'is', 'quite', 'clear', 'on', 'this', 'matter', 'blogs', 'and', 'other', 'websites', 'which', 'do', 'not', 'employ', 'editorial', 'oversight', 'of', 'authors', "'", 'work', 'are', 'not', 'permitted', 'as', 'sources', 'here', '.', 'please', 'stop', 'adding', 'blogs', '.'], ['please', 'stop', 'deleting', 'reputable', 'sources', 'from', 'this', 'article', '.', 'you', 'have', 'deleted', 'joe', 'wilson', "'", 's', 'nyt', 'article', 'that', 'is', 'a', 'key', 'factor', 'in', 'this', 'whole', 'controversy', '!', 'among', 'others', '.', 'simply', 'because', 'the', 'article', 'is', 'printed', 'on', 'a', 'different', 'site', 'does', 'not', 'mean', 'it', 'is', 'sourced', 'to', 'a', '"', 'heinous', 'blog', '"', '(', 'which', 'the', 'site', 'is', 'not', 'anyway', ')', '.', 'if', 'you', 'find', 'a', 'better', 'place', 'that', 'the', 'article', 'exists', ',', 'put', 'it', 'there', '.', 'or', 'if'], ['the', 'american', 'prospect', 'article', 'should', 'stay', '-', 'american', 'prospect', 'easily', 'meets', 'UNK', '.', 'the', 'cooperative', 'research', 'project', 'link', 'should', 'be', 'nuked', 'and', 'should', 'stay', 'nuked', '-', 'i', 'see', 'no', 'evidence', 'that', 'it', "'", 's', 'a', 'reliable', 'source', '.', 'factcheck', '.', 'org', 'is', 'reliable', 'enough', 'that', 'the', 'vice', 'president', 'of', 'the', 'united', 'states', '(', 'incorrectly', ')', 'cited', 'it', 'in', 'his', 'debate', 'as', 'an', 'authoritative', 'source', ';', 'they', 'have', 'a', 'good', 'reputation', ',', 'and', 'their', 'very', "'", "'", 'purpose', "'", "'"], ['agreed', 'UNK', 'cooperative', 'research', 'but', 'not', 'the', 'alternet', 'citation', '-', 'they', 'are', 'transcribing', 'an', 'interview', 'on', 'a', 'well', 'known', 'radio', 'show', 'with', 'a', 'well', 'known', 'source', 'with', 'expertise', 'on', 'this', 'topic', 'whose', 'comments', 'are', 'cited', 'in', 'numerous', 'mainstream', 'sources', '.', 'if', 'you', 'have', 'a', 'better', 'source', 'for', 'the', 'transcript', 'that', 'is', 'fine', 'but', 'you', 'cannot', 'just', 'delete', 'it', 'because', 'it', 'is', '"', 'edited', '"', '-', 'unless', 'you', 'have', 'evidence', 'that', 'they', 'are', 'making', 'stuff', 'up', ',', 'we', 'must', 'presume'], ['actually', ',', 'especially', 'with', 'alternet', ',', 'we', "'", "'", 'can', "'", 't', "'", "'", 'assume', 'good', 'faith', ';', 'we', 'need', 'to', 'do', 'exactly', 'the', 'opposite', '.', 'we', 'need', 'to', 'examine', 'sources', 'critically', ',', 'according', 'to', 'the', 'guidelines', 'on', 'UNK', '.', 'were', 'it', 'to', 'be', 'a', 'verbatim', 'copy', ',', 'perhaps', 'we', 'could', 'accept', 'it', 'as', 'a', 'source', '(', "'", "'", 'perhaps', "'", "'", 'being', 'absolutely', 'critical', ')', ',', 'but', 'because', 'it', "'", 's', 'edited', 'and', 'doesn', "'", 't', 'contain', 'information']], ['(', '1', ')', 'please', 'substantiate', 'that', 'the', 'source', 'is', '"', 'notoriously', 'unreliable', '.', '"', '(', '2', ')', 'please', 'indicate', 'where', 'it', 'says', 'we', 'should', 'assume', 'bad', 'faith', 'with', 'sources', 'that', 'are', 'transcripts', 'of', 'interviews', '(', 'i', 'know', 'the', 'quote', 'in', 'the', 'article', 'is', 'directly', 'from', 'the', 'interview', 'as', 'i', 'listened', 'to', 'the', 'interview', 'myself', ';', 'i', 'also', 'have', 'looked', 'at', 'the', 'transcript', 'and', 'do', 'not', 'see', 'anything', 'that', 'is', 'different', 'from', 'what', 'i', 'heard', ';', 'but', 'apparently', 'i', 'should'], 0, '67176052.25110.25110')</code></pre>
</div>
</div>
</section>
<section id="part-3-define-the-model" class="level2">
<h2 class="anchored" data-anchor-id="part-3-define-the-model">Part 3: define the model</h2>
<p>Next, we need to set up the individual components of the CRAFT framework: the utterance encoder, the context encoder, and the classification head (since we are fine-tuning a pretrained model, we do not need to define the decoder here). Each component will be defined as a PyTorch <code>nn.Module</code>.</p>
<div id="cell-19" class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> EncoderRNN(nn.Module):</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""This module represents the utterance encoder component of CRAFT, responsible for creating vector representations of utterances"""</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, hidden_size, embedding, n_layers<span class="op">=</span><span class="dv">1</span>, dropout<span class="op">=</span><span class="dv">0</span>):</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(EncoderRNN, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_layers <span class="op">=</span> n_layers</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.hidden_size <span class="op">=</span> hidden_size</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.embedding <span class="op">=</span> embedding</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Initialize GRU; the input_size and hidden_size params are both set to 'hidden_size'</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>        <span class="co">#   because our input size is a word embedding with number of features == hidden_size</span></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.gru <span class="op">=</span> nn.GRU(hidden_size, hidden_size, n_layers,</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>                          dropout<span class="op">=</span>(<span class="dv">0</span> <span class="cf">if</span> n_layers <span class="op">==</span> <span class="dv">1</span> <span class="cf">else</span> dropout), bidirectional<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, input_seq, input_lengths, hidden<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Convert word indexes to embeddings</span></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>        embedded <span class="op">=</span> <span class="va">self</span>.embedding(input_seq)</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Pack padded batch of sequences for RNN module</span></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>        packed <span class="op">=</span> torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Forward pass through GRU</span></span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>        outputs, hidden <span class="op">=</span> <span class="va">self</span>.gru(packed, hidden)</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Unpack padding</span></span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>        outputs, _ <span class="op">=</span> torch.nn.utils.rnn.pad_packed_sequence(outputs)</span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Sum bidirectional GRU outputs</span></span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> outputs[:, :, :<span class="va">self</span>.hidden_size] <span class="op">+</span> outputs[:, : ,<span class="va">self</span>.hidden_size:]</span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Return output and final hidden state</span></span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> outputs, hidden</span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ContextEncoderRNN(nn.Module):</span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""This module represents the context encoder component of CRAFT, responsible for creating an order-sensitive vector representation of conversation context"""</span></span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, hidden_size, n_layers<span class="op">=</span><span class="dv">1</span>, dropout<span class="op">=</span><span class="dv">0</span>):</span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(ContextEncoderRNN, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_layers <span class="op">=</span> n_layers</span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.hidden_size <span class="op">=</span> hidden_size</span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-35"><a href="#cb19-35" aria-hidden="true" tabindex="-1"></a>        <span class="co"># only unidirectional GRU for context encoding</span></span>
<span id="cb19-36"><a href="#cb19-36" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.gru <span class="op">=</span> nn.GRU(hidden_size, hidden_size, n_layers,</span>
<span id="cb19-37"><a href="#cb19-37" aria-hidden="true" tabindex="-1"></a>                          dropout<span class="op">=</span>(<span class="dv">0</span> <span class="cf">if</span> n_layers <span class="op">==</span> <span class="dv">1</span> <span class="cf">else</span> dropout), bidirectional<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb19-38"><a href="#cb19-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-39"><a href="#cb19-39" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, input_seq, input_lengths, hidden<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb19-40"><a href="#cb19-40" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Pack padded batch of sequences for RNN module</span></span>
<span id="cb19-41"><a href="#cb19-41" aria-hidden="true" tabindex="-1"></a>        packed <span class="op">=</span> torch.nn.utils.rnn.pack_padded_sequence(input_seq, input_lengths)</span>
<span id="cb19-42"><a href="#cb19-42" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Forward pass through GRU</span></span>
<span id="cb19-43"><a href="#cb19-43" aria-hidden="true" tabindex="-1"></a>        outputs, hidden <span class="op">=</span> <span class="va">self</span>.gru(packed, hidden)</span>
<span id="cb19-44"><a href="#cb19-44" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Unpack padding</span></span>
<span id="cb19-45"><a href="#cb19-45" aria-hidden="true" tabindex="-1"></a>        outputs, _ <span class="op">=</span> torch.nn.utils.rnn.pad_packed_sequence(outputs)</span>
<span id="cb19-46"><a href="#cb19-46" aria-hidden="true" tabindex="-1"></a>        <span class="co"># return output and final hidden state</span></span>
<span id="cb19-47"><a href="#cb19-47" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> outputs, hidden</span>
<span id="cb19-48"><a href="#cb19-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-49"><a href="#cb19-49" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SingleTargetClf(nn.Module):</span>
<span id="cb19-50"><a href="#cb19-50" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""This module represents the CRAFT classifier head, which takes the context encoding and uses it to make a forecast"""</span></span>
<span id="cb19-51"><a href="#cb19-51" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, hidden_size, dropout<span class="op">=</span><span class="fl">0.1</span>):</span>
<span id="cb19-52"><a href="#cb19-52" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(SingleTargetClf, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb19-53"><a href="#cb19-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-54"><a href="#cb19-54" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.hidden_size <span class="op">=</span> hidden_size</span>
<span id="cb19-55"><a href="#cb19-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-56"><a href="#cb19-56" aria-hidden="true" tabindex="-1"></a>        <span class="co"># initialize classifier</span></span>
<span id="cb19-57"><a href="#cb19-57" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layer1 <span class="op">=</span> nn.Linear(hidden_size, hidden_size)</span>
<span id="cb19-58"><a href="#cb19-58" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layer1_act <span class="op">=</span> nn.LeakyReLU()</span>
<span id="cb19-59"><a href="#cb19-59" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layer2 <span class="op">=</span> nn.Linear(hidden_size, hidden_size <span class="op">//</span> <span class="dv">2</span>)</span>
<span id="cb19-60"><a href="#cb19-60" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layer2_act <span class="op">=</span> nn.LeakyReLU()</span>
<span id="cb19-61"><a href="#cb19-61" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.clf <span class="op">=</span> nn.Linear(hidden_size <span class="op">//</span> <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb19-62"><a href="#cb19-62" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dropout <span class="op">=</span> nn.Dropout(p<span class="op">=</span>dropout)</span>
<span id="cb19-63"><a href="#cb19-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-64"><a href="#cb19-64" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, encoder_outputs, encoder_input_lengths):</span>
<span id="cb19-65"><a href="#cb19-65" aria-hidden="true" tabindex="-1"></a>        <span class="co"># from stackoverflow (https://stackoverflow.com/questions/50856936/taking-the-last-state-from-bilstm-bigru-in-pytorch)</span></span>
<span id="cb19-66"><a href="#cb19-66" aria-hidden="true" tabindex="-1"></a>        <span class="co"># First we unsqueeze seqlengths two times so it has the same number of</span></span>
<span id="cb19-67"><a href="#cb19-67" aria-hidden="true" tabindex="-1"></a>        <span class="co"># of dimensions as output_forward</span></span>
<span id="cb19-68"><a href="#cb19-68" aria-hidden="true" tabindex="-1"></a>        <span class="co"># (batch_size) -&gt; (1, batch_size, 1)</span></span>
<span id="cb19-69"><a href="#cb19-69" aria-hidden="true" tabindex="-1"></a>        lengths <span class="op">=</span> encoder_input_lengths.unsqueeze(<span class="dv">0</span>).unsqueeze(<span class="dv">2</span>)</span>
<span id="cb19-70"><a href="#cb19-70" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Then we expand it accordingly</span></span>
<span id="cb19-71"><a href="#cb19-71" aria-hidden="true" tabindex="-1"></a>        <span class="co"># (1, batch_size, 1) -&gt; (1, batch_size, hidden_size)</span></span>
<span id="cb19-72"><a href="#cb19-72" aria-hidden="true" tabindex="-1"></a>        lengths <span class="op">=</span> lengths.expand((<span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>, encoder_outputs.size(<span class="dv">2</span>)))</span>
<span id="cb19-73"><a href="#cb19-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-74"><a href="#cb19-74" aria-hidden="true" tabindex="-1"></a>        <span class="co"># take only the last state of the encoder for each batch</span></span>
<span id="cb19-75"><a href="#cb19-75" aria-hidden="true" tabindex="-1"></a>        last_outputs <span class="op">=</span> torch.gather(encoder_outputs, <span class="dv">0</span>, lengths<span class="op">-</span><span class="dv">1</span>).squeeze()</span>
<span id="cb19-76"><a href="#cb19-76" aria-hidden="true" tabindex="-1"></a>        <span class="co"># forward pass through hidden layers</span></span>
<span id="cb19-77"><a href="#cb19-77" aria-hidden="true" tabindex="-1"></a>        layer1_out <span class="op">=</span> <span class="va">self</span>.layer1_act(<span class="va">self</span>.layer1(<span class="va">self</span>.dropout(last_outputs)))</span>
<span id="cb19-78"><a href="#cb19-78" aria-hidden="true" tabindex="-1"></a>        layer2_out <span class="op">=</span> <span class="va">self</span>.layer2_act(<span class="va">self</span>.layer2(<span class="va">self</span>.dropout(layer1_out)))</span>
<span id="cb19-79"><a href="#cb19-79" aria-hidden="true" tabindex="-1"></a>        <span class="co"># compute and return logits</span></span>
<span id="cb19-80"><a href="#cb19-80" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> <span class="va">self</span>.clf(<span class="va">self</span>.dropout(layer2_out)).squeeze()</span>
<span id="cb19-81"><a href="#cb19-81" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> logits</span>
<span id="cb19-82"><a href="#cb19-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-83"><a href="#cb19-83" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Predictor(nn.Module):</span>
<span id="cb19-84"><a href="#cb19-84" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""This helper module encapsulates the CRAFT pipeline, defining the logic of passing an input through each consecutive sub-module."""</span></span>
<span id="cb19-85"><a href="#cb19-85" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, encoder, context_encoder, classifier):</span>
<span id="cb19-86"><a href="#cb19-86" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(Predictor, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb19-87"><a href="#cb19-87" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.encoder <span class="op">=</span> encoder</span>
<span id="cb19-88"><a href="#cb19-88" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.context_encoder <span class="op">=</span> context_encoder</span>
<span id="cb19-89"><a href="#cb19-89" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.classifier <span class="op">=</span> classifier</span>
<span id="cb19-90"><a href="#cb19-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-91"><a href="#cb19-91" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, input_batch, dialog_lengths, dialog_lengths_list, utt_lengths, batch_indices, dialog_indices, batch_size, max_length):</span>
<span id="cb19-92"><a href="#cb19-92" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Forward input through encoder model</span></span>
<span id="cb19-93"><a href="#cb19-93" aria-hidden="true" tabindex="-1"></a>        _, utt_encoder_hidden <span class="op">=</span> <span class="va">self</span>.encoder(input_batch, utt_lengths)</span>
<span id="cb19-94"><a href="#cb19-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-95"><a href="#cb19-95" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Convert utterance encoder final states to batched dialogs for use by context encoder</span></span>
<span id="cb19-96"><a href="#cb19-96" aria-hidden="true" tabindex="-1"></a>        context_encoder_input <span class="op">=</span> makeContextEncoderInput(utt_encoder_hidden, dialog_lengths_list, batch_size, batch_indices, dialog_indices)</span>
<span id="cb19-97"><a href="#cb19-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-98"><a href="#cb19-98" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Forward pass through context encoder</span></span>
<span id="cb19-99"><a href="#cb19-99" aria-hidden="true" tabindex="-1"></a>        context_encoder_outputs, context_encoder_hidden <span class="op">=</span> <span class="va">self</span>.context_encoder(context_encoder_input, dialog_lengths)</span>
<span id="cb19-100"><a href="#cb19-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-101"><a href="#cb19-101" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Forward pass through classifier to get prediction logits</span></span>
<span id="cb19-102"><a href="#cb19-102" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> <span class="va">self</span>.classifier(context_encoder_outputs, dialog_lengths)</span>
<span id="cb19-103"><a href="#cb19-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-104"><a href="#cb19-104" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply sigmoid activation</span></span>
<span id="cb19-105"><a href="#cb19-105" aria-hidden="true" tabindex="-1"></a>        predictions <span class="op">=</span> F.sigmoid(logits)</span>
<span id="cb19-106"><a href="#cb19-106" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> predictions</span>
<span id="cb19-107"><a href="#cb19-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-108"><a href="#cb19-108" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> makeContextEncoderInput(utt_encoder_hidden, dialog_lengths, batch_size, batch_indices, dialog_indices):</span>
<span id="cb19-109"><a href="#cb19-109" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""The utterance encoder takes in utterances in combined batches, with no knowledge of which ones go where in which conversation.</span></span>
<span id="cb19-110"><a href="#cb19-110" aria-hidden="true" tabindex="-1"></a><span class="co">       Its output is therefore also unordered. We correct this by using the information computed during tensor conversion to regroup</span></span>
<span id="cb19-111"><a href="#cb19-111" aria-hidden="true" tabindex="-1"></a><span class="co">       the utterance vectors into their proper conversational order."""</span></span>
<span id="cb19-112"><a href="#cb19-112" aria-hidden="true" tabindex="-1"></a>    <span class="co"># first, sum the forward and backward encoder states</span></span>
<span id="cb19-113"><a href="#cb19-113" aria-hidden="true" tabindex="-1"></a>    utt_encoder_summed <span class="op">=</span> utt_encoder_hidden[<span class="op">-</span><span class="dv">2</span>,:,:] <span class="op">+</span> utt_encoder_hidden[<span class="op">-</span><span class="dv">1</span>,:,:]</span>
<span id="cb19-114"><a href="#cb19-114" aria-hidden="true" tabindex="-1"></a>    <span class="co"># we now have hidden state of shape [utterance_batch_size, hidden_size]</span></span>
<span id="cb19-115"><a href="#cb19-115" aria-hidden="true" tabindex="-1"></a>    <span class="co"># split it into a list of [hidden_size,] x utterance_batch_size</span></span>
<span id="cb19-116"><a href="#cb19-116" aria-hidden="true" tabindex="-1"></a>    last_states <span class="op">=</span> [t.squeeze() <span class="cf">for</span> t <span class="kw">in</span> utt_encoder_summed.split(<span class="dv">1</span>, dim<span class="op">=</span><span class="dv">0</span>)]</span>
<span id="cb19-117"><a href="#cb19-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-118"><a href="#cb19-118" aria-hidden="true" tabindex="-1"></a>    <span class="co"># create a placeholder list of tensors to group the states by source dialog</span></span>
<span id="cb19-119"><a href="#cb19-119" aria-hidden="true" tabindex="-1"></a>    states_dialog_batched <span class="op">=</span> [[<span class="va">None</span> <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(dialog_lengths[i])] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(batch_size)]</span>
<span id="cb19-120"><a href="#cb19-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-121"><a href="#cb19-121" aria-hidden="true" tabindex="-1"></a>    <span class="co"># group the states by source dialog</span></span>
<span id="cb19-122"><a href="#cb19-122" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> hidden_state, batch_idx, dialog_idx <span class="kw">in</span> <span class="bu">zip</span>(last_states, batch_indices, dialog_indices):</span>
<span id="cb19-123"><a href="#cb19-123" aria-hidden="true" tabindex="-1"></a>        states_dialog_batched[batch_idx][dialog_idx] <span class="op">=</span> hidden_state</span>
<span id="cb19-124"><a href="#cb19-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-125"><a href="#cb19-125" aria-hidden="true" tabindex="-1"></a>    <span class="co"># stack each dialog into a tensor of shape [dialog_length, hidden_size]</span></span>
<span id="cb19-126"><a href="#cb19-126" aria-hidden="true" tabindex="-1"></a>    states_dialog_batched <span class="op">=</span> [torch.stack(d) <span class="cf">for</span> d <span class="kw">in</span> states_dialog_batched]</span>
<span id="cb19-127"><a href="#cb19-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-128"><a href="#cb19-128" aria-hidden="true" tabindex="-1"></a>    <span class="co"># finally, condense all the dialog tensors into a single zero-padded tensor</span></span>
<span id="cb19-129"><a href="#cb19-129" aria-hidden="true" tabindex="-1"></a>    <span class="co"># of shape [max_dialog_length, batch_size, hidden_size]</span></span>
<span id="cb19-130"><a href="#cb19-130" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> torch.nn.utils.rnn.pad_sequence(states_dialog_batched)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="part-4-define-training-loop" class="level2">
<h2 class="anchored" data-anchor-id="part-4-define-training-loop">Part 4: define training loop</h2>
<p>Now that we have all the model components defined, we need to define the actual training procedure. This will be a fairly standard neural network training loop, iterating over batches of labeled dialogs and computing cross-entropy loss on the predicted label. We will also define evaluation functions so that we can compute accuracy on the validation set after every epoch, allowing us to keep the model with the best validation performance. Note that for the sake of simpler code, validation accuracy is computed in the “unfair” manner using a single run of CRAFT over the full context preceding the actual personal attack, rather than the more realistic (and complicated) iterated evaluation that is used for final evaluation of the test set (in practice the two metrics track each other fairly well, making this a reasonable simplification for the sake of easy validation).</p>
<div id="cell-21" class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train(input_variable, dialog_lengths, dialog_lengths_list, utt_lengths, batch_indices, dialog_indices, labels, <span class="co"># input/output arguments</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>          encoder, context_encoder, attack_clf,                                                                    <span class="co"># network arguments</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>          encoder_optimizer, context_encoder_optimizer, attack_clf_optimizer,                                      <span class="co"># optimization arguments</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>          batch_size, clip, max_length<span class="op">=</span>MAX_LENGTH):                                                                <span class="co"># misc arguments</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Zero gradients</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>    encoder_optimizer.zero_grad()</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>    context_encoder_optimizer.zero_grad()</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>    attack_clf_optimizer.zero_grad()</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Set device options</span></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>    input_variable <span class="op">=</span> input_variable.to(device)</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>    dialog_lengths <span class="op">=</span> dialog_lengths.to(device)</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>    utt_lengths <span class="op">=</span> utt_lengths.to(device)</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> labels.to(device)</span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Forward pass through utterance encoder</span></span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>    _, utt_encoder_hidden <span class="op">=</span> encoder(input_variable, utt_lengths)</span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convert utterance encoder final states to batched dialogs for use by context encoder</span></span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a>    context_encoder_input <span class="op">=</span> makeContextEncoderInput(utt_encoder_hidden, dialog_lengths_list, batch_size, batch_indices, dialog_indices)</span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Forward pass through context encoder</span></span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a>    context_encoder_outputs, _ <span class="op">=</span> context_encoder(context_encoder_input, dialog_lengths)</span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Forward pass through classifier to get prediction logits</span></span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a>    logits <span class="op">=</span> attack_clf(context_encoder_outputs, dialog_lengths)</span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate loss</span></span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> F.binary_cross_entropy_with_logits(logits, labels)</span>
<span id="cb20-31"><a href="#cb20-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-32"><a href="#cb20-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Perform backpropatation</span></span>
<span id="cb20-33"><a href="#cb20-33" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb20-34"><a href="#cb20-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-35"><a href="#cb20-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Clip gradients: gradients are modified in place</span></span>
<span id="cb20-36"><a href="#cb20-36" aria-hidden="true" tabindex="-1"></a>    _ <span class="op">=</span> torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)</span>
<span id="cb20-37"><a href="#cb20-37" aria-hidden="true" tabindex="-1"></a>    _ <span class="op">=</span> torch.nn.utils.clip_grad_norm_(context_encoder.parameters(), clip)</span>
<span id="cb20-38"><a href="#cb20-38" aria-hidden="true" tabindex="-1"></a>    _ <span class="op">=</span> torch.nn.utils.clip_grad_norm_(attack_clf.parameters(), clip)</span>
<span id="cb20-39"><a href="#cb20-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-40"><a href="#cb20-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Adjust model weights</span></span>
<span id="cb20-41"><a href="#cb20-41" aria-hidden="true" tabindex="-1"></a>    encoder_optimizer.step()</span>
<span id="cb20-42"><a href="#cb20-42" aria-hidden="true" tabindex="-1"></a>    context_encoder_optimizer.step()</span>
<span id="cb20-43"><a href="#cb20-43" aria-hidden="true" tabindex="-1"></a>    attack_clf_optimizer.step()</span>
<span id="cb20-44"><a href="#cb20-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-45"><a href="#cb20-45" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> loss.item()</span>
<span id="cb20-46"><a href="#cb20-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-47"><a href="#cb20-47" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluateBatch(encoder, context_encoder, predictor, voc, input_batch, dialog_lengths,</span>
<span id="cb20-48"><a href="#cb20-48" aria-hidden="true" tabindex="-1"></a>                  dialog_lengths_list, utt_lengths, batch_indices, dialog_indices, batch_size, device, max_length<span class="op">=</span>MAX_LENGTH):</span>
<span id="cb20-49"><a href="#cb20-49" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Set device options</span></span>
<span id="cb20-50"><a href="#cb20-50" aria-hidden="true" tabindex="-1"></a>    input_batch <span class="op">=</span> input_batch.to(device)</span>
<span id="cb20-51"><a href="#cb20-51" aria-hidden="true" tabindex="-1"></a>    dialog_lengths <span class="op">=</span> dialog_lengths.to(device)</span>
<span id="cb20-52"><a href="#cb20-52" aria-hidden="true" tabindex="-1"></a>    utt_lengths <span class="op">=</span> utt_lengths.to(device)</span>
<span id="cb20-53"><a href="#cb20-53" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Predict future attack using predictor</span></span>
<span id="cb20-54"><a href="#cb20-54" aria-hidden="true" tabindex="-1"></a>    scores <span class="op">=</span> predictor(input_batch, dialog_lengths, dialog_lengths_list, utt_lengths, batch_indices, dialog_indices, batch_size, max_length)</span>
<span id="cb20-55"><a href="#cb20-55" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> (scores <span class="op">&gt;</span> <span class="fl">0.5</span>).<span class="bu">float</span>()</span>
<span id="cb20-56"><a href="#cb20-56" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> predictions, scores</span>
<span id="cb20-57"><a href="#cb20-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-58"><a href="#cb20-58" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> validate(dataset, encoder, context_encoder, predictor, voc, batch_size, device):</span>
<span id="cb20-59"><a href="#cb20-59" aria-hidden="true" tabindex="-1"></a>    <span class="co"># create a batch iterator for the given data</span></span>
<span id="cb20-60"><a href="#cb20-60" aria-hidden="true" tabindex="-1"></a>    batch_iterator <span class="op">=</span> batchIterator(voc, dataset, batch_size, shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb20-61"><a href="#cb20-61" aria-hidden="true" tabindex="-1"></a>    <span class="co"># find out how many iterations we will need to cover the whole dataset</span></span>
<span id="cb20-62"><a href="#cb20-62" aria-hidden="true" tabindex="-1"></a>    n_iters <span class="op">=</span> <span class="bu">len</span>(dataset) <span class="op">//</span> batch_size <span class="op">+</span> <span class="bu">int</span>(<span class="bu">len</span>(dataset) <span class="op">%</span> batch_size <span class="op">&gt;</span> <span class="dv">0</span>)</span>
<span id="cb20-63"><a href="#cb20-63" aria-hidden="true" tabindex="-1"></a>    <span class="co"># containers for full prediction results so we can compute accuracy at the end</span></span>
<span id="cb20-64"><a href="#cb20-64" aria-hidden="true" tabindex="-1"></a>    all_preds <span class="op">=</span> []</span>
<span id="cb20-65"><a href="#cb20-65" aria-hidden="true" tabindex="-1"></a>    all_labels <span class="op">=</span> []</span>
<span id="cb20-66"><a href="#cb20-66" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> iteration <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, n_iters<span class="op">+</span><span class="dv">1</span>):</span>
<span id="cb20-67"><a href="#cb20-67" aria-hidden="true" tabindex="-1"></a>        batch, batch_dialogs, _, true_batch_size <span class="op">=</span> <span class="bu">next</span>(batch_iterator)</span>
<span id="cb20-68"><a href="#cb20-68" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Extract fields from batch</span></span>
<span id="cb20-69"><a href="#cb20-69" aria-hidden="true" tabindex="-1"></a>        input_variable, dialog_lengths, utt_lengths, batch_indices, dialog_indices, labels, convo_ids, target_variable, mask, max_target_len <span class="op">=</span> batch</span>
<span id="cb20-70"><a href="#cb20-70" aria-hidden="true" tabindex="-1"></a>        dialog_lengths_list <span class="op">=</span> [<span class="bu">len</span>(x) <span class="cf">for</span> x <span class="kw">in</span> batch_dialogs]</span>
<span id="cb20-71"><a href="#cb20-71" aria-hidden="true" tabindex="-1"></a>        <span class="co"># run the model</span></span>
<span id="cb20-72"><a href="#cb20-72" aria-hidden="true" tabindex="-1"></a>        predictions, scores <span class="op">=</span> evaluateBatch(encoder, context_encoder, predictor, voc, input_variable,</span>
<span id="cb20-73"><a href="#cb20-73" aria-hidden="true" tabindex="-1"></a>                                            dialog_lengths, dialog_lengths_list, utt_lengths, batch_indices, dialog_indices,</span>
<span id="cb20-74"><a href="#cb20-74" aria-hidden="true" tabindex="-1"></a>                                            true_batch_size, device)</span>
<span id="cb20-75"><a href="#cb20-75" aria-hidden="true" tabindex="-1"></a>        <span class="co"># aggregate results for computing accuracy at the end</span></span>
<span id="cb20-76"><a href="#cb20-76" aria-hidden="true" tabindex="-1"></a>        all_preds <span class="op">+=</span> [p.item() <span class="cf">for</span> p <span class="kw">in</span> predictions]</span>
<span id="cb20-77"><a href="#cb20-77" aria-hidden="true" tabindex="-1"></a>        all_labels <span class="op">+=</span> [l.item() <span class="cf">for</span> l <span class="kw">in</span> labels]</span>
<span id="cb20-78"><a href="#cb20-78" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Iteration: </span><span class="sc">{}</span><span class="st">; Percent complete: </span><span class="sc">{:.1f}</span><span class="st">%"</span>.<span class="bu">format</span>(iteration, iteration <span class="op">/</span> n_iters <span class="op">*</span> <span class="dv">100</span>))</span>
<span id="cb20-79"><a href="#cb20-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-80"><a href="#cb20-80" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compute and return the accuracy</span></span>
<span id="cb20-81"><a href="#cb20-81" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (np.asarray(all_preds) <span class="op">==</span> np.asarray(all_labels)).mean()</span>
<span id="cb20-82"><a href="#cb20-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-83"><a href="#cb20-83" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> trainIters(voc, pairs, val_pairs, encoder, context_encoder, attack_clf,</span>
<span id="cb20-84"><a href="#cb20-84" aria-hidden="true" tabindex="-1"></a>               encoder_optimizer, context_encoder_optimizer, attack_clf_optimizer, embedding,</span>
<span id="cb20-85"><a href="#cb20-85" aria-hidden="true" tabindex="-1"></a>               n_iteration, batch_size, print_every, validate_every, clip):</span>
<span id="cb20-86"><a href="#cb20-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-87"><a href="#cb20-87" aria-hidden="true" tabindex="-1"></a>    <span class="co"># create a batch iterator for training data</span></span>
<span id="cb20-88"><a href="#cb20-88" aria-hidden="true" tabindex="-1"></a>    batch_iterator <span class="op">=</span> batchIterator(voc, pairs, batch_size)</span>
<span id="cb20-89"><a href="#cb20-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-90"><a href="#cb20-90" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initializations</span></span>
<span id="cb20-91"><a href="#cb20-91" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Initializing ...'</span>)</span>
<span id="cb20-92"><a href="#cb20-92" aria-hidden="true" tabindex="-1"></a>    start_iteration <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb20-93"><a href="#cb20-93" aria-hidden="true" tabindex="-1"></a>    print_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb20-94"><a href="#cb20-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-95"><a href="#cb20-95" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Training loop</span></span>
<span id="cb20-96"><a href="#cb20-96" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Training..."</span>)</span>
<span id="cb20-97"><a href="#cb20-97" aria-hidden="true" tabindex="-1"></a>    <span class="co"># keep track of best validation accuracy - only save when we have a model that beats the current best</span></span>
<span id="cb20-98"><a href="#cb20-98" aria-hidden="true" tabindex="-1"></a>    best_acc <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb20-99"><a href="#cb20-99" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> iteration <span class="kw">in</span> <span class="bu">range</span>(start_iteration, n_iteration <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb20-100"><a href="#cb20-100" aria-hidden="true" tabindex="-1"></a>        training_batch, training_dialogs, _, true_batch_size <span class="op">=</span> <span class="bu">next</span>(batch_iterator)</span>
<span id="cb20-101"><a href="#cb20-101" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Extract fields from batch</span></span>
<span id="cb20-102"><a href="#cb20-102" aria-hidden="true" tabindex="-1"></a>        input_variable, dialog_lengths, utt_lengths, batch_indices, dialog_indices, labels, _, target_variable, mask, max_target_len <span class="op">=</span> training_batch</span>
<span id="cb20-103"><a href="#cb20-103" aria-hidden="true" tabindex="-1"></a>        dialog_lengths_list <span class="op">=</span> [<span class="bu">len</span>(x) <span class="cf">for</span> x <span class="kw">in</span> training_dialogs]</span>
<span id="cb20-104"><a href="#cb20-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-105"><a href="#cb20-105" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Run a training iteration with batch</span></span>
<span id="cb20-106"><a href="#cb20-106" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> train(input_variable, dialog_lengths, dialog_lengths_list, utt_lengths, batch_indices, dialog_indices, labels, <span class="co"># input/output arguments</span></span>
<span id="cb20-107"><a href="#cb20-107" aria-hidden="true" tabindex="-1"></a>                     encoder, context_encoder, attack_clf,                                                                    <span class="co"># network arguments</span></span>
<span id="cb20-108"><a href="#cb20-108" aria-hidden="true" tabindex="-1"></a>                     encoder_optimizer, context_encoder_optimizer, attack_clf_optimizer,                                      <span class="co"># optimization arguments</span></span>
<span id="cb20-109"><a href="#cb20-109" aria-hidden="true" tabindex="-1"></a>                     true_batch_size, clip)                                                                                   <span class="co"># misc arguments</span></span>
<span id="cb20-110"><a href="#cb20-110" aria-hidden="true" tabindex="-1"></a>        print_loss <span class="op">+=</span> loss</span>
<span id="cb20-111"><a href="#cb20-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-112"><a href="#cb20-112" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Print progress</span></span>
<span id="cb20-113"><a href="#cb20-113" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> iteration <span class="op">%</span> print_every <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb20-114"><a href="#cb20-114" aria-hidden="true" tabindex="-1"></a>            print_loss_avg <span class="op">=</span> print_loss <span class="op">/</span> print_every</span>
<span id="cb20-115"><a href="#cb20-115" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Iteration: </span><span class="sc">{}</span><span class="st">; Percent complete: </span><span class="sc">{:.1f}</span><span class="st">%; Average loss: </span><span class="sc">{:.4f}</span><span class="st">"</span>.<span class="bu">format</span>(iteration, iteration <span class="op">/</span> n_iteration <span class="op">*</span> <span class="dv">100</span>, print_loss_avg))</span>
<span id="cb20-116"><a href="#cb20-116" aria-hidden="true" tabindex="-1"></a>            print_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb20-117"><a href="#cb20-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-118"><a href="#cb20-118" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Evaluate on validation set</span></span>
<span id="cb20-119"><a href="#cb20-119" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> (iteration <span class="op">%</span> validate_every <span class="op">==</span> <span class="dv">0</span>):</span>
<span id="cb20-120"><a href="#cb20-120" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Validating!"</span>)</span>
<span id="cb20-121"><a href="#cb20-121" aria-hidden="true" tabindex="-1"></a>            <span class="co"># put the network components into evaluation mode</span></span>
<span id="cb20-122"><a href="#cb20-122" aria-hidden="true" tabindex="-1"></a>            encoder.<span class="bu">eval</span>()</span>
<span id="cb20-123"><a href="#cb20-123" aria-hidden="true" tabindex="-1"></a>            context_encoder.<span class="bu">eval</span>()</span>
<span id="cb20-124"><a href="#cb20-124" aria-hidden="true" tabindex="-1"></a>            attack_clf.<span class="bu">eval</span>()</span>
<span id="cb20-125"><a href="#cb20-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-126"><a href="#cb20-126" aria-hidden="true" tabindex="-1"></a>            predictor <span class="op">=</span> Predictor(encoder, context_encoder, attack_clf)</span>
<span id="cb20-127"><a href="#cb20-127" aria-hidden="true" tabindex="-1"></a>            accuracy <span class="op">=</span> validate(val_pairs, encoder, context_encoder, predictor, voc, batch_size, device)</span>
<span id="cb20-128"><a href="#cb20-128" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Validation set accuracy: </span><span class="sc">{:.2f}</span><span class="st">%"</span>.<span class="bu">format</span>(accuracy <span class="op">*</span> <span class="dv">100</span>))</span>
<span id="cb20-129"><a href="#cb20-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-130"><a href="#cb20-130" aria-hidden="true" tabindex="-1"></a>            <span class="co"># keep track of our best model so far</span></span>
<span id="cb20-131"><a href="#cb20-131" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> accuracy <span class="op">&gt;</span> best_acc:</span>
<span id="cb20-132"><a href="#cb20-132" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="st">"Validation accuracy better than current best; saving model..."</span>)</span>
<span id="cb20-133"><a href="#cb20-133" aria-hidden="true" tabindex="-1"></a>                best_acc <span class="op">=</span> accuracy</span>
<span id="cb20-134"><a href="#cb20-134" aria-hidden="true" tabindex="-1"></a>                torch.save({</span>
<span id="cb20-135"><a href="#cb20-135" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'iteration'</span>: iteration,</span>
<span id="cb20-136"><a href="#cb20-136" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'en'</span>: encoder.state_dict(),</span>
<span id="cb20-137"><a href="#cb20-137" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'ctx'</span>: context_encoder.state_dict(),</span>
<span id="cb20-138"><a href="#cb20-138" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'atk_clf'</span>: attack_clf.state_dict(),</span>
<span id="cb20-139"><a href="#cb20-139" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'en_opt'</span>: encoder_optimizer.state_dict(),</span>
<span id="cb20-140"><a href="#cb20-140" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'ctx_opt'</span>: context_encoder_optimizer.state_dict(),</span>
<span id="cb20-141"><a href="#cb20-141" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'atk_clf_opt'</span>: attack_clf_optimizer.state_dict(),</span>
<span id="cb20-142"><a href="#cb20-142" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'loss'</span>: loss,</span>
<span id="cb20-143"><a href="#cb20-143" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'voc_dict'</span>: voc.__dict__,</span>
<span id="cb20-144"><a href="#cb20-144" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'embedding'</span>: embedding.state_dict()</span>
<span id="cb20-145"><a href="#cb20-145" aria-hidden="true" tabindex="-1"></a>                }, <span class="st">"finetuned_model.tar"</span>)</span>
<span id="cb20-146"><a href="#cb20-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-147"><a href="#cb20-147" aria-hidden="true" tabindex="-1"></a>            <span class="co"># put the network components back into training mode</span></span>
<span id="cb20-148"><a href="#cb20-148" aria-hidden="true" tabindex="-1"></a>            encoder.train()</span>
<span id="cb20-149"><a href="#cb20-149" aria-hidden="true" tabindex="-1"></a>            context_encoder.train()</span>
<span id="cb20-150"><a href="#cb20-150" aria-hidden="true" tabindex="-1"></a>            attack_clf.train()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="part-5-define-the-evaluation-procedure" class="level2">
<h2 class="anchored" data-anchor-id="part-5-define-the-evaluation-procedure">Part 5: define the evaluation procedure</h2>
<p>We’re almost ready to run! The last component we need is some code to evaluate performance on the test set after fine-tuning is completed. This evaluation should use the full iterative procedure described in the paper, replicating how a system might be deployed in practice, without knowledge of where the personal attack occurs</p>
<div id="cell-23" class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluateDataset(dataset, encoder, context_encoder, predictor, voc, batch_size, device):</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># create a batch iterator for the given data</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>    batch_iterator <span class="op">=</span> batchIterator(voc, dataset, batch_size, shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># find out how many iterations we will need to cover the whole dataset</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>    n_iters <span class="op">=</span> <span class="bu">len</span>(dataset) <span class="op">//</span> batch_size <span class="op">+</span> <span class="bu">int</span>(<span class="bu">len</span>(dataset) <span class="op">%</span> batch_size <span class="op">&gt;</span> <span class="dv">0</span>)</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>    output_df <span class="op">=</span> {</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>        <span class="st">"id"</span>: [],</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">"prediction"</span>: [],</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">"score"</span>: []</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> iteration <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, n_iters<span class="op">+</span><span class="dv">1</span>):</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>        batch, batch_dialogs, _, true_batch_size <span class="op">=</span> <span class="bu">next</span>(batch_iterator)</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Extract fields from batch</span></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>        input_variable, dialog_lengths, utt_lengths, batch_indices, dialog_indices, labels, convo_ids, target_variable, mask, max_target_len <span class="op">=</span> batch</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>        dialog_lengths_list <span class="op">=</span> [<span class="bu">len</span>(x) <span class="cf">for</span> x <span class="kw">in</span> batch_dialogs]</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># run the model</span></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>        predictions, scores <span class="op">=</span> evaluateBatch(encoder, context_encoder, predictor, voc, input_variable,</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>                                            dialog_lengths, dialog_lengths_list, utt_lengths, batch_indices, dialog_indices,</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>                                            true_batch_size, device)</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># format the output as a dataframe (which we can later re-join with the corpus)</span></span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(true_batch_size):</span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>            convo_id <span class="op">=</span> convo_ids[i]</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>            pred <span class="op">=</span> predictions[i].item()</span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>            score <span class="op">=</span> scores[i].item()</span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>            output_df[<span class="st">"id"</span>].append(convo_id)</span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>            output_df[<span class="st">"prediction"</span>].append(pred)</span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a>            output_df[<span class="st">"score"</span>].append(score)</span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Iteration: </span><span class="sc">{}</span><span class="st">; Percent complete: </span><span class="sc">{:.1f}</span><span class="st">%"</span>.<span class="bu">format</span>(iteration, iteration <span class="op">/</span> n_iters <span class="op">*</span> <span class="dv">100</span>))</span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pd.DataFrame(output_df).set_index(<span class="st">"id"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="part-6-build-and-fine-tune-the-model" class="level2">
<h2 class="anchored" data-anchor-id="part-6-build-and-fine-tune-the-model">Part 6: build and fine-tune the model</h2>
<p>We finally have all the components we need! Now we can instantiate the CRAFT model components, load the pre-trained weights, and run fine-tuning.</p>
<div id="cell-25" class="cell" data-outputid="99df8b29-f6cb-4fab-80db-611e73ab3869">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fix random state (affect native Python code only, does not affect PyTorch and hence does not guarantee reproducibility)</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>random.seed(<span class="dv">2019</span>)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Tell torch to use GPU. Note that if you are running this notebook in a non-GPU environment, you can change 'cuda' to 'cpu' to get the code to run.</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">'cuda'</span>)</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Loading saved parameters..."</span>)</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> os.path.isfile(<span class="st">"pretrained_model.tar"</span>):</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\t</span><span class="st">Downloading pre-trained CRAFT..."</span>)</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>    urlretrieve(MODEL_URL, <span class="st">"pretrained_model.tar"</span>)</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\t</span><span class="st">...Done!"</span>)</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>checkpoint <span class="op">=</span> torch.load(<span class="st">"pretrained_model.tar"</span>)</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a><span class="co"># If running in a non-GPU environment, you need to tell PyTorch to convert the parameters to CPU tensor format.</span></span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a><span class="co"># To do so, replace the previous line with the following:</span></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a><span class="co">#checkpoint = torch.load("model.tar", map_location=torch.device('cpu'))</span></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>encoder_sd <span class="op">=</span> checkpoint[<span class="st">'en'</span>]</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>context_sd <span class="op">=</span> checkpoint[<span class="st">'ctx'</span>]</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>embedding_sd <span class="op">=</span> checkpoint[<span class="st">'embedding'</span>]</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>voc.__dict__ <span class="op">=</span> checkpoint[<span class="st">'voc_dict'</span>]</span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Building encoders, decoder, and classifier...'</span>)</span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize word embeddings</span></span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a>embedding <span class="op">=</span> nn.Embedding(voc.num_words, hidden_size)</span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a>embedding.load_state_dict(embedding_sd)</span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize utterance and context encoders</span></span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a>encoder <span class="op">=</span> EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)</span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a>context_encoder <span class="op">=</span> ContextEncoderRNN(hidden_size, context_encoder_n_layers, dropout)</span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a>encoder.load_state_dict(encoder_sd)</span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a>context_encoder.load_state_dict(context_sd)</span>
<span id="cb22-30"><a href="#cb22-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize classifier</span></span>
<span id="cb22-31"><a href="#cb22-31" aria-hidden="true" tabindex="-1"></a>attack_clf <span class="op">=</span> SingleTargetClf(hidden_size, dropout)</span>
<span id="cb22-32"><a href="#cb22-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Use appropriate device</span></span>
<span id="cb22-33"><a href="#cb22-33" aria-hidden="true" tabindex="-1"></a>encoder <span class="op">=</span> encoder.to(device)</span>
<span id="cb22-34"><a href="#cb22-34" aria-hidden="true" tabindex="-1"></a>context_encoder <span class="op">=</span> context_encoder.to(device)</span>
<span id="cb22-35"><a href="#cb22-35" aria-hidden="true" tabindex="-1"></a>attack_clf <span class="op">=</span> attack_clf.to(device)</span>
<span id="cb22-36"><a href="#cb22-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Models built and ready to go!'</span>)</span>
<span id="cb22-37"><a href="#cb22-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-38"><a href="#cb22-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the number of training iterations we will need in order to achieve the number of epochs specified in the settings at the start of the notebook</span></span>
<span id="cb22-39"><a href="#cb22-39" aria-hidden="true" tabindex="-1"></a>n_iter_per_epoch <span class="op">=</span> <span class="bu">len</span>(train_pairs) <span class="op">//</span> batch_size <span class="op">+</span> <span class="bu">int</span>(<span class="bu">len</span>(train_pairs) <span class="op">%</span> batch_size <span class="op">==</span> <span class="dv">1</span>)</span>
<span id="cb22-40"><a href="#cb22-40" aria-hidden="true" tabindex="-1"></a>n_iteration <span class="op">=</span> n_iter_per_epoch <span class="op">*</span> train_epochs</span>
<span id="cb22-41"><a href="#cb22-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-42"><a href="#cb22-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Put dropout layers in train mode</span></span>
<span id="cb22-43"><a href="#cb22-43" aria-hidden="true" tabindex="-1"></a>encoder.train()</span>
<span id="cb22-44"><a href="#cb22-44" aria-hidden="true" tabindex="-1"></a>context_encoder.train()</span>
<span id="cb22-45"><a href="#cb22-45" aria-hidden="true" tabindex="-1"></a>attack_clf.train()</span>
<span id="cb22-46"><a href="#cb22-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-47"><a href="#cb22-47" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize optimizers</span></span>
<span id="cb22-48"><a href="#cb22-48" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Building optimizers...'</span>)</span>
<span id="cb22-49"><a href="#cb22-49" aria-hidden="true" tabindex="-1"></a>encoder_optimizer <span class="op">=</span> optim.Adam(encoder.parameters(), lr<span class="op">=</span>learning_rate)</span>
<span id="cb22-50"><a href="#cb22-50" aria-hidden="true" tabindex="-1"></a>context_encoder_optimizer <span class="op">=</span> optim.Adam(context_encoder.parameters(), lr<span class="op">=</span>learning_rate)</span>
<span id="cb22-51"><a href="#cb22-51" aria-hidden="true" tabindex="-1"></a>attack_clf_optimizer <span class="op">=</span> optim.Adam(attack_clf.parameters(), lr<span class="op">=</span>learning_rate)</span>
<span id="cb22-52"><a href="#cb22-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-53"><a href="#cb22-53" aria-hidden="true" tabindex="-1"></a><span class="co"># Run training iterations, validating after every epoch</span></span>
<span id="cb22-54"><a href="#cb22-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Starting Training!"</span>)</span>
<span id="cb22-55"><a href="#cb22-55" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Will train for </span><span class="sc">{}</span><span class="st"> iterations"</span>.<span class="bu">format</span>(n_iteration))</span>
<span id="cb22-56"><a href="#cb22-56" aria-hidden="true" tabindex="-1"></a>trainIters(voc, train_pairs, val_pairs, encoder, context_encoder, attack_clf,</span>
<span id="cb22-57"><a href="#cb22-57" aria-hidden="true" tabindex="-1"></a>           encoder_optimizer, context_encoder_optimizer, attack_clf_optimizer, embedding,</span>
<span id="cb22-58"><a href="#cb22-58" aria-hidden="true" tabindex="-1"></a>           n_iteration, batch_size, print_every, n_iter_per_epoch, clip)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Loading saved parameters...
Building encoders, decoder, and classifier...
Models built and ready to go!
Building optimizers...
Starting Training!
Will train for 1170 iterations
Initializing ...
Training...
Iteration: 10; Percent complete: 0.9%; Average loss: 0.6931
Iteration: 20; Percent complete: 1.7%; Average loss: 0.6928
Iteration: 30; Percent complete: 2.6%; Average loss: 0.6932
Validating!
Iteration: 1; Percent complete: 7.1%
Iteration: 2; Percent complete: 14.3%</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Iteration: 3; Percent complete: 21.4%
Iteration: 4; Percent complete: 28.6%
Iteration: 5; Percent complete: 35.7%
Iteration: 6; Percent complete: 42.9%
Iteration: 7; Percent complete: 50.0%
Iteration: 8; Percent complete: 57.1%
Iteration: 9; Percent complete: 64.3%
Iteration: 10; Percent complete: 71.4%
Iteration: 11; Percent complete: 78.6%
Iteration: 12; Percent complete: 85.7%
Iteration: 13; Percent complete: 92.9%
Iteration: 14; Percent complete: 100.0%
Validation set accuracy: 52.98%
Validation accuracy better than current best; saving model...
Iteration: 40; Percent complete: 3.4%; Average loss: 0.6932
Iteration: 50; Percent complete: 4.3%; Average loss: 0.6929
Iteration: 60; Percent complete: 5.1%; Average loss: 0.6928
Iteration: 70; Percent complete: 6.0%; Average loss: 0.6925
Validating!
Iteration: 1; Percent complete: 7.1%
Iteration: 2; Percent complete: 14.3%
Iteration: 3; Percent complete: 21.4%
Iteration: 4; Percent complete: 28.6%
Iteration: 5; Percent complete: 35.7%
Iteration: 6; Percent complete: 42.9%
Iteration: 7; Percent complete: 50.0%
Iteration: 8; Percent complete: 57.1%
Iteration: 9; Percent complete: 64.3%
Iteration: 10; Percent complete: 71.4%
Iteration: 11; Percent complete: 78.6%
Iteration: 12; Percent complete: 85.7%
Iteration: 13; Percent complete: 92.9%
Iteration: 14; Percent complete: 100.0%
Validation set accuracy: 55.95%
Validation accuracy better than current best; saving model...
Iteration: 80; Percent complete: 6.8%; Average loss: 0.6921
Iteration: 90; Percent complete: 7.7%; Average loss: 0.6925
Iteration: 100; Percent complete: 8.5%; Average loss: 0.6921
Iteration: 110; Percent complete: 9.4%; Average loss: 0.6923
Validating!
Iteration: 1; Percent complete: 7.1%
Iteration: 2; Percent complete: 14.3%
Iteration: 3; Percent complete: 21.4%
Iteration: 4; Percent complete: 28.6%
Iteration: 5; Percent complete: 35.7%
Iteration: 6; Percent complete: 42.9%
Iteration: 7; Percent complete: 50.0%
Iteration: 8; Percent complete: 57.1%
Iteration: 9; Percent complete: 64.3%
Iteration: 10; Percent complete: 71.4%
Iteration: 11; Percent complete: 78.6%
Iteration: 12; Percent complete: 85.7%
Iteration: 13; Percent complete: 92.9%
Iteration: 14; Percent complete: 100.0%
Validation set accuracy: 56.07%
Validation accuracy better than current best; saving model...
Iteration: 120; Percent complete: 10.3%; Average loss: 0.6918
Iteration: 130; Percent complete: 11.1%; Average loss: 0.6917
Iteration: 140; Percent complete: 12.0%; Average loss: 0.6914
Iteration: 150; Percent complete: 12.8%; Average loss: 0.6912
Validating!
Iteration: 1; Percent complete: 7.1%
Iteration: 2; Percent complete: 14.3%
Iteration: 3; Percent complete: 21.4%
Iteration: 4; Percent complete: 28.6%
Iteration: 5; Percent complete: 35.7%
Iteration: 6; Percent complete: 42.9%
Iteration: 7; Percent complete: 50.0%
Iteration: 8; Percent complete: 57.1%
Iteration: 9; Percent complete: 64.3%
Iteration: 10; Percent complete: 71.4%
Iteration: 11; Percent complete: 78.6%
Iteration: 12; Percent complete: 85.7%
Iteration: 13; Percent complete: 92.9%
Iteration: 14; Percent complete: 100.0%
Validation set accuracy: 58.21%
Validation accuracy better than current best; saving model...
Iteration: 160; Percent complete: 13.7%; Average loss: 0.6906
Iteration: 170; Percent complete: 14.5%; Average loss: 0.6910
Iteration: 180; Percent complete: 15.4%; Average loss: 0.6908
Iteration: 190; Percent complete: 16.2%; Average loss: 0.6903
Validating!
Iteration: 1; Percent complete: 7.1%
Iteration: 2; Percent complete: 14.3%
Iteration: 3; Percent complete: 21.4%
Iteration: 4; Percent complete: 28.6%
Iteration: 5; Percent complete: 35.7%
Iteration: 6; Percent complete: 42.9%
Iteration: 7; Percent complete: 50.0%
Iteration: 8; Percent complete: 57.1%
Iteration: 9; Percent complete: 64.3%
Iteration: 10; Percent complete: 71.4%
Iteration: 11; Percent complete: 78.6%
Iteration: 12; Percent complete: 85.7%
Iteration: 13; Percent complete: 92.9%
Iteration: 14; Percent complete: 100.0%
Validation set accuracy: 58.57%
Validation accuracy better than current best; saving model...
Iteration: 200; Percent complete: 17.1%; Average loss: 0.6901
Iteration: 210; Percent complete: 17.9%; Average loss: 0.6894
Iteration: 220; Percent complete: 18.8%; Average loss: 0.6895
Iteration: 230; Percent complete: 19.7%; Average loss: 0.6893
Validating!
Iteration: 1; Percent complete: 7.1%
Iteration: 2; Percent complete: 14.3%
Iteration: 3; Percent complete: 21.4%
Iteration: 4; Percent complete: 28.6%
Iteration: 5; Percent complete: 35.7%
Iteration: 6; Percent complete: 42.9%
Iteration: 7; Percent complete: 50.0%
Iteration: 8; Percent complete: 57.1%
Iteration: 9; Percent complete: 64.3%
Iteration: 10; Percent complete: 71.4%
Iteration: 11; Percent complete: 78.6%
Iteration: 12; Percent complete: 85.7%
Iteration: 13; Percent complete: 92.9%
Iteration: 14; Percent complete: 100.0%
Validation set accuracy: 58.21%
Iteration: 240; Percent complete: 20.5%; Average loss: 0.6885
Iteration: 250; Percent complete: 21.4%; Average loss: 0.6878
Iteration: 260; Percent complete: 22.2%; Average loss: 0.6878
Iteration: 270; Percent complete: 23.1%; Average loss: 0.6877
Validating!
Iteration: 1; Percent complete: 7.1%
Iteration: 2; Percent complete: 14.3%
Iteration: 3; Percent complete: 21.4%
Iteration: 4; Percent complete: 28.6%
Iteration: 5; Percent complete: 35.7%
Iteration: 6; Percent complete: 42.9%
Iteration: 7; Percent complete: 50.0%
Iteration: 8; Percent complete: 57.1%
Iteration: 9; Percent complete: 64.3%
Iteration: 10; Percent complete: 71.4%
Iteration: 11; Percent complete: 78.6%
Iteration: 12; Percent complete: 85.7%
Iteration: 13; Percent complete: 92.9%
Iteration: 14; Percent complete: 100.0%
Validation set accuracy: 59.64%
Validation accuracy better than current best; saving model...
Iteration: 280; Percent complete: 23.9%; Average loss: 0.6875
Iteration: 290; Percent complete: 24.8%; Average loss: 0.6864
Iteration: 300; Percent complete: 25.6%; Average loss: 0.6854
Iteration: 310; Percent complete: 26.5%; Average loss: 0.6850
Validating!
Iteration: 1; Percent complete: 7.1%
Iteration: 2; Percent complete: 14.3%
Iteration: 3; Percent complete: 21.4%
Iteration: 4; Percent complete: 28.6%
Iteration: 5; Percent complete: 35.7%
Iteration: 6; Percent complete: 42.9%
Iteration: 7; Percent complete: 50.0%
Iteration: 8; Percent complete: 57.1%
Iteration: 9; Percent complete: 64.3%
Iteration: 10; Percent complete: 71.4%
Iteration: 11; Percent complete: 78.6%
Iteration: 12; Percent complete: 85.7%
Iteration: 13; Percent complete: 92.9%
Iteration: 14; Percent complete: 100.0%
Validation set accuracy: 60.24%
Validation accuracy better than current best; saving model...
Iteration: 320; Percent complete: 27.4%; Average loss: 0.6832
Iteration: 330; Percent complete: 28.2%; Average loss: 0.6822
Iteration: 340; Percent complete: 29.1%; Average loss: 0.6811
Iteration: 350; Percent complete: 29.9%; Average loss: 0.6811
Validating!
Iteration: 1; Percent complete: 7.1%
Iteration: 2; Percent complete: 14.3%
Iteration: 3; Percent complete: 21.4%
Iteration: 4; Percent complete: 28.6%
Iteration: 5; Percent complete: 35.7%
Iteration: 6; Percent complete: 42.9%
Iteration: 7; Percent complete: 50.0%
Iteration: 8; Percent complete: 57.1%
Iteration: 9; Percent complete: 64.3%
Iteration: 10; Percent complete: 71.4%
Iteration: 11; Percent complete: 78.6%
Iteration: 12; Percent complete: 85.7%
Iteration: 13; Percent complete: 92.9%
Iteration: 14; Percent complete: 100.0%
Validation set accuracy: 60.24%
Iteration: 360; Percent complete: 30.8%; Average loss: 0.6828
Iteration: 370; Percent complete: 31.6%; Average loss: 0.6757
Iteration: 380; Percent complete: 32.5%; Average loss: 0.6757
Iteration: 390; Percent complete: 33.3%; Average loss: 0.6710
Validating!
Iteration: 1; Percent complete: 7.1%
Iteration: 2; Percent complete: 14.3%
Iteration: 3; Percent complete: 21.4%
Iteration: 4; Percent complete: 28.6%
Iteration: 5; Percent complete: 35.7%
Iteration: 6; Percent complete: 42.9%
Iteration: 7; Percent complete: 50.0%
Iteration: 8; Percent complete: 57.1%
Iteration: 9; Percent complete: 64.3%
Iteration: 10; Percent complete: 71.4%
Iteration: 11; Percent complete: 78.6%
Iteration: 12; Percent complete: 85.7%
Iteration: 13; Percent complete: 92.9%
Iteration: 14; Percent complete: 100.0%
Validation set accuracy: 62.14%
Validation accuracy better than current best; saving model...
Iteration: 400; Percent complete: 34.2%; Average loss: 0.6723
Iteration: 410; Percent complete: 35.0%; Average loss: 0.6672
Iteration: 420; Percent complete: 35.9%; Average loss: 0.6620
Validating!
Iteration: 1; Percent complete: 7.1%
Iteration: 2; Percent complete: 14.3%
Iteration: 3; Percent complete: 21.4%
Iteration: 4; Percent complete: 28.6%
Iteration: 5; Percent complete: 35.7%
Iteration: 6; Percent complete: 42.9%
Iteration: 7; Percent complete: 50.0%
Iteration: 8; Percent complete: 57.1%
Iteration: 9; Percent complete: 64.3%
Iteration: 10; Percent complete: 71.4%
Iteration: 11; Percent complete: 78.6%
Iteration: 12; Percent complete: 85.7%
Iteration: 13; Percent complete: 92.9%
Iteration: 14; Percent complete: 100.0%
Validation set accuracy: 62.14%
Iteration: 430; Percent complete: 36.8%; Average loss: 0.6573
Iteration: 440; Percent complete: 37.6%; Average loss: 0.6551
Iteration: 450; Percent complete: 38.5%; Average loss: 0.6458
Iteration: 460; Percent complete: 39.3%; Average loss: 0.6489
Validating!
Iteration: 1; Percent complete: 7.1%
Iteration: 2; Percent complete: 14.3%
Iteration: 3; Percent complete: 21.4%
Iteration: 4; Percent complete: 28.6%
Iteration: 5; Percent complete: 35.7%
Iteration: 6; Percent complete: 42.9%
Iteration: 7; Percent complete: 50.0%
Iteration: 8; Percent complete: 57.1%
Iteration: 9; Percent complete: 64.3%
Iteration: 10; Percent complete: 71.4%
Iteration: 11; Percent complete: 78.6%
Iteration: 12; Percent complete: 85.7%
Iteration: 13; Percent complete: 92.9%
Iteration: 14; Percent complete: 100.0%
Validation set accuracy: 62.86%
Validation accuracy better than current best; saving model...
Iteration: 470; Percent complete: 40.2%; Average loss: 0.6323
Iteration: 480; Percent complete: 41.0%; Average loss: 0.6192
Iteration: 490; Percent complete: 41.9%; Average loss: 0.6178
Iteration: 500; Percent complete: 42.7%; Average loss: 0.6014
Validating!
Iteration: 1; Percent complete: 7.1%
Iteration: 2; Percent complete: 14.3%
Iteration: 3; Percent complete: 21.4%
Iteration: 4; Percent complete: 28.6%
Iteration: 5; Percent complete: 35.7%
Iteration: 6; Percent complete: 42.9%
Iteration: 7; Percent complete: 50.0%
Iteration: 8; Percent complete: 57.1%
Iteration: 9; Percent complete: 64.3%
Iteration: 10; Percent complete: 71.4%
Iteration: 11; Percent complete: 78.6%
Iteration: 12; Percent complete: 85.7%
Iteration: 13; Percent complete: 92.9%
Iteration: 14; Percent complete: 100.0%
Validation set accuracy: 64.76%
Validation accuracy better than current best; saving model...
Iteration: 510; Percent complete: 43.6%; Average loss: 0.5925
Iteration: 520; Percent complete: 44.4%; Average loss: 0.5889
Iteration: 530; Percent complete: 45.3%; Average loss: 0.5653
Iteration: 540; Percent complete: 46.2%; Average loss: 0.5628
Validating!
Iteration: 1; Percent complete: 7.1%
Iteration: 2; Percent complete: 14.3%
Iteration: 3; Percent complete: 21.4%
Iteration: 4; Percent complete: 28.6%
Iteration: 5; Percent complete: 35.7%
Iteration: 6; Percent complete: 42.9%
Iteration: 7; Percent complete: 50.0%
Iteration: 8; Percent complete: 57.1%
Iteration: 9; Percent complete: 64.3%
Iteration: 10; Percent complete: 71.4%
Iteration: 11; Percent complete: 78.6%
Iteration: 12; Percent complete: 85.7%
Iteration: 13; Percent complete: 92.9%
Iteration: 14; Percent complete: 100.0%
Validation set accuracy: 64.52%
Iteration: 550; Percent complete: 47.0%; Average loss: 0.5631
Iteration: 560; Percent complete: 47.9%; Average loss: 0.5645
Iteration: 570; Percent complete: 48.7%; Average loss: 0.5232
Iteration: 580; Percent complete: 49.6%; Average loss: 0.5292
Validating!
Iteration: 1; Percent complete: 7.1%
Iteration: 2; Percent complete: 14.3%
Iteration: 3; Percent complete: 21.4%
Iteration: 4; Percent complete: 28.6%
Iteration: 5; Percent complete: 35.7%
Iteration: 6; Percent complete: 42.9%
Iteration: 7; Percent complete: 50.0%
Iteration: 8; Percent complete: 57.1%
Iteration: 9; Percent complete: 64.3%
Iteration: 10; Percent complete: 71.4%
Iteration: 11; Percent complete: 78.6%
Iteration: 12; Percent complete: 85.7%
Iteration: 13; Percent complete: 92.9%
Iteration: 14; Percent complete: 100.0%
Validation set accuracy: 64.17%
Iteration: 590; Percent complete: 50.4%; Average loss: 0.5362
Iteration: 600; Percent complete: 51.3%; Average loss: 0.5371
Iteration: 610; Percent complete: 52.1%; Average loss: 0.5146
Iteration: 620; Percent complete: 53.0%; Average loss: 0.5136
Validating!
Iteration: 1; Percent complete: 7.1%
Iteration: 2; Percent complete: 14.3%
Iteration: 3; Percent complete: 21.4%
Iteration: 4; Percent complete: 28.6%
Iteration: 5; Percent complete: 35.7%
Iteration: 6; Percent complete: 42.9%
Iteration: 7; Percent complete: 50.0%
Iteration: 8; Percent complete: 57.1%
Iteration: 9; Percent complete: 64.3%
Iteration: 10; Percent complete: 71.4%
Iteration: 11; Percent complete: 78.6%
Iteration: 12; Percent complete: 85.7%
Iteration: 13; Percent complete: 92.9%
Iteration: 14; Percent complete: 100.0%
Validation set accuracy: 64.88%
Validation accuracy better than current best; saving model...
Iteration: 630; Percent complete: 53.8%; Average loss: 0.4756
Iteration: 640; Percent complete: 54.7%; Average loss: 0.4970
Iteration: 650; Percent complete: 55.6%; Average loss: 0.4534
Iteration: 660; Percent complete: 56.4%; Average loss: 0.4884
Validating!
Iteration: 1; Percent complete: 7.1%
Iteration: 2; Percent complete: 14.3%
Iteration: 3; Percent complete: 21.4%
Iteration: 4; Percent complete: 28.6%
Iteration: 5; Percent complete: 35.7%
Iteration: 6; Percent complete: 42.9%
Iteration: 7; Percent complete: 50.0%
Iteration: 8; Percent complete: 57.1%
Iteration: 9; Percent complete: 64.3%
Iteration: 10; Percent complete: 71.4%
Iteration: 11; Percent complete: 78.6%
Iteration: 12; Percent complete: 85.7%
Iteration: 13; Percent complete: 92.9%
Iteration: 14; Percent complete: 100.0%
Validation set accuracy: 64.52%
Iteration: 670; Percent complete: 57.3%; Average loss: 0.4638
Iteration: 680; Percent complete: 58.1%; Average loss: 0.4493
Iteration: 690; Percent complete: 59.0%; Average loss: 0.4276
Iteration: 700; Percent complete: 59.8%; Average loss: 0.4350
Validating!
Iteration: 1; Percent complete: 7.1%
Iteration: 2; Percent complete: 14.3%
Iteration: 3; Percent complete: 21.4%
Iteration: 4; Percent complete: 28.6%
Iteration: 5; Percent complete: 35.7%
Iteration: 6; Percent complete: 42.9%
Iteration: 7; Percent complete: 50.0%
Iteration: 8; Percent complete: 57.1%
Iteration: 9; Percent complete: 64.3%
Iteration: 10; Percent complete: 71.4%
Iteration: 11; Percent complete: 78.6%
Iteration: 12; Percent complete: 85.7%
Iteration: 13; Percent complete: 92.9%
Iteration: 14; Percent complete: 100.0%
Validation set accuracy: 64.40%
Iteration: 710; Percent complete: 60.7%; Average loss: 0.4465
Iteration: 720; Percent complete: 61.5%; Average loss: 0.4442
Iteration: 730; Percent complete: 62.4%; Average loss: 0.3888
Iteration: 740; Percent complete: 63.2%; Average loss: 0.3680
Validating!
Iteration: 1; Percent complete: 7.1%
Iteration: 2; Percent complete: 14.3%
Iteration: 3; Percent complete: 21.4%
Iteration: 4; Percent complete: 28.6%
Iteration: 5; Percent complete: 35.7%
Iteration: 6; Percent complete: 42.9%
Iteration: 7; Percent complete: 50.0%
Iteration: 8; Percent complete: 57.1%
Iteration: 9; Percent complete: 64.3%
Iteration: 10; Percent complete: 71.4%
Iteration: 11; Percent complete: 78.6%
Iteration: 12; Percent complete: 85.7%
Iteration: 13; Percent complete: 92.9%
Iteration: 14; Percent complete: 100.0%
Validation set accuracy: 64.52%
Iteration: 750; Percent complete: 64.1%; Average loss: 0.4093
Iteration: 760; Percent complete: 65.0%; Average loss: 0.4613
Iteration: 770; Percent complete: 65.8%; Average loss: 0.3405
Iteration: 780; Percent complete: 66.7%; Average loss: 0.3864
Validating!
Iteration: 1; Percent complete: 7.1%
Iteration: 2; Percent complete: 14.3%
Iteration: 3; Percent complete: 21.4%
Iteration: 4; Percent complete: 28.6%
Iteration: 5; Percent complete: 35.7%
Iteration: 6; Percent complete: 42.9%
Iteration: 7; Percent complete: 50.0%
Iteration: 8; Percent complete: 57.1%
Iteration: 9; Percent complete: 64.3%
Iteration: 10; Percent complete: 71.4%
Iteration: 11; Percent complete: 78.6%
Iteration: 12; Percent complete: 85.7%
Iteration: 13; Percent complete: 92.9%
Iteration: 14; Percent complete: 100.0%
Validation set accuracy: 65.24%
Validation accuracy better than current best; saving model...
Iteration: 790; Percent complete: 67.5%; Average loss: 0.3877
Iteration: 800; Percent complete: 68.4%; Average loss: 0.3566
Iteration: 810; Percent complete: 69.2%; Average loss: 0.3338
Validating!
Iteration: 1; Percent complete: 7.1%
Iteration: 2; Percent complete: 14.3%
Iteration: 3; Percent complete: 21.4%
Iteration: 4; Percent complete: 28.6%
Iteration: 5; Percent complete: 35.7%
Iteration: 6; Percent complete: 42.9%
Iteration: 7; Percent complete: 50.0%
Iteration: 8; Percent complete: 57.1%
Iteration: 9; Percent complete: 64.3%
Iteration: 10; Percent complete: 71.4%
Iteration: 11; Percent complete: 78.6%
Iteration: 12; Percent complete: 85.7%
Iteration: 13; Percent complete: 92.9%
Iteration: 14; Percent complete: 100.0%
Validation set accuracy: 64.64%
Iteration: 820; Percent complete: 70.1%; Average loss: 0.3410
Iteration: 830; Percent complete: 70.9%; Average loss: 0.3472
Iteration: 840; Percent complete: 71.8%; Average loss: 0.3186
Iteration: 850; Percent complete: 72.6%; Average loss: 0.3243
Validating!
Iteration: 1; Percent complete: 7.1%
Iteration: 2; Percent complete: 14.3%
Iteration: 3; Percent complete: 21.4%
Iteration: 4; Percent complete: 28.6%
Iteration: 5; Percent complete: 35.7%
Iteration: 6; Percent complete: 42.9%
Iteration: 7; Percent complete: 50.0%
Iteration: 8; Percent complete: 57.1%
Iteration: 9; Percent complete: 64.3%
Iteration: 10; Percent complete: 71.4%
Iteration: 11; Percent complete: 78.6%
Iteration: 12; Percent complete: 85.7%
Iteration: 13; Percent complete: 92.9%
Iteration: 14; Percent complete: 100.0%
Validation set accuracy: 65.36%
Validation accuracy better than current best; saving model...
Iteration: 860; Percent complete: 73.5%; Average loss: 0.3046
Iteration: 870; Percent complete: 74.4%; Average loss: 0.2941
Iteration: 880; Percent complete: 75.2%; Average loss: 0.3040
Iteration: 890; Percent complete: 76.1%; Average loss: 0.2523
Validating!
Iteration: 1; Percent complete: 7.1%
Iteration: 2; Percent complete: 14.3%
Iteration: 3; Percent complete: 21.4%
Iteration: 4; Percent complete: 28.6%
Iteration: 5; Percent complete: 35.7%
Iteration: 6; Percent complete: 42.9%
Iteration: 7; Percent complete: 50.0%
Iteration: 8; Percent complete: 57.1%
Iteration: 9; Percent complete: 64.3%
Iteration: 10; Percent complete: 71.4%
Iteration: 11; Percent complete: 78.6%
Iteration: 12; Percent complete: 85.7%
Iteration: 13; Percent complete: 92.9%
Iteration: 14; Percent complete: 100.0%
Validation set accuracy: 65.36%
Iteration: 900; Percent complete: 76.9%; Average loss: 0.2909
Iteration: 910; Percent complete: 77.8%; Average loss: 0.2636
Iteration: 920; Percent complete: 78.6%; Average loss: 0.3216
Iteration: 930; Percent complete: 79.5%; Average loss: 0.2464
Validating!
Iteration: 1; Percent complete: 7.1%
Iteration: 2; Percent complete: 14.3%
Iteration: 3; Percent complete: 21.4%
Iteration: 4; Percent complete: 28.6%
Iteration: 5; Percent complete: 35.7%
Iteration: 6; Percent complete: 42.9%
Iteration: 7; Percent complete: 50.0%
Iteration: 8; Percent complete: 57.1%
Iteration: 9; Percent complete: 64.3%
Iteration: 10; Percent complete: 71.4%
Iteration: 11; Percent complete: 78.6%
Iteration: 12; Percent complete: 85.7%
Iteration: 13; Percent complete: 92.9%
Iteration: 14; Percent complete: 100.0%
Validation set accuracy: 65.83%
Validation accuracy better than current best; saving model...
Iteration: 940; Percent complete: 80.3%; Average loss: 0.2263
Iteration: 950; Percent complete: 81.2%; Average loss: 0.2287
Iteration: 960; Percent complete: 82.1%; Average loss: 0.2494
Iteration: 970; Percent complete: 82.9%; Average loss: 0.2394
Validating!
Iteration: 1; Percent complete: 7.1%
Iteration: 2; Percent complete: 14.3%
Iteration: 3; Percent complete: 21.4%
Iteration: 4; Percent complete: 28.6%
Iteration: 5; Percent complete: 35.7%
Iteration: 6; Percent complete: 42.9%
Iteration: 7; Percent complete: 50.0%
Iteration: 8; Percent complete: 57.1%
Iteration: 9; Percent complete: 64.3%
Iteration: 10; Percent complete: 71.4%
Iteration: 11; Percent complete: 78.6%
Iteration: 12; Percent complete: 85.7%
Iteration: 13; Percent complete: 92.9%
Iteration: 14; Percent complete: 100.0%
Validation set accuracy: 65.71%
Iteration: 980; Percent complete: 83.8%; Average loss: 0.2072
Iteration: 990; Percent complete: 84.6%; Average loss: 0.1860
Iteration: 1000; Percent complete: 85.5%; Average loss: 0.2065
Iteration: 1010; Percent complete: 86.3%; Average loss: 0.1825
Validating!
Iteration: 1; Percent complete: 7.1%
Iteration: 2; Percent complete: 14.3%
Iteration: 3; Percent complete: 21.4%
Iteration: 4; Percent complete: 28.6%
Iteration: 5; Percent complete: 35.7%
Iteration: 6; Percent complete: 42.9%
Iteration: 7; Percent complete: 50.0%
Iteration: 8; Percent complete: 57.1%
Iteration: 9; Percent complete: 64.3%
Iteration: 10; Percent complete: 71.4%
Iteration: 11; Percent complete: 78.6%
Iteration: 12; Percent complete: 85.7%
Iteration: 13; Percent complete: 92.9%
Iteration: 14; Percent complete: 100.0%
Validation set accuracy: 65.71%
Iteration: 1020; Percent complete: 87.2%; Average loss: 0.1563
Iteration: 1030; Percent complete: 88.0%; Average loss: 0.1951
Iteration: 1040; Percent complete: 88.9%; Average loss: 0.1809
Iteration: 1050; Percent complete: 89.7%; Average loss: 0.1757
Validating!
Iteration: 1; Percent complete: 7.1%
Iteration: 2; Percent complete: 14.3%
Iteration: 3; Percent complete: 21.4%
Iteration: 4; Percent complete: 28.6%
Iteration: 5; Percent complete: 35.7%
Iteration: 6; Percent complete: 42.9%
Iteration: 7; Percent complete: 50.0%
Iteration: 8; Percent complete: 57.1%
Iteration: 9; Percent complete: 64.3%
Iteration: 10; Percent complete: 71.4%
Iteration: 11; Percent complete: 78.6%
Iteration: 12; Percent complete: 85.7%
Iteration: 13; Percent complete: 92.9%
Iteration: 14; Percent complete: 100.0%
Validation set accuracy: 65.71%
Iteration: 1060; Percent complete: 90.6%; Average loss: 0.1550
Iteration: 1070; Percent complete: 91.5%; Average loss: 0.1622
Iteration: 1080; Percent complete: 92.3%; Average loss: 0.1301
Iteration: 1090; Percent complete: 93.2%; Average loss: 0.1117
Validating!
Iteration: 1; Percent complete: 7.1%
Iteration: 2; Percent complete: 14.3%
Iteration: 3; Percent complete: 21.4%
Iteration: 4; Percent complete: 28.6%
Iteration: 5; Percent complete: 35.7%
Iteration: 6; Percent complete: 42.9%
Iteration: 7; Percent complete: 50.0%
Iteration: 8; Percent complete: 57.1%
Iteration: 9; Percent complete: 64.3%
Iteration: 10; Percent complete: 71.4%
Iteration: 11; Percent complete: 78.6%
Iteration: 12; Percent complete: 85.7%
Iteration: 13; Percent complete: 92.9%
Iteration: 14; Percent complete: 100.0%
Validation set accuracy: 65.71%
Iteration: 1100; Percent complete: 94.0%; Average loss: 0.1553
Iteration: 1110; Percent complete: 94.9%; Average loss: 0.1188
Iteration: 1120; Percent complete: 95.7%; Average loss: 0.1326
Iteration: 1130; Percent complete: 96.6%; Average loss: 0.1339
Validating!
Iteration: 1; Percent complete: 7.1%
Iteration: 2; Percent complete: 14.3%
Iteration: 3; Percent complete: 21.4%
Iteration: 4; Percent complete: 28.6%
Iteration: 5; Percent complete: 35.7%
Iteration: 6; Percent complete: 42.9%
Iteration: 7; Percent complete: 50.0%
Iteration: 8; Percent complete: 57.1%
Iteration: 9; Percent complete: 64.3%
Iteration: 10; Percent complete: 71.4%
Iteration: 11; Percent complete: 78.6%
Iteration: 12; Percent complete: 85.7%
Iteration: 13; Percent complete: 92.9%
Iteration: 14; Percent complete: 100.0%
Validation set accuracy: 65.60%
Iteration: 1140; Percent complete: 97.4%; Average loss: 0.1078
Iteration: 1150; Percent complete: 98.3%; Average loss: 0.1155
Iteration: 1160; Percent complete: 99.1%; Average loss: 0.1010
Iteration: 1170; Percent complete: 100.0%; Average loss: 0.0923
Validating!
Iteration: 1; Percent complete: 7.1%
Iteration: 2; Percent complete: 14.3%
Iteration: 3; Percent complete: 21.4%
Iteration: 4; Percent complete: 28.6%
Iteration: 5; Percent complete: 35.7%
Iteration: 6; Percent complete: 42.9%
Iteration: 7; Percent complete: 50.0%
Iteration: 8; Percent complete: 57.1%
Iteration: 9; Percent complete: 64.3%
Iteration: 10; Percent complete: 71.4%
Iteration: 11; Percent complete: 78.6%
Iteration: 12; Percent complete: 85.7%
Iteration: 13; Percent complete: 92.9%
Iteration: 14; Percent complete: 100.0%
Validation set accuracy: 65.12%</code></pre>
</div>
</div>
</section>
<section id="part-7-run-test-set-evaluation" class="level2">
<h2 class="anchored" data-anchor-id="part-7-run-test-set-evaluation">Part 7: run test set evaluation</h2>
<p>Now that we have successfully fine-tuned the model, we run it on the test set so that we can evaluate performance.</p>
<div id="cell-27" class="cell" data-outputid="154d7581-37a7-48e7-c203-9d3a97c472ed">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fix random state for reproducibility</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>random.seed(<span class="dv">2019</span>)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Tell torch to use GPU. Note that if you are running this notebook in a non-GPU environment, you can change 'cuda' to 'cpu' to get the code to run.</span></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">'cuda'</span>)</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Loading saved parameters..."</span>)</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>checkpoint <span class="op">=</span> torch.load(<span class="st">"finetuned_model.tar"</span>)</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a><span class="co"># If running in a non-GPU environment, you need to tell PyTorch to convert the parameters to CPU tensor format.</span></span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a><span class="co"># To do so, replace the previous line with the following:</span></span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a><span class="co">#checkpoint = torch.load("model.tar", map_location=torch.device('cpu'))</span></span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>encoder_sd <span class="op">=</span> checkpoint[<span class="st">'en'</span>]</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>context_sd <span class="op">=</span> checkpoint[<span class="st">'ctx'</span>]</span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>attack_clf_sd <span class="op">=</span> checkpoint[<span class="st">'atk_clf'</span>]</span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>embedding_sd <span class="op">=</span> checkpoint[<span class="st">'embedding'</span>]</span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a>voc.__dict__ <span class="op">=</span> checkpoint[<span class="st">'voc_dict'</span>]</span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Building encoders, decoder, and classifier...'</span>)</span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize word embeddings</span></span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a>embedding <span class="op">=</span> nn.Embedding(voc.num_words, hidden_size)</span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a>embedding.load_state_dict(embedding_sd)</span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize utterance and context encoders</span></span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a>encoder <span class="op">=</span> EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)</span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a>context_encoder <span class="op">=</span> ContextEncoderRNN(hidden_size, context_encoder_n_layers, dropout)</span>
<span id="cb26-25"><a href="#cb26-25" aria-hidden="true" tabindex="-1"></a>encoder.load_state_dict(encoder_sd)</span>
<span id="cb26-26"><a href="#cb26-26" aria-hidden="true" tabindex="-1"></a>context_encoder.load_state_dict(context_sd)</span>
<span id="cb26-27"><a href="#cb26-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize classifier</span></span>
<span id="cb26-28"><a href="#cb26-28" aria-hidden="true" tabindex="-1"></a>attack_clf <span class="op">=</span> SingleTargetClf(hidden_size, dropout)</span>
<span id="cb26-29"><a href="#cb26-29" aria-hidden="true" tabindex="-1"></a>attack_clf.load_state_dict(attack_clf_sd)</span>
<span id="cb26-30"><a href="#cb26-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Use appropriate device</span></span>
<span id="cb26-31"><a href="#cb26-31" aria-hidden="true" tabindex="-1"></a>encoder <span class="op">=</span> encoder.to(device)</span>
<span id="cb26-32"><a href="#cb26-32" aria-hidden="true" tabindex="-1"></a>context_encoder <span class="op">=</span> context_encoder.to(device)</span>
<span id="cb26-33"><a href="#cb26-33" aria-hidden="true" tabindex="-1"></a>attack_clf <span class="op">=</span> attack_clf.to(device)</span>
<span id="cb26-34"><a href="#cb26-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Models built and ready to go!'</span>)</span>
<span id="cb26-35"><a href="#cb26-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-36"><a href="#cb26-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Set dropout layers to eval mode</span></span>
<span id="cb26-37"><a href="#cb26-37" aria-hidden="true" tabindex="-1"></a>encoder.<span class="bu">eval</span>()</span>
<span id="cb26-38"><a href="#cb26-38" aria-hidden="true" tabindex="-1"></a>context_encoder.<span class="bu">eval</span>()</span>
<span id="cb26-39"><a href="#cb26-39" aria-hidden="true" tabindex="-1"></a>attack_clf.<span class="bu">eval</span>()</span>
<span id="cb26-40"><a href="#cb26-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-41"><a href="#cb26-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the pipeline</span></span>
<span id="cb26-42"><a href="#cb26-42" aria-hidden="true" tabindex="-1"></a>predictor <span class="op">=</span> Predictor(encoder, context_encoder, attack_clf)</span>
<span id="cb26-43"><a href="#cb26-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-44"><a href="#cb26-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the pipeline!</span></span>
<span id="cb26-45"><a href="#cb26-45" aria-hidden="true" tabindex="-1"></a>forecasts_df <span class="op">=</span> evaluateDataset(test_pairs, encoder, context_encoder, predictor, voc, batch_size, device)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Loading saved parameters...
Building encoders, decoder, and classifier...
Models built and ready to go!
Iteration: 1; Percent complete: 1.4%
Iteration: 2; Percent complete: 2.9%
Iteration: 3; Percent complete: 4.3%</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Iteration: 4; Percent complete: 5.8%
Iteration: 5; Percent complete: 7.2%
Iteration: 6; Percent complete: 8.7%
Iteration: 7; Percent complete: 10.1%
Iteration: 8; Percent complete: 11.6%
Iteration: 9; Percent complete: 13.0%
Iteration: 10; Percent complete: 14.5%
Iteration: 11; Percent complete: 15.9%
Iteration: 12; Percent complete: 17.4%
Iteration: 13; Percent complete: 18.8%
Iteration: 14; Percent complete: 20.3%
Iteration: 15; Percent complete: 21.7%
Iteration: 16; Percent complete: 23.2%
Iteration: 17; Percent complete: 24.6%
Iteration: 18; Percent complete: 26.1%
Iteration: 19; Percent complete: 27.5%
Iteration: 20; Percent complete: 29.0%
Iteration: 21; Percent complete: 30.4%
Iteration: 22; Percent complete: 31.9%
Iteration: 23; Percent complete: 33.3%
Iteration: 24; Percent complete: 34.8%
Iteration: 25; Percent complete: 36.2%
Iteration: 26; Percent complete: 37.7%
Iteration: 27; Percent complete: 39.1%
Iteration: 28; Percent complete: 40.6%
Iteration: 29; Percent complete: 42.0%
Iteration: 30; Percent complete: 43.5%
Iteration: 31; Percent complete: 44.9%
Iteration: 32; Percent complete: 46.4%
Iteration: 33; Percent complete: 47.8%
Iteration: 34; Percent complete: 49.3%
Iteration: 35; Percent complete: 50.7%
Iteration: 36; Percent complete: 52.2%
Iteration: 37; Percent complete: 53.6%
Iteration: 38; Percent complete: 55.1%
Iteration: 39; Percent complete: 56.5%
Iteration: 40; Percent complete: 58.0%
Iteration: 41; Percent complete: 59.4%
Iteration: 42; Percent complete: 60.9%
Iteration: 43; Percent complete: 62.3%
Iteration: 44; Percent complete: 63.8%
Iteration: 45; Percent complete: 65.2%
Iteration: 46; Percent complete: 66.7%
Iteration: 47; Percent complete: 68.1%
Iteration: 48; Percent complete: 69.6%
Iteration: 49; Percent complete: 71.0%
Iteration: 50; Percent complete: 72.5%
Iteration: 51; Percent complete: 73.9%
Iteration: 52; Percent complete: 75.4%
Iteration: 53; Percent complete: 76.8%
Iteration: 54; Percent complete: 78.3%
Iteration: 55; Percent complete: 79.7%
Iteration: 56; Percent complete: 81.2%
Iteration: 57; Percent complete: 82.6%
Iteration: 58; Percent complete: 84.1%
Iteration: 59; Percent complete: 85.5%
Iteration: 60; Percent complete: 87.0%
Iteration: 61; Percent complete: 88.4%
Iteration: 62; Percent complete: 89.9%
Iteration: 63; Percent complete: 91.3%
Iteration: 64; Percent complete: 92.8%
Iteration: 65; Percent complete: 94.2%
Iteration: 66; Percent complete: 95.7%
Iteration: 67; Percent complete: 97.1%
Iteration: 68; Percent complete: 98.6%
Iteration: 69; Percent complete: 100.0%</code></pre>
</div>
</div>
<div id="cell-28" class="cell" data-outputid="8b208593-4f96-444f-ad6c-cb84c0ffd88b">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Inspect some of the outputs as a sanity-check</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>forecasts_df.head(<span class="dv">20</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">prediction</th>
<th data-quarto-table-cell-role="th">score</th>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">id</th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">191681310.17214.17214</td>
<td>0.0</td>
<td>0.300737</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">193088419.20001.20001</td>
<td>1.0</td>
<td>0.945930</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">191149920.17102.17102</td>
<td>0.0</td>
<td>0.347532</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">192892110.19259.19259</td>
<td>1.0</td>
<td>0.813790</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">190192199.17060.17060</td>
<td>0.0</td>
<td>0.045523</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">192890095.19227.19227</td>
<td>1.0</td>
<td>0.941272</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">190192005.17004.17004</td>
<td>0.0</td>
<td>0.043127</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">192885632.19156.19156</td>
<td>0.0</td>
<td>0.473514</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">190191827.16918.16918</td>
<td>0.0</td>
<td>0.126330</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">192882222.19129.19129</td>
<td>1.0</td>
<td>0.569842</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">190191097.16843.16843</td>
<td>0.0</td>
<td>0.260226</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">192642615.19074.19074</td>
<td>0.0</td>
<td>0.332530</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">190190570.16705.16705</td>
<td>1.0</td>
<td>0.758276</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">203899060.13359.13359</td>
<td>1.0</td>
<td>0.989039</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">15869198.3976.3976</td>
<td>0.0</td>
<td>0.340487</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">192640416.19036.19036</td>
<td>0.0</td>
<td>0.224283</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">190189346.16645.16645</td>
<td>0.0</td>
<td>0.124451</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">203898053.13222.13222</td>
<td>1.0</td>
<td>0.986863</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">390066809.29445.29445</td>
<td>1.0</td>
<td>0.804826</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">434001261.9906.9906</td>
<td>0.0</td>
<td>0.440444</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="part-8-merge-predictions-back-into-corpus-and-evaluate" class="level2">
<h2 class="anchored" data-anchor-id="part-8-merge-predictions-back-into-corpus-and-evaluate">Part 8: merge predictions back into corpus and evaluate</h2>
<p>Now that the hard part is done, all that is left to do is to evaluate the predictions. Since the predictions are in no particular order, we will first merge each prediction back into the source corpus, and then evaluate each conversation according to the order of utterances within that conversation.</p>
<div id="cell-30" class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># We will add a metadata entry to each test-set utterance signifying whether it was FORECAST to be a derailment.</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Note that there is an important subtlety in how this metadata field is to be interpreted - the forecast for a given</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="co"># utterance is made BEFORE the model actually sees the utterance. That is, the forecast does not mean "the model thinks</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="co"># this utterance *is* a derailment" but rather that "based on the context of all preceding utterances, the model predicted,</span></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="co"># prior to actually seeing this utterance, that this utterance *would be* a derailment".</span></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> convo <span class="kw">in</span> corpus.iter_conversations():</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># only consider test set conversations (we did not make predictions for the other ones)</span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> convo.meta[<span class="st">'split'</span>] <span class="op">==</span> <span class="st">"test"</span>:</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> utt <span class="kw">in</span> convo.iter_utterances():</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> utt.<span class="bu">id</span> <span class="kw">in</span> forecasts_df.index:</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>                utt.meta[<span class="st">'forecast_score'</span>] <span class="op">=</span> forecasts_df.loc[utt.<span class="bu">id</span>].score</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-31" class="cell" data-outputid="d478288b-55ae-4bc9-cb8c-f294a80f3174">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Finally, we can use the forecast-annotated corpus to compute the forecast accuracy.</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Though we have an individual forecast per utterance, ground truth is at the conversation level:</span></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="co"># either a conversation derails or it does not. Thus, forecast accuracy is computed as follows:</span></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="co">#   - True positives are cases that actually derail, for which the model made at least one positive forecast ANYTIME prior to derailment</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="co">#   - False positives are cases that don't derail but for which the model made at least one positive forecast</span></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a><span class="co">#   - False negatives are cases that derail but for which the model made no positive forecasts prior to derailment</span></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a><span class="co">#   - True negatives are cases that don't derail, for which the model made no positive forecasts</span></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Note that by construction, the last comment of each conversation is the one marked as derailment, and that our earlier code was therefore</span></span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a><span class="co"># set up to not look at the last comment, meaning that all forecasts we obtained are forecasts made prior to derailment. This simplifies</span></span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a><span class="co"># the computation of forecast accuracy as we now do not need to explicitly consider when a forecast was made.</span></span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a>conversational_forecasts_df <span class="op">=</span> {</span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">"convo_id"</span>: [],</span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">"label"</span>: [],</span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">"score"</span>: [],</span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a>    <span class="st">"prediction"</span>: []</span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> convo <span class="kw">in</span> corpus.iter_conversations():</span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> convo.meta[<span class="st">'split'</span>] <span class="op">==</span> <span class="st">"test"</span>:</span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a>        conversational_forecasts_df[<span class="st">'convo_id'</span>].append(convo.<span class="bu">id</span>)</span>
<span id="cb32-22"><a href="#cb32-22" aria-hidden="true" tabindex="-1"></a>        conversational_forecasts_df[<span class="st">'label'</span>].append(<span class="bu">int</span>(convo.meta[<span class="st">'conversation_has_personal_attack'</span>]))</span>
<span id="cb32-23"><a href="#cb32-23" aria-hidden="true" tabindex="-1"></a>        forecast_scores <span class="op">=</span> [utt.meta[<span class="st">'forecast_score'</span>] <span class="cf">for</span> utt <span class="kw">in</span> convo.iter_utterances() <span class="cf">if</span> <span class="st">'forecast_score'</span> <span class="kw">in</span> utt.meta]</span>
<span id="cb32-24"><a href="#cb32-24" aria-hidden="true" tabindex="-1"></a>        conversational_forecasts_df[<span class="st">'score'</span>] <span class="op">=</span> np.<span class="bu">max</span>(forecast_scores)</span>
<span id="cb32-25"><a href="#cb32-25" aria-hidden="true" tabindex="-1"></a>        conversational_forecasts_df[<span class="st">'prediction'</span>].append(<span class="bu">int</span>(np.<span class="bu">max</span>(forecast_scores) <span class="op">&gt;</span> FORECAST_THRESH))</span>
<span id="cb32-26"><a href="#cb32-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-27"><a href="#cb32-27" aria-hidden="true" tabindex="-1"></a>conversational_forecasts_df <span class="op">=</span> pd.DataFrame(conversational_forecasts_df).set_index(<span class="st">"convo_id"</span>)</span>
<span id="cb32-28"><a href="#cb32-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>((conversational_forecasts_df.label <span class="op">==</span> conversational_forecasts_df.prediction).mean())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.6547619047619048</code></pre>
</div>
</div>
<div id="cell-32" class="cell" data-outputid="d1ae7b87-6973-41a1-e7aa-806d57990c01">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># in addition to accuracy, we can also consider applying other metrics at the conversation level, such as precision/recall</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_pr_stats(preds, labels):</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>    tp <span class="op">=</span> ((labels<span class="op">==</span><span class="dv">1</span>)<span class="op">&amp;</span>(preds<span class="op">==</span><span class="dv">1</span>)).<span class="bu">sum</span>()</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>    fp <span class="op">=</span> ((labels<span class="op">==</span><span class="dv">0</span>)<span class="op">&amp;</span>(preds<span class="op">==</span><span class="dv">1</span>)).<span class="bu">sum</span>()</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>    tn <span class="op">=</span> ((labels<span class="op">==</span><span class="dv">0</span>)<span class="op">&amp;</span>(preds<span class="op">==</span><span class="dv">0</span>)).<span class="bu">sum</span>()</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>    fn <span class="op">=</span> ((labels<span class="op">==</span><span class="dv">1</span>)<span class="op">&amp;</span>(preds<span class="op">==</span><span class="dv">0</span>)).<span class="bu">sum</span>()</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Precision = </span><span class="sc">{0:.4f}</span><span class="st">, recall = </span><span class="sc">{1:.4f}</span><span class="st">"</span>.<span class="bu">format</span>(tp <span class="op">/</span> (tp <span class="op">+</span> fp), tp <span class="op">/</span> (tp <span class="op">+</span> fn)))</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"False positive rate ="</span>, fp <span class="op">/</span> (fp <span class="op">+</span> tn))</span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"F1 ="</span>, <span class="dv">2</span> <span class="op">/</span> (((tp <span class="op">+</span> fp) <span class="op">/</span> tp) <span class="op">+</span> ((tp <span class="op">+</span> fn) <span class="op">/</span> tp)))</span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>get_pr_stats(conversational_forecasts_df.prediction, conversational_forecasts_df.label)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Precision = 0.6354, recall = 0.7262
False positive rate = 0.4166666666666667
F1 = 0.6777777777777778</code></pre>
</div>
</div>
</section>
<section id="part-9-model-analysis-how-early-is-early-warning" class="level2">
<h2 class="anchored" data-anchor-id="part-9-model-analysis-how-early-is-early-warning">Part 9: model analysis: how early is early warning?</h2>
<p>The goal of CRAFT is to forecast outcomes in advance, but how far in advance does it typically make its prediction? Following the paper, we measure this in two ways: the number of <em>comments</em> between the first prediction and the actual derailment, and how much <em>elapsed time</em> that gap actually translates to.</p>
<div id="cell-34" class="cell">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>comments_until_derail <span class="op">=</span> {} <span class="co"># store the "number of comments until derailment" metric for each conversation</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>time_until_derail <span class="op">=</span> {} <span class="co"># store the "time until derailment" metric for each conversation</span></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> convo <span class="kw">in</span> corpus.iter_conversations():</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> convo.meta[<span class="st">'split'</span>] <span class="op">==</span> <span class="st">"test"</span> <span class="kw">and</span> convo.meta[<span class="st">'conversation_has_personal_attack'</span>]:</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># filter out the section header as usual</span></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>        utts <span class="op">=</span> [utt <span class="cf">for</span> utt <span class="kw">in</span> convo.iter_utterances() <span class="cf">if</span> <span class="kw">not</span> utt.meta[<span class="st">'is_section_header'</span>]]</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># by construction, the last comment is the one with the personal attack</span></span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>        derail_idx <span class="op">=</span> <span class="bu">len</span>(utts) <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># now scan the utterances in order until we find the first derailment prediction (if any)</span></span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> idx <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(utts)):</span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> utts[idx].meta[<span class="st">'forecast_score'</span>] <span class="op">&gt;</span> FORECAST_THRESH:</span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a>                <span class="co"># recall that the forecast_score meta field specifies what CRAFT thought this comment would look like BEFORE it</span></span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a>                <span class="co"># saw this comment. So the actual CRAFT forecast is made during the previous comment; we account for this by</span></span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a>                <span class="co"># subtracting 1 from idx</span></span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true" tabindex="-1"></a>                comments_until_derail[convo.<span class="bu">id</span>] <span class="op">=</span> derail_idx <span class="op">-</span> (idx<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb36-17"><a href="#cb36-17" aria-hidden="true" tabindex="-1"></a>                time_until_derail[convo.<span class="bu">id</span>] <span class="op">=</span> utts[derail_idx].timestamp <span class="op">-</span> utts[(idx<span class="op">-</span><span class="dv">1</span>)].timestamp</span>
<span id="cb36-18"><a href="#cb36-18" aria-hidden="true" tabindex="-1"></a>                <span class="cf">break</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-35" class="cell" data-outputid="26611644-8c44-4380-8897-b0de6eece0cd">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># compute some quick statistics about the distribution of the "number of comments until derailment" metric</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>comments_until_derail_vals <span class="op">=</span> np.asarray(<span class="bu">list</span>(comments_until_derail.values()))</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(np.<span class="bu">min</span>(comments_until_derail_vals), np.<span class="bu">max</span>(comments_until_derail_vals), np.median(comments_until_derail_vals), np.mean(comments_until_derail_vals))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1 12 3.0 3.2</code></pre>
</div>
</div>
<div id="cell-36" class="cell" data-outputid="85df20c5-62e1-4d2c-8736-8432a65f55ac">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># compute some quick statistics about the distribution of the "time until derailment" metric</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="co"># note that since timestamps are in seconds, we convert to hours by dividing by 3600, to make it more human readable</span></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>time_until_derail_vals <span class="op">=</span> np.asarray(<span class="bu">list</span>(time_until_derail.values())) <span class="op">/</span> <span class="dv">3600</span></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(np.<span class="bu">min</span>(time_until_derail_vals), np.<span class="bu">max</span>(time_until_derail_vals), np.median(time_until_derail_vals), np.mean(time_until_derail_vals))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.0 25575.071111111112 3.4491666666666667 277.8502741347906</code></pre>
</div>
</div>
<div id="cell-37" class="cell" data-outputid="7de51fb0-dbb9-42f2-8d5f-18fcda28ab00">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># visualize the distribution of "number of comments until derailment" as a histogram (reproducing Figure 4 from the paper)</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">'figure.figsize'</span>] <span class="op">=</span> (<span class="fl">10.0</span>, <span class="fl">5.0</span>)</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">'font.size'</span>] <span class="op">=</span> <span class="dv">24</span></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>plt.hist(comments_until_derail_vals, bins<span class="op">=</span><span class="bu">range</span>(<span class="dv">1</span>, np.<span class="bu">max</span>(comments_until_derail_vals)), density<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>plt.xlim(<span class="dv">1</span>,<span class="dv">10</span>)</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>plt.xticks(np.arange(<span class="dv">1</span>,<span class="dv">10</span>)<span class="op">+</span><span class="fl">0.5</span>, np.arange(<span class="dv">1</span>,<span class="dv">10</span>))</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>plt.yticks(np.arange(<span class="dv">0</span>,<span class="fl">0.25</span>,<span class="fl">0.05</span>), np.arange(<span class="dv">0</span>,<span class="dv">25</span>,<span class="dv">5</span>))</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Number of comments elapsed"</span>)</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"</span><span class="sc">% o</span><span class="st">f conversations"</span>)</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="CRAFT_fine_tuning_demo_using_ConvoKit_files/figure-html/cell-27-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>