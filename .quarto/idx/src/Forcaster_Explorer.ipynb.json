{"title":"Forecaster Prediction Performance","markdown":{"yaml":{"title":"Forecaster Prediction Performance","author":"Michelle Gelman","date":"04/21/2025","format":{"html":{"code-fold":true}},"jupyter":"python3"},"headingText":"Creating KODIS Corpus Object","containsRefs":false,"markdown":"\n\n\n### Create Corpus\n\n### Add conversation lengths as conversation metadata\n- 1 is \"impasse\"\n- 0 is \"success\"\n\n### Add Conversation Labels from Final Pre-processed Dataframe as conversation metadata\n\n# Creating Forecaster and Model Objects\n\n### CMV Model and Forecaster Object\n\n### Wiki Model and Forecaster Object\n\n# Model Weight Info\n\n### **craft‑wiki‑pretrained**\n\n- Contains only the utterance and context encoder layers pre‑trained on the CGA‑Wikipedia data (via next‑comment prediction), but its classifier head (the SingleTargetClf) is still at its random initialization.\n\n- Intended as a starting point if you want to fine‑tune CRAFT on your own conversational data (you’ll call fit to learn the classifier weights).\n\n### **craft‑wiki‑finetuned**\n- Builds on the above by having already fine‑tuned the entire network (including the classifier head).\n- Ready for inference only—you can call transform immediately and get sensible forecasts without any further training.\n\n# Run predictions on fine-tuned WIKI dataset with CRAFT model\n\n### Fresh Kodis Corpus\n\n### Make predictions as conversation evolves (temporally) - When will this conversation derail?\n\n### Make predictions on last utterance only (classification) - Is this a derailed conversation?\n\n# Run predictions on fine-tuned REDDIT CMV dataset with CRAFT model\n\n### Fresh Kodis Corpus\n\n### Make predictions as conversation evolves (temporally) - When will this conversation derail?\n\n### Make predictions on last utterance only (classification) - Is this a derailed conversation?\n\n\n# Compare Predicitons on test sets for CMV and WIKI datasets using respecitve fine-tuned CRAFT Models (todo)\n- for reproducability, need to check if any additions since 2018 for wiki data as it is public and growing. reddit cmv was created specifically for this paper, so no updates expected.\n\n# Comparing fine-tuned Models on KODIS Corpus\n\n### Running predictions on both fine-tuned wiki and cmv CRAFT models temporally on all utterances\n\n### Getting average derailement prediction and frequency of forecast probabilities across all utterances\n- Prediciton is *per utterance* on surface, but CRAFT model behind-the-scenes makes predicitons on encoded contexts which contain the conversation history up to current utterance. \n- See [Predictor Class](https://github.com/CornellNLP/ConvoKit/blob/master/convokit/forecaster/CRAFT/runners.py#L15) in runnery.py for CRAFT model\n- We get the frequency of KODIS utterances across 50 probabilities [0, .02, .04, ...,1] binned from the  predicited probabilities of each utterance by the fine-tuned cmv and fine-tuned wiki model\n\n### **Insights**\n- craft-wiki tends to \n**TODO** Make 3D plot, add another dimension for the length of current context (collapse by coversation by averaging over all convos that have that context length)\n\n### Conversation-level AUC and PR Curves\nto create these plots, I looked at [Forecasters](https://github.com/CornellNLP/ConvoKit/blob/master/convokit/forecaster/forecaster.py#L139) code for aggregating utternce-levele metrics on a conversation level where:\n\n- np.max(forecast_scores) is highest probability the model ever assigned to any utterance in this conversation\n- np.max(forecasts) is if the model ever cross its decision threshold and predict 1 (derailement) for thsi conversation\n\n### **Insights**\n- baseline positive class rate (impasse dispute) for KODIS is 17.6% out of current 2107 disputes.\n\n**PR Curve**\n\n-  bottoms out at baseline accuracy with higher decision thresholds, so no presicion-accuracy trade-off. Essesntially, lower decision threshold -> model is as good as baseline posititve rate, **so it never actually predicts derailment**. Probably due to high impassee/success class imbalance\n\n**AUC Curve**\n\n-  AUC still looks high for both bc of the class imbalance for derailement disputes I think-- so this may be misleading currently\n\n    - need to downsample and check if we do better than random \n\n### Comparing forcaster summaries for both fine-tuned wiki and cmv CRAFT models predictions\n- Ran using Forecasters summarize function for conversation-level statistics\n- both reddit and cmv have **Utterance-level labels for derailed comment** as well as classify derailment on a conversation level if the conversation contains a derailement comment.\n### Insights\n**Forecast Horizon: \"How early can we detect derailement?\"**\n- Since our dataset has an average length of 13.5 utterances, the forecast horizon on average is 9.72 and 10 respecitvely for the WIKI and cmv models, meaning derailement is forecast towards the end of a KODIS dispute.\n- This measures the number of utterances after the derailed utterance the model predicted in a coversation.\n\n**Conversation Metrics**\n- On a conversation-level, accuracy of predicting derailement is pretty low and F1 scores are low for both fine-tuned models\n    - **Accuracy**: The model mispredicts derailements most of the time - out of 2017 disputes, 45% and 24% were wrongly flagged as derailed. -> low Accuracy\n    - **Recall**: Models are very sensitive to derailement events and for all actual derailed disputes, it correctly flags them -> high Recall\n    - **FPR**: Since there are many successul disputes (majority class), the models flag a lot of them as derailed -> high FPR\n\nThe above is why the \"good\" AUC curve is misleading I think\n\n### Average length of tokenized utterances for wiki, cmv, and kodis corpora from CRAFT tokenization scheme\n- CRAFT has max tokenization length of 80 tokens per utterance. Is this relevant to the performance in anyway? More specifically:\n    - what are the tokenization lengths of the utterances for the data used in the train sets for CMV and Wiki?\n    - what is the average tokenization length for a KODIS utterance?\n\nIs it even relevant to affecting performance, and how to measure this?\n\n## Get tokenized utterances from training set data used in \"Trouble on the Horizon\" paper.\n- MAX_LENGTH = 80 for tokenized utterances\n","srcMarkdownNoYaml":"\n\n# Creating KODIS Corpus Object\n\n### Create Corpus\n\n### Add conversation lengths as conversation metadata\n- 1 is \"impasse\"\n- 0 is \"success\"\n\n### Add Conversation Labels from Final Pre-processed Dataframe as conversation metadata\n\n# Creating Forecaster and Model Objects\n\n### CMV Model and Forecaster Object\n\n### Wiki Model and Forecaster Object\n\n# Model Weight Info\n\n### **craft‑wiki‑pretrained**\n\n- Contains only the utterance and context encoder layers pre‑trained on the CGA‑Wikipedia data (via next‑comment prediction), but its classifier head (the SingleTargetClf) is still at its random initialization.\n\n- Intended as a starting point if you want to fine‑tune CRAFT on your own conversational data (you’ll call fit to learn the classifier weights).\n\n### **craft‑wiki‑finetuned**\n- Builds on the above by having already fine‑tuned the entire network (including the classifier head).\n- Ready for inference only—you can call transform immediately and get sensible forecasts without any further training.\n\n# Run predictions on fine-tuned WIKI dataset with CRAFT model\n\n### Fresh Kodis Corpus\n\n### Make predictions as conversation evolves (temporally) - When will this conversation derail?\n\n### Make predictions on last utterance only (classification) - Is this a derailed conversation?\n\n# Run predictions on fine-tuned REDDIT CMV dataset with CRAFT model\n\n### Fresh Kodis Corpus\n\n### Make predictions as conversation evolves (temporally) - When will this conversation derail?\n\n### Make predictions on last utterance only (classification) - Is this a derailed conversation?\n\n\n# Compare Predicitons on test sets for CMV and WIKI datasets using respecitve fine-tuned CRAFT Models (todo)\n- for reproducability, need to check if any additions since 2018 for wiki data as it is public and growing. reddit cmv was created specifically for this paper, so no updates expected.\n\n# Comparing fine-tuned Models on KODIS Corpus\n\n### Running predictions on both fine-tuned wiki and cmv CRAFT models temporally on all utterances\n\n### Getting average derailement prediction and frequency of forecast probabilities across all utterances\n- Prediciton is *per utterance* on surface, but CRAFT model behind-the-scenes makes predicitons on encoded contexts which contain the conversation history up to current utterance. \n- See [Predictor Class](https://github.com/CornellNLP/ConvoKit/blob/master/convokit/forecaster/CRAFT/runners.py#L15) in runnery.py for CRAFT model\n- We get the frequency of KODIS utterances across 50 probabilities [0, .02, .04, ...,1] binned from the  predicited probabilities of each utterance by the fine-tuned cmv and fine-tuned wiki model\n\n### **Insights**\n- craft-wiki tends to \n**TODO** Make 3D plot, add another dimension for the length of current context (collapse by coversation by averaging over all convos that have that context length)\n\n### Conversation-level AUC and PR Curves\nto create these plots, I looked at [Forecasters](https://github.com/CornellNLP/ConvoKit/blob/master/convokit/forecaster/forecaster.py#L139) code for aggregating utternce-levele metrics on a conversation level where:\n\n- np.max(forecast_scores) is highest probability the model ever assigned to any utterance in this conversation\n- np.max(forecasts) is if the model ever cross its decision threshold and predict 1 (derailement) for thsi conversation\n\n### **Insights**\n- baseline positive class rate (impasse dispute) for KODIS is 17.6% out of current 2107 disputes.\n\n**PR Curve**\n\n-  bottoms out at baseline accuracy with higher decision thresholds, so no presicion-accuracy trade-off. Essesntially, lower decision threshold -> model is as good as baseline posititve rate, **so it never actually predicts derailment**. Probably due to high impassee/success class imbalance\n\n**AUC Curve**\n\n-  AUC still looks high for both bc of the class imbalance for derailement disputes I think-- so this may be misleading currently\n\n    - need to downsample and check if we do better than random \n\n### Comparing forcaster summaries for both fine-tuned wiki and cmv CRAFT models predictions\n- Ran using Forecasters summarize function for conversation-level statistics\n- both reddit and cmv have **Utterance-level labels for derailed comment** as well as classify derailment on a conversation level if the conversation contains a derailement comment.\n### Insights\n**Forecast Horizon: \"How early can we detect derailement?\"**\n- Since our dataset has an average length of 13.5 utterances, the forecast horizon on average is 9.72 and 10 respecitvely for the WIKI and cmv models, meaning derailement is forecast towards the end of a KODIS dispute.\n- This measures the number of utterances after the derailed utterance the model predicted in a coversation.\n\n**Conversation Metrics**\n- On a conversation-level, accuracy of predicting derailement is pretty low and F1 scores are low for both fine-tuned models\n    - **Accuracy**: The model mispredicts derailements most of the time - out of 2017 disputes, 45% and 24% were wrongly flagged as derailed. -> low Accuracy\n    - **Recall**: Models are very sensitive to derailement events and for all actual derailed disputes, it correctly flags them -> high Recall\n    - **FPR**: Since there are many successul disputes (majority class), the models flag a lot of them as derailed -> high FPR\n\nThe above is why the \"good\" AUC curve is misleading I think\n\n### Average length of tokenized utterances for wiki, cmv, and kodis corpora from CRAFT tokenization scheme\n- CRAFT has max tokenization length of 80 tokens per utterance. Is this relevant to the performance in anyway? More specifically:\n    - what are the tokenization lengths of the utterances for the data used in the train sets for CMV and Wiki?\n    - what is the average tokenization length for a KODIS utterance?\n\nIs it even relevant to affecting performance, and how to measure this?\n\n## Get tokenized utterances from training set data used in \"Trouble on the Horizon\" paper.\n- MAX_LENGTH = 80 for tokenized utterances\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","output-file":"Forcaster_Explorer.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.42","site-lib-dir":"docs/site-libs","title":"Forecaster Prediction Performance","author":"Michelle Gelman","date":"04/21/2025","jupyter":"python3"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}